# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.

name: Synopsys Intelligent Security Scan

on: #!usr/bin/env python
__author__ = ""
__email__ = "@westwoodrobotics.io"
__copyright__ = "Copyright 2020 Westwood Robotics"
__date__ = "Jan 8, 2020"
__version__ = "0.1.2"
__status__ = "Production"

# -----------------------------
# Simple code to set ID for BEAR

from pybear import Manager

bear = Manager.BEAR(port="COM7", baudrate=8000000)
m_id = int(input("Enter the present ID and press enter.\n"))
print("Present ID entered is: %d" % m_id)
if bear.ping(m_id):
    print("BEAR connected.")
    m_id_new = int(input("Enter the new ID and press enter.\n"))
    bear.set_id((m_id, m_id_new))
    bear.save_config(m_id_new)
    if bear.ping(m_id_new):
        print("BEAR ID has been changed from %d to %d" % (m_id, m_id_new))
    else:
        print("BEAR ID change unsuccessful. Please try again.")
else:
    print("Seems like that BEAR is offline, please double check your entry and connections.")
  push: #!usr/bin/env python
__author__ = ""
__email__ = "@westwoodrobotics.io"
__copyright__ = "Copyright 2022 Westwood Robotics"
__date__ = "July 18, 2022"
__version__ = "0.0.1"
__status__ = "Prototype"

# -----------------------------
# Search and list all motors in the chain
# Prompt to change ID for each motor

# Ping and search for available BEARs
from pybear import Manager

# Define port and baud rate
bear_port = "COM11"
bear_baudrate = 8000000
# Define ID search range
id_range = range(0, 253)

bear = Manager.BEAR(port=bear_port, baudrate=bear_baudrate)
bear_list = []
found = False
for i in id_range:
    m_id = i
    data = bear.ping(m_id)[0]
    if data:
        found = True
        bear_list.append(m_id)
if found:
    print("Search done. Total of %d BEARs found. And their IDs are:" % len(bear_list))
    print(bear_list)
else:
    print("Search done. No BEAR found.")
    exit()

# Change ID if found BEAR(s).
if found:
    print("Changing ID...")
    for idx, m_id in enumerate(bear_list):
        print("Current object: %d of %d" % (idx+1, len(bear_list)))
        change_in_progress = True
        while change_in_progress:
            usr = input("Present ID: %d, enter new id or 'N/n' to skip:" % m_id)
            if usr in ['n', 'N']:
                change_in_progress = False
            else:
                try:
                    usr = int(usr)
                    if -1 < usr < 254:
                        if usr not in bear_list:
                            bear.set_id((m_id, usr))
                            bear.save_config(usr)
                            if bear.ping(usr):
                                print("Present BEAR's ID has been changed from %d to %d" % (m_id, usr))
                                change_in_progress = False
                            else:
                                print("BEAR ID change unsuccessful. Please debug.")
                                exit()
                        else:
                            print("Entered ID already exists in chain. Please try again.")
                    else:
                        print("Invalid entrance. Only integers from 0 to 253 accepted.")
                except:
                    print("Invalid entrance. Only integers from 0 to 253 accepted.")
    print("All done.")
    branches: [ "main" ]
  pull_request: #!usr/bin/env python
__author__ = ""
__email__ = "@westwoodrobotics.io"
__copyright__ = "Copyright 2022 Westwood Robotics"
__date__ = "July 18, 2022"
__version__ = "0.0.1"
__status__ = "Prototype"

# Test bulk_comm speed

from pybear import Manager
import time

BEAR_LIST = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]

port = 'COM11'
baud = 8000000
pbm = Manager.BEAR(port=port, baudrate=baud, bulk_timeout=0.002)


start_time = time.time()
for i in range(1000):
    pbm.bulk_read(BEAR_LIST, ['present_position', 'present_velocity', 'present_iq'])
end_time = time.time()
freq = 1000/(end_time-start_time)

print("Bulk_comm frequency: %2.4f" % freq)

    # The branches below must be a subset of the branches above
    branches: [ "main" ]
  schedule: #!usr/bin/env python
__author__ = ""
__email__ = "@westwoodrobotics.io"
__copyright__ = "Copyright 2020 Westwood Robotics"
__date__ = "Jan 8, 2021"
__version__ = "0.1.3"
__status__ = "Production"

# Ping and search for available BEARs
from pybear import Manager

# Define port and baud rate
bear_port = "COM7"
bear_baudrate = 8000000
# Define ID search range
id_range = range(0, 9)

bear = Manager.BEAR(port=bear_port, baudrate=bear_baudrate)
bear_list = []
found = False
for i in id_range:
    m_id = i
    print("Pinging BEAR with ID %d" % m_id)
    data = bear.ping(m_id)[0]
    if data:
        print("Found BEAR with ID %d." % m_id)
        found = True
        bear_list.append(m_id)
if found:
    print("Search done. Total of %d BEARs found. And their IDs are:\n" % len(bear_list))
    print(bear_list)
else:
    print("Search done. No BEAR found.")
    - cron: '35 22 * * 6'

jobs: # See here for image contents: https://github.com/microsoft/vscode-dev-containers/tree/v0.191.1/containers/typescript-node/.devcontainer/base.Dockerfile

# [Choice] Node.js version: 16, 14, 12
ARG VARIANT="16-buster"
FROM mcr.microsoft.com/vscode/devcontainers/typescript-node:0-${VARIANT}

# [Optional] Uncomment this section to install additional OS packages.
RUN apt-get update \
    && export DEBIAN_FRONTEND=noninteractive \
    && apt-get -y install --no-install-recommends \
        openjdk-11-jdk \
        firefox-esr

# Chromium and chrome-driver
ARG CHROMIUM_DEB_URL=https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
RUN wget -qO - $CHROMIUM_DEB_URL > /tmp/chrome_linux64.deb \
    && apt -y install /tmp/chrome_linux64.deb -f \
    && FULL_CHROME_VERSION=$(google-chrome --product-version) \
    && CHROME_VERSION=${FULL_CHROME_VERSION%.*} \
    && CHROMEDRIVER_DIR="/usr/local/share/chrome_driver" \
    && CHROMEDRIVER_BIN="$CHROMEDRIVER_DIR/chromedriver" \
    && LATEST_CHROMEDRIVER_VERSION=$(curl -sL "https://chromedriver.storage.googleapis.com/LATEST_RELEASE_$CHROME_VERSION") \
    && CHROMEDRIVER_URL="https://chromedriver.storage.googleapis.com/$LATEST_CHROMEDRIVER_VERSION/chromedriver_linux64.zip" \
    && wget -qO - $CHROMEDRIVER_URL > /tmp/chromedriver_linux64.zip \
    && mkdir -p $CHROMEDRIVER_DIR \
    && unzip -qq /tmp/chromedriver_linux64.zip -d $CHROMEDRIVER_DIR \
    && chmod +x $CHROMEDRIVER_BIN \
    && ln -s "$CHROMEDRIVER_BIN" /usr/bin/ \
    && rm -rf /tmp/chrome*

# [Optional] Uncomment if you want to install an additional version of node using nvm
# ARG EXTRA_NODE_VERSION=10
# RUN su node -c "source /usr/local/share/nvm/nvm.sh && nvm install ${EXTRA_NODE_VERSION}"

# [Optional] Uncomment if you want to install more global node packages
# RUN su node -c "npm install -g <your-package-list -here>"
  analyze: // For format details, see https://aka.ms/devcontainer.json. For config options, see the README at:
// https://github.com/microsoft/vscode-dev-containers/tree/v0.191.1/containers/typescript-node
{
  "name": "Node.js & TypeScript",
  "build": {
    "dockerfile": "Dockerfile",
    // Update 'VARIANT' to pick a Node version: 12, 14, 16
    "args": {
      "VARIANT": "16"
    }
  },
  // Set *default* container specific settings.json values on container create.
  "settings": {},
  // Add the IDs of extensions you want installed when the container is created.
  "extensions": [
    "dbaeumer.vscode-eslint"
  ],
  // Use 'forwardPorts' to make a list of ports inside the container available locally.
  // "forwardPorts": [],
  // Use 'postCreateCommand' to run commands after the container is created.
  "postCreateCommand": "yarn install && yarn build",
  // Comment out connect as root instead. More info: https://aka.ms/vscode-remote/containers/non-root.
  "remoteUser": "node"
}
    name: #!/usr/bin/env bash
set -eux

DEV_BUILD_REPO_NAME="hotwired/dev-builds"
DEV_BUILD_ORIGIN_URL="https://${1}@github.com/${DEV_BUILD_REPO_NAME}.git"
BUILD_PATH="$HOME/publish-dev-build"

mkdir "$BUILD_PATH"

cd "$GITHUB_WORKSPACE"
package_name="$(jq -r .name package.json)"
package_files=( dist package.json )
tag="${package_name}/${GITHUB_SHA:0:7}"

name="$(git log -n 1 --format=format:%cn)"
email="$(git log -n 1 --format=format:%ce)"
subject="$(git log -n 1 --format=format:%s)"
date="$(git log -n 1 --format=format:%ai)"
url="https://github.com/${GITHUB_REPOSITORY}/tree/${GITHUB_SHA}"
message="$tag $subject"$'\n\n'"$url"

cp -R "${package_files[@]}" "$BUILD_PATH"

cd "$BUILD_PATH"
git init .
git remote add origin "$DEV_BUILD_ORIGIN_URL"
git symbolic-ref HEAD refs/heads/publish-dev-build
git add "${package_files[@]}"

GIT_AUTHOR_DATE="$date" GIT_COMMITTER_DATE="$date" \
GIT_AUTHOR_NAME="$name" GIT_COMMITTER_NAME="$name" \
GIT_AUTHOR_EMAIL="$email" GIT_COMMITTER_EMAIL="$email" \
  git commit -m "$message"

git tag "$tag"
[ "$GITHUB_REF" != "refs/heads/main" ] || git tag -f "${package_name}/latest"
git push -f --tags

echo done
    runs-on: name: CI

on: [push, pull_request]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v3
    - uses: actions/setup-node@v3
      with:
        node-version: '16'
        cache: 'yarn'
    - run: yarn install --frozen-lockfile
    - run: yarn run playwright install --with-deps
    - run: yarn build

    - name: Set Chrome Version
      run: |
        CHROMEVER="$(chromedriver --version | cut -d' ' -f2)"
        echo "Actions ChromeDriver is $CHROMEVER"
        echo "CHROMEVER=${CHROMEVER}" >> $GITHUB_ENV

    - name: Lint
      run: yarn lint

    - name: Unit Test
      run: yarn test:unit

    - name: Chrome Test
      run: yarn test:browser --project=chrome

    - name: Firefox Test
      run: yarn test:browser --project=firefox

    - uses: actions/upload-artifact@v3
      with:
        name: turbo-dist
        path: dist/*
    permissions: name: dev-builds

on:
  workflow_dispatch:
  push:
    branches:
      - main
      - 'builds/**'

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-node@v3
        with:
          node-version: '16'
          cache: 'yarn'

      - run: yarn install --frozen-lockfile
      - run: yarn build

      - name: Publish dev build
        run: .github/scripts/publish-dev-build '${{ secrets.DEV_BUILD_GITHUB_TOKEN }}'
      actions: read
      contents: read
      security-events: write

    steps: {
  // Use IntelliSense to learn about possible attributes.
  // Hover to view descriptions of existing attributes.
  // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
  "version": "0.2.0",
  "configurations": [
    {
      "type": "node",
      "request": "launch",
      "name": "Turbo: Debug browser tests",
      "cwd": "${workspaceFolder}",
      "port": 9229,
      "outputCapture": "std",
      "internalConsoleOptions": "openOnSessionStart",
      "runtimeExecutable": "yarn",
      "runtimeArgs": ["test"]
    }
  ]
}
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Synopsys Intelligent Security Scan
      id: prescription
      uses: synopsys-sig/intelligent-security-scan@48eedfcd42bc342a294dc495ac452797b2d9ff08
      with: {
  // See https://go.microsoft.com/fwlink/?LinkId=733558
  // for the documentation about the tasks.json format
  "version": "2.0.0",
  "tasks": [
    {
      "label": "Turbo: Build dist directory",
      "type": "shell",
      "command": "yarn build",
      "group": {
        "kind": "build",
        "isDefault": true
      }
    },
    {
      "label": "Turbo: Run tests",
      "type": "shell",
      "dependsOn": "Turbo: Build dist directory",
      "command": "yarn test",
      "group": {
        "kind": "test",
        "isDefault": true
      }
    },
    {
      "label": "Turbo: Start dev server",
      "type": "shell",
      "dependsOn": "Turbo: Build dist directory",
      "command": "yarn start",
      "problemMatcher": []
    }
  ]
}
        ioServerUrl: ${{secrets.IO_SERVER_URL}}
        ioServerToken: ${{secrets.IO_SERVER_TOKEN}}
        workflowServerUrl: ${{secrets.WORKFLOW_SERVER_URL}}
        additionalWorkflowArgs: --polaris.url=${{secrets.POLARIS_SERVER_URL}} --polaris.token=${{secrets.POLARIS_ACCESS_TOKEN}}
        stage: "IO"

    # Please note that the ID in previous step was set to prescription
    # in order for this logic to work also make sure that POLARIS_ACCESS_TOKEN
    # is defined in settings
    - name: Static Analysis with Polaris
      if: ${{steps.prescription.outputs.sastScan == 'true' }}
      run: |
          export POLARIS_SERVER_URL=${{ secrets.POLARIS_SERVER_URL}}
          export POLARIS_ACCESS_TOKEN=${{ secrets.POLARIS_ACCESS_TOKEN}}
          wget -q ${{ secrets.POLARIS_SERVER_URL}}/api/tools/polaris_cli-linux64.zip
          unzip -j polaris_cli-linux64.zip -d /tmp
          /tmp/polaris analyze -w

    # Please note that the ID in previous step was set to prescription
    # in order for this logic to work
    - name: Software Composition Analysis with Black Duck
      if: ${{steps.prescription.outputs.scaScan == 'true' }}
      uses: blackducksoftware/github-action@9ea442b34409737f64743781e9adc71fd8e17d38
      with:
         args: '--blackduck.url="${{ secrets.BLACKDUCK_URL}}" --blackduck.api.token="${{ secrets.BLACKDUCK_TOKEN}}" --detect.tools="SIGNATURE_SCAN,DETECTOR"'

    - name: Synopsys Intelligent Security Scan
      if: ${{ steps.prescription.outputs.sastScan == 'true' || steps.prescription.outputs.scaScan == 'true' }}
      uses: synopsys-sig/intelligent-security-scan@48eedfcd42bc342a294dc495ac452797b2d9ff08
      with:
        ioServerUrl: ${{secrets.IO_SERVER_URL}}
        ioServerToken: ${{secrets.IO_SERVER_TOKEN}}
        workflowServerUrl: ${{secrets.WORKFLOW_SERVER_URL}}
        additionalWorkflowArgs: --IS_SAST_ENABLED=${{steps.prescription.outputs.sastScan}} --IS_SCA_ENABLED=${{steps.prescription.outputs.scaScan}}
                --polaris.project.name={{PROJECT_NAME}} --polaris.url=${{secrets.POLARIS_SERVER_URL}} --polaris.token=${{secrets.POLARIS_ACCESS_TOKEN}}
                --blackduck.project.name={{PROJECT_NAME}}:{{PROJECT_VERSION}} --blackduck.url=${{secrets.BLACKDUCK_URL}} --blackduck.api.token=${{secrets.BLACKDUCK_TOKEN}}
        stage: "WORKFLOW"

    - name: Upload SARIF file
      if: ${{steps.prescription.outputs.sastScan == 'true' }}
      uses: github/codeql-action/upload-sarif@v2
      with:
        # Path to SARIF file relative to the root of the repository
        sarif_file: workflowengine-results.sarif.json
