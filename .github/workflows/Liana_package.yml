# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.
#
# See https://github.com/r-lib/actions/tree/master/examples#readme for
# additional example workflows available for the R community.

name: R

on: #' Function to handle different types of object as input and do basic quality checks
#'
#' @param sce SingleCellExperiment or Seurat object
#' @param ... dot dot dot bucket - not passed to anything, handles issues with
#' passing non-existing arguments
#'
#' @export
liana_prep <- function (sce, ...) {
    UseMethod("liana_prep", sce)
}

#' @export
liana_prep.SingleCellExperiment <- function(sce,
                                            idents_col = NULL,
                                            verbose = TRUE,
                                            min_cells = 0,
                                            ...){

    if(!all(c("counts", "logcounts") %in% SummarizedExperiment::assayNames(sce))){
        stop("liana expects `counts` and `logcounts` to be present in the SCE object")
    }

    # Assign idents to default if not passed
    idents <-
        .format_idents(metadata = as.data.frame(SingleCellExperiment::colData(sce)),
                       active_idents = SingleCellExperiment::colLabels(sce),
                       idents_col = idents_col,
                       object_class = class(sce) %>% pluck(1),
                       verbose = verbose)

    # Assign idents to default if not passed
    SingleCellExperiment::colLabels(sce) <- idents
    sce@int_metadata$base <- 2 # save base for logFC conv

    return(.filter_sce(sce, min_cells, verbose))
}

#' @export
liana_prep.Seurat <- function(sce,
                              idents_col = NULL,
                              verbose = TRUE,
                              assay = NULL,
                              min_cells = 0,
                              ...){

    assay %<>% `%||%`(SeuratObject::DefaultAssay(sce))
    message(stringr::str_glue("Expression from the `{assay}` assay will be used"))

    # Assign idents to default if not passed
    # Assign idents to default if not passed
    idents <-
        .format_idents(metadata = sce@meta.data,
                       active_idents = SeuratObject::Idents(sce),
                       idents_col = idents_col,
                       object_class = class(sce) %>% pluck(1),
                       verbose = verbose)

    # convert from seurat_object to sce
    sce <- SingleCellExperiment::SingleCellExperiment(
        list(
            counts = SeuratObject::GetAssayData(object = sce,
                                                assay = assay,
                                                slot = "counts"),
            logcounts = SeuratObject::GetAssayData(object = sce,
                                                   assay = assay,
                                                   slot = "data")
        ),
        metadata = sce@meta.data)

    SingleCellExperiment::colLabels(sce) <- idents
    sce@int_metadata$base <- exp(1) # save base for logFC conv

    return(.filter_sce(sce, min_cells, verbose))
}


#' Helper function to perform basic filterin on the SCE object prior to feeding it to LIANA
#'
#' @param sce SingleCellExperiment Object
#' @param min_cells minimum cell per cell identity to be considered for analysis
#' @param verbose logical for verbosity
#'
#' @return SingleCellExperiment object
#'
#' @noRd
.filter_sce <- function(sce, min_cells, verbose){
    # EXTEND QUALITY CONTROL STEPS
    if(any(is.na(colLabels(sce)))){
        stop("NAs found in Idents/Labels!")
    }

    if (!is.numeric(min_cells) | min_cells < 0) {
      stop("min_cells parameter should be a positive number")
    }

    # Remove any cell types with less than X cells
    remove_labels <- colData(sce) %>%
        as_tibble() %>%
        mutate(label = as.character(label)) %>%
        group_by(label) %>%
        summarise(remove=n() < min_cells) %>%
        filter(remove) %>%
        pull(label)
    if(length(remove_labels) > 0){
        liana_message(
            stringr::str_glue(
                "Cell identities with less ",
                "than {min_cells} cells: {remove_labels} were removed!"
                ),
            output="message",
            verbose=verbose
        )
        sce <- sce[,!colLabels(sce) %in% remove_labels]
        colLabels(sce) <- as.factor(as.character(colLabels(sce)))
    }

    nonzero_genes <- rowSums(counts(sce)) > 0
    nonzero_cells <- colSums(counts(sce)) > 0

    if(!all(nonzero_cells) | !all(nonzero_genes)){
        nzero_genes <- sum(map_dbl(nonzero_genes, function(x) rlang::is_false(x = x)))
        nzero_cells <- sum(map_dbl(nonzero_cells, function(x) rlang::is_false(x = x)))

        liana_message(
            stringr::str_glue("{nzero_genes} genes and/or {nzero_cells} ",
                              "cells were removed as they had no counts!"),
            output="warning",
            verbose=verbose
        )
    }

    # Convert to sparse!
    if(!is(counts(sce), "sparseMatrix")){
        counts(sce) <- as(counts(sce), "sparseMatrix")
        logcounts(sce) <- as(logcounts(sce), "sparseMatrix")
    }

    # Check counts (if negative -> Stop)
    if(min(exec("logcounts", sce)) < 0){
        stop("Negative counts are present in the Matrix!")
    }

    # Check counts (if not log-transformed -> Stop)
    if(all(round(exec("logcounts", sce)@x[1:100]) == exec("logcounts", sce)@x[1:100])){
        stop("Please make sure an assay with normalized counts is present!")
    }


    return(sce[nonzero_genes, nonzero_cells])
}



#' Helper Function to get/format the required indentity if required
#'
#' @param metadata metadata obtained from the sce object
#' @param active_idents active idents (e.g. Seurat::Idents, or sce colLabels)
#' @param object_class class of the sce object (SingleCellExperiment or Seurat)
#'
#' @inheritParams liana_wrap
#'
#' @noRd
.format_idents <- function (metadata,
                            active_idents,
                            idents_col,
                            object_class,
                            verbose){
    if (is_null(idents_col)){
        # get active ident col and assign
        idents_col <- .get_ident(metadata,
                                 active_idents,
                                 object_class = object_class)
    }

    if(!is_null(idents_col)){
        # If idents_col is not null set it that one
        if(!idents_col %in% colnames(metadata)){
            stop(str_glue("`{idents_col}` was not found!"))
        }
        idents <- metadata[[idents_col]]
        liana_message(str_glue("Running LIANA with `{idents_col}` as labels!"),
                      verbose = verbose)

    } else if(!is_null(active_idents)){
        idents <- active_idents
        liana_message(str_glue("Running LIANA with `colLabels`/`Idents` as labels",
                               " (matching column in metadata not found).",
                               .sep = ""),
                      verbose = verbose)
    } else{
        stop("Please provide existing cell type identities!")
    }

    # Check if idents is a factor
    if(is.null(levels(idents))){
        idents %<>% as.factor()
        message(str_glue("`Idents` were converted to factor"))

    }


    return(idents)
}




#' Helper Function to get the required identity (cluster annotation column)
#'  from the sce/seurat object metadata
#'
#' @param metadata df/tibble with metadata information
#'
#' @noRd
.get_ident <- function(metadata, idents, object_class){
    map(names(metadata),
        function(x){
            p <- metadata %>%
                select(sym(x)) %>%
                {`if`(object_class=="SingleCellExperiment",
                     .,
                     rownames_to_column(., "names")
                     )} %>%
                deframe()

            if(identical(p, idents)){
                return(x)
            }
            return()
        }) %>%
        compact %>%
        as.character %>%
        pluck(1) # to handle scenario when there are two identical columns
}



#' LIANA message/warning helper function to allow for verbosity
#'
#' @inheritParams base::stop
#' @param output type of output - message, warning, or stop
#' @param verbose logical for verbosity
liana_message <- function(...,
                          output = "message",
                          verbose = TRUE){
    if(verbose){
        exec(output, ...)
    }
}



#' Helper function to convert sce to seurat for EXTERNAL `call_` functions only
#'
#' @param sce SingleCellExperiment or Seurat Object
#' @param assay name of the active assay
#'
#' @noRd
.liana_convert <- function(sce, assay){
    seurat_object <- SeuratObject::as.Seurat(sce)
    SeuratObject::Idents(seurat_object) <- SingleCellExperiment::colLabels(sce)
    seurat_object@assays[[assay]] <- seurat_object@assays[[1]]
    SeuratObject::DefaultAssay(seurat_object) <- assay

    return(seurat_object)
}
  push: #' Helper function to account for complexes in the resources
#'
#' @param lr_res decomplexified* lr_res
#' @param columns columns to account for complexes for (obtained via the `ScoreSpecifics` class)
#' @param ... placeholder
#'
#' One could choose to do any other type of mean: geometric, TriMean, etc.
#'
#' @returns complex-accounted lr_res, with both complex and subunit genesymbols
#'
#' @details to be passed before the relevant score_calc function;
#' * decomplexified refers to complexes being broken into subunits which are then
#'  treated as seperate entities and re-assembled into complexes (or 'recomplexified')
#'  by this function
#'
#' Note that we call `account_missing` function to assign any complex with missing subunits's
#' relevant columns and expression proportion to 0. This then results in the whole
#' complex being then being filtered (by default) or considered as non-expressed.
#'
#' @export
#'
#' @keywords internal
#'
#' @importFrom stringr str_split
recomplexify <- function(lr_res,
                         columns,
                         add_columns,
                         ...){

    # Get Complex policy from elipses
    complex_policy <- list(...)[["complex_policy"]]

    # Account for Missing Subunits
    recomplexify_env = new.env()
    lr_res %<>% account_missing(recomplexify_env)

    # Account for Complexes
    grps <- c("source", "target",
              "ligand.complex", "receptor.complex")

    lr_res <- lr_res %>%
        group_by(across(all_of(grps))) %>%
        mutate(ligand.prop = min(ligand.prop),
               receptor.prop = min(receptor.prop))

    columns %>%
        map(function(col){

            col.min <- sym(str_glue("{col}.min"))
            col.flag <- sym(str_glue("{col}.flag"))

            lr_res <<- lr_res %>%
                group_by(across(all_of(grps))) %>%
                mutate( {{ col.min }} := min(.data[[col]]) ) %>%
                mutate( {{ col.flag }} :=
                            ifelse(.data[[col]]==.data[[col.min]],
                                   TRUE,
                                   FALSE)) %>%
                mutate( {{ col }} := exec(complex_policy, .data[[col]]) )
        })

    # ad-hoc fix for NATMI
    if("ligand.sum" %in% add_columns){
        corrected_sums <- lr_res %>%
            # Keep only the min-expressed subunits
            group_by(across(all_of(grps))) %>%
            summarise(ligand.sum = exec(complex_policy, ligand.sum),
                      receptor.sum = exec(complex_policy, receptor.sum))

        lr_res %<>%
            select(-c("ligand.sum", "receptor.sum")) %>%
            left_join(corrected_sums, by = grps)
    }

    lr_cmplx <- lr_res %>%
        # Keep only the min-expressed subunits
        filter(if_all(ends_with("flag"))) %>%
        # Group for the subsequent scoring functions
        group_by(across(all_of(c("source", "target",
                                 "ligand", "receptor"))))

    return(lr_cmplx)
}



#' Function to account for missing subunits
#'
#' @param lr_res LR results as obtained by `lr_pipe`
#' @param env environemnt to which the lr_res will be saved
#'
#' @details this function applies loops over all complexes and assigns 0s to
#'    the stats of any complexes with a missing subunit. The loop is iteratively
#'    applied over the same `lr_res`, to provide a more controlled environment
#'    we pass the environment of recomplexify and modify `lr_res` in place.
#'
#' @noRd
account_missing <- function(lr_res, env){

    env$lr_res <- lr_res

    ligand_complexes <- lr_res %>%
        filter(str_detect(.data[["ligand.complex"]], "_")) %>%
        pluck("ligand.complex") %>%
        unique()

    receptor_complexes <- lr_res %>%
        filter(str_detect(.data$receptor.complex, "_")) %>%
        pluck("receptor.complex") %>%
        unique()

    map(ligand_complexes,
        ~missing_subunits_to0(lr_res = lr_res,
                              complex = .x,
                              entity = "ligand",
                              env = env))

    map(receptor_complexes,
        ~missing_subunits_to0(lr_res = lr_res,
                              complex = .x,
                              entity = "receptor",
                              env = env))

    return(env$lr_res)
}


#' Helper Function that assigns 0s to any complexes with missing subunits
#'
#' @param lr_res LR results as obtained by `lr_pipe`
#' @param complex complex of interest
#' @param entity is the complex a 'ligand' or 'receptor'
#' @param env environment passed to which recursive changes are saved
#'
#' @return A `lr_res` tibble with
#'
#' @noRd
missing_subunits_to0 <- function(lr_res, complex, entity, env){

    entity.complex <- str_glue("{entity}.complex")

    complex_split <- # split complex into subunits
        str_split(complex, "_") %>%
        pluck(1)

    # check if subunits are present
    absent_subunits <- setdiff(complex_split,
                               lr_res[[entity]] %>% unique())

    # if there are absent subunits assign 0s and pvalues of 1
    if(length(absent_subunits) > 0){
        env$lr_res <- env$lr_res %>%
            # any numeric value to 0
            mutate(across(where(is.numeric) & starts_with(!!entity),
                          ~ ifelse(.data[[entity.complex]]==complex, 0, .))) %>%
            # FDR and pval to 1
            mutate(across(starts_with(!!entity) &
                              (ends_with("FDR") | ends_with("pval")),
                          ~ ifelse(.data[[entity.complex]]==complex, 1, .)))
    }

    return()
}


#' Helper Function which returns the value closest to 0
#' @param vec numeric vector
#'
#' @return value closest to 0
#'
min0 <- function(vec){
    vec[which.min(abs(vec))]
}


#' Helper Function which returns the mean, unless there is a 0 value then it returns 0
#'
#' @param vec numeric vector
#'
#' @return the mean of the vector unless 0 is present, then returns 0
#'
#' @export
#'
#' @keywords internal
mean0 <- function(vec){
    if((0 %in% vec)){
        return(0)
    }
    return(mean(x = vec))
}
    branches: [ "main" ]
  pull_request: #' S4 Class used to generate aggregate/consesus scores for the methods.
#'
#' @name ScoreSpecifics-class
#'
#' @field method_name name of the method (e.g. cellchat)
#' @field method_score The interaction score provided by the method (typically
#' the score that reflects the specificity of interaction)
#' @field descending_order whether the score should be interpreted in
#'  descending order (i.e. highest score for an interaction is most likely)
#'
#' @field score_fun name of the function to call to generate the results
#'
#' @field columns columns required to generate the score
#'
#' @exportClass ScoreSpecifics
#'
#' @keywords internal
setClass("ScoreSpecifics",
         slots=list(method_name = "character",
                    method_score = "character",
                    descending_order= "logical",
                    score_fun = "function",
                    columns = "character",
                    add_columns = 'character'
                    )
)


#' Score Specs Holder
#'
#' @return list of ScoreSpecifics objects for each method
#'
#' @noRd
#'
#' @details This function returns a list with objects per method in LIANA.
#' These object are used in the liana aggragate function, as well as in
#' liana_score and liana_call.
.score_specs <- function(){
    list(
        "connectome" =
            methods::new(
                "ScoreSpecifics",
                method_name = "connectome",
                method_score = "weight_sc",
                descending_order = TRUE,
                score_fun = connectome_score,
                columns = c("ligand.scaled", "receptor.scaled"),
                add_columns = NA_character_
            ),
        "logfc" =
            methods::new(
                "ScoreSpecifics",
                method_name = "logfc", # ~italk
                method_score = "logfc_comb",
                descending_order = TRUE,
                score_fun = logfc_score,
                columns = c("ligand.log2FC", "receptor.log2FC"),
                add_columns = NA_character_
            ),
        "natmi" =
            methods::new(
                "ScoreSpecifics",
                method_name = "natmi",
                method_score = "edge_specificity",
                descending_order = TRUE,
                score_fun = natmi_score,
                # Note that passing both .sum and .expr results the means
                # being returned for both of them (i.e. recomplexify will
                # account for both)
                columns = c("ligand.expr", "receptor.expr"),
                add_columns = c("ligand.sum", "receptor.sum")
            ),
        "sca" =
            methods::new(
                "ScoreSpecifics",
                method_name = "sca",
                method_score = "LRscore",
                descending_order = TRUE,
                score_fun = sca_score,
                columns = c("ligand.expr", "receptor.expr"),
                add_columns = c("global_mean")
            ),
        "cellphonedb" =
            methods::new(
                "ScoreSpecifics",
                method_name = "cellphonedb",
                method_score = "pvalue",
                descending_order = FALSE,
                score_fun = cellphonedb_score,
                columns = c("ligand.expr", "receptor.expr"),
                add_columns = NA_character_
            ),
        "cytotalk" =
            methods::new(
                "ScoreSpecifics",
                method_name = "cytotalk",
                method_score = "crosstalk_score",
                descending_order = TRUE,
                score_fun = cytotalk_score,
                columns = c("receptor.pem", "ligand.pem"),
                add_columns = NA_character_
            ),

        # External
        "call_squidpy" =
            methods::new(
                "ScoreSpecifics",
                method_name = "Squidpy",
                method_score = "pvalue",
                descending_order = FALSE,
                score_fun = function(){},
                columns = "",
                add_columns = NA_character_
            ),
        "call_cellchat" =
            methods::new(
                "ScoreSpecifics",
                method_name = "cellchat",
                method_score = "pval",
                descending_order = FALSE,
                score_fun = function(){},
                columns = "",
                add_columns = NA_character_
            ),

        "call_connectome" =
            methods::new(
                "ScoreSpecifics",
                method_name = "connectome",
                method_score = "weight_sc",
                descending_order = TRUE,
                score_fun = function(){},
                columns = "",
                add_columns = NA_character_
            ),
        "call_sca" = methods::new(
            "ScoreSpecifics",
            method_name = "sca",
            method_score = "LRscore",
            descending_order = TRUE,
            score_fun = function(){},
            columns = "",
            add_columns = NA_character_
        ),
        "call_italk" =
            methods::new(
                "ScoreSpecifics",
                method_name = "italk",
                method_score = "logfc_comb",
                descending_order = TRUE,
                score_fun = function(){},
                columns = "",
                add_columns = NA_character_
            ),
        "call_natmi" =
            methods::new(
                "ScoreSpecifics",
                method_name = "natmi",
                method_score = "edge_specificity",
                descending_order = TRUE,
                score_fun = function(){},
                columns = "",
                add_columns = NA_character_
            )
    )
}






#' Helper function to call aggregate housekeeping scores of external methods.
#'
#' @details functions the same way as .score_specs, but is only used in
#' liana_aggragate for the purpose of the manuscript.
#'
#' @noRd
.score_housekeep <- function(){
    list(
        "squidpy" =
            methods::new(
                "ScoreSpecifics",
                method_name = "Squidpy",
                method_score = "means",
                descending_order = TRUE,
                score_fun = function(){},
                columns = "",
                add_columns = NA_character_
            ),
        "cellphonedb" =
            methods::new(
                "ScoreSpecifics",
                method_name = "cellphonedb",
                method_score = "lr.mean",
                descending_order = TRUE,
                score_fun = function(){},
                columns = "",
                add_columns = NA_character_
            ),
        "natmi" =
            methods::new(
                "ScoreSpecifics",
                method_name = "natmi",
                method_score = "prod_weight",
                descending_order = TRUE,
                score_fun = function(){},
                columns = "",
                add_columns = NA_character_
            ),
        "cellchat" =
            methods::new(
                "ScoreSpecifics",
                method_name = "cellchat",
                method_score = "prob",
                descending_order = TRUE,
                score_fun = function(){},
                columns = "",
                add_columns = NA_character_
            ),
        "call_connectome" =
            methods::new(
                "ScoreSpecifics",
                method_name = "connectome",
                method_score = "weight_norm",
                descending_order = TRUE,
                score_fun = function(){},
                columns = "",
                add_columns = NA_character_
            ),
        "call_sca" = methods::new(
            "ScoreSpecifics",
            method_name = "sca",
            method_score = "LRscore",
            descending_order = TRUE,
            score_fun = function(){},
            columns = "",
            add_columns = NA_character_
        ),
        "sca" = methods::new(
            "ScoreSpecifics",
            method_name = "sca",
            method_score = "LRscore",
            descending_order = TRUE,
            score_fun = function(){},
            columns = "",
            add_columns = NA_character_
        ),
        "call_natmi" =
            methods::new(
                "ScoreSpecifics",
                method_name = "natmi",
                method_score = "edge_avg_expr",
                descending_order = TRUE,
                score_fun = function(){},
                columns = "",
                add_columns = NA_character_
            )
    )
}
    branches: [ "main" ]

permissions: #' Wrapper function to run `cell2cell_tensor` with LIANA output.
#'
#' @details This function servers as a one-liner wrapper to the tensor factorisation
#' method described in \href{https://www.nature.com/articles/s41467-022-31369-2}{tensor_cell2cell}.
#' We refer the user to the publication and \href{https://earmingol.github.io/cell2cell/tutorials/ASD/01-Tensor-Factorization-ASD/}{tensor_cell2cell tutorial page}
#' made by the authors. Logically, one should cite cell2cell's paper if their
#' method was used via LIANA.
#'
#' @param sce SingleCellExperiment with `context_df_dict` - i.e. liana results
#' per context (sample) stored at `sce@metadata$liana_res`
#'
#' @param context_df_dict Dictionary (named list) containing a dataframe for
#' each context. The dataframe must contain columns containing sender (source) cells,
#' receiver (target) cells, ligands, receptors, and communication scores, separately.
#' Keys are context names and values are dataframes. NULL by default.
#' If not NULL will be used instead of `sce@metadata$liana_res`.
#'
#' @param sender_col Name of the column containing the sender cells in all context
#' dataframes.
#'
#' @param receiver_col Name of the column containing the receiver cells in all context
#' dataframes.
#'
#' @param ligand_col Name of the column containing the ligands in all context
#' dataframes.
#'
#' @param receptor_col Name of the column containing the receptors in all context
#' dataframes.
#'
#' @param score_col Name of the column containing the communication scores in
#' all context dataframes.
#'
#' @param how  Approach to consider cell types and genes present across multiple contexts.
#' - 'inner' : Considers only cell types and LR pairs that are present in all contexts (intersection).
#' - 'outer' : Considers all cell types and LR pairs that are present across contexts (union).
#' - 'outer_lr' : Considers only cell types that are present in all contexts (intersection),
#'  while all LR pairs that are present across contexts (union).
#' - 'outer_cells' : Considers only LR pairs that are present in all contexts (intersection),
#'  while all cell types that are present across contexts (union).
#'
#' @param lr_fill Value to fill communication scores when a ligand-receptor
#'  pair is not present across all contexts. (NaN by default)
#'
#' @param cell_fill Value to fill communication scores when a cell is not
#'  present across all ligand-receptor pairs or all contexts. (NaN by default)
#'
#' @param lr_sep Separation character to join ligands and receptors into a
#'  LR pair name. ('^' by Default)
#'
#' @param context_order List used to sort the contexts when building the tensor.
#'  Elements must be all elements in `names(context_df_dict)`. (NULL by default)
#'
#' @param sort_elements  Whether alphabetically sorting elements in the
#' InteractionTensor. The Context Dimension is not sorted if a
#' 'context_order' list is provided. (TRUE by default).
#'
#' @param device Device to use when backend is pytorch.
#' Options are: ['cpu', 'cuda:0', None]. NULL by Default
#'
#' @param rank Ranks for the Tensor Factorization (number of factors to deconvolve the original tensor).
#'  If NULL, then rank selection is performed using the `elbow_rank_selection` function.
#'
#' @param seed Random seed integer
#'
#' @param upper_rank Upper bound of ranks to explore with the elbow analysis.
#'
#' @param runs Number of tensor factorization performed for a given rank.
#' Each factorization varies in the seed of initialization. Consider increasing
#' the number of runs, in order to obtain a more robust rank estimate.
#'
#' @param init Initialization method for computing the Tensor Factorization.
#' {‘svd’, ‘random’}
#'
#' @param build_only Whether to only return a tensor instance, without rank
#'   selection and no factorization.
#'
#' @param factors_only whether to return only the factors after factorization
#'
#' @param conda_env name of existing conda environment
#'
#' @param use_available whether to use c2c if available in current env.
#' False by default.
#'
#' @param verbose verbosity logical
#'
#' @param inplace logical (TRUE by default) if liana results are to be saved
#'  to the SingleCellExperiment object (`sce@metadata$liana_res`)
#'
#' @param ... Dictionary containing keyword arguments for the c2c.compute_tensor_factorization function.
#' The function deals with `random_state` (seed) and `rank` internally.
#'
#' @returns an instance of the cell2cell.tensor.BaseTensor class (via reticulate).
#' If build_only is TRUE, then no rank selection or tensor decomposition is returned.
#' Otherwise, returns a tensor with factorization results.
#'
#' @import reticulate basilisk
#'
#' @export
#'
liana_tensor_c2c <- function(sce=NULL,
                             context_df_dict = NULL,
                             score_col = "LRscore",
                             how='inner',
                             lr_fill=NaN,
                             cell_fill=NaN,
                             lr_sep="^",
                             context_order=NULL,
                             sort_elements=TRUE,
                             device=NULL,
                             rank=NULL,
                             seed = 1337,
                             upper_rank = 25,
                             runs = 3,
                             init = 'svd',
                             build_only = FALSE,
                             factors_only = TRUE,
                             conda_env=NULL,
                             use_available=FALSE,
                             verbose = TRUE,
                             inplace=TRUE,
                             sender_col = "source",
                             receiver_col = "target",
                             ligand_col = "ligand.complex",
                             receptor_col = "receptor.complex",
                             ...){

    if(is.null(context_df_dict) & is.null(sce)){
        stop("Please provide a valid `sce` OR `context_df_dict` object")
    }

    if(!is.null(context_df_dict) & !is.null(sce)){
        liana_message("`sce` was superseded by `context_df_dict`!",
                      output = "warning",
                      verbose = verbose
                      )
    }

    if(is.null(context_df_dict)){
        context_df_dict <- sce@metadata$liana_res
    }

    # Deal with rank
    rank <- if(is.null(rank)){ NULL } else {as.integer(rank)}

    c2c_available <-
    # Load correct conda env
    if(!is.null(conda_env)){
        print(0)
        liana_message(str_glue("Loading `{conda_env}` Conda Environment"),
                      verbose = verbose,
                      output = "message")
        reticulate::use_condaenv(condaenv = conda_env,
                                 conda = "auto",
                                 required = TRUE)

    # check if c2c is available, if not create env with basilisk
    } else if(use_available){
        if(!reticulate::py_module_available("cell2cell")){
            stop("cell2cell was not found")
        }
    } else{
        # load basilisk env
        liana_message(str_glue("Setting up Conda Environment with Basilisk"),
                      verbose = verbose,
                      output = "message")

        # Set up basilisk
        liana_env <- basilisk::BasiliskEnvironment(envname="liana_cell2cell",
                                                   pkgname="liana",
                                                   packages=.lianapy_packages,
                                                   pip=.liana_pips)
        basilisk::basiliskStart(liana_env, testload="scipy.optimize")
    }
    reticulate::py_set_seed(seed)

    # Import c2c
    c2c <- reticulate::import(module = "cell2cell", as="c2c")

    # Format scores to tensor
    liana_message(str_glue("Building the tensor using {score_col}..."),
                  verbose = verbose,
                  output = "message")

    # Build tensor from scores dict
    tensor <- c2c$tensor$dataframes_to_tensor(context_df_dict = context_df_dict,
                                              sender_col = sender_col,
                                              receiver_col = receiver_col,
                                              ligand_col = ligand_col,
                                              receptor_col = receptor_col,
                                              score_col = score_col,
                                              how = how,
                                              lr_fill = lr_fill,
                                              cell_fill = cell_fill,
                                              lr_sep = lr_sep,
                                              context_order = context_order,
                                              order_labels = list('contexts',
                                                                  'interactions',
                                                                  'senders',
                                                                  'receivers'),
                                              sort_elements = sort_elements,
                                              device = device
                                              )

    if(build_only) return(tensor)

    elbow_metric_raw <- NULL

    # estimate factor rank
    if(is.null(rank)){
        liana_message(str_glue("Estimating ranks..."),
                      verbose = verbose,
                      output = "message")
        py$temp <- tensor$elbow_rank_selection(upper_rank=as.integer(upper_rank),
                                               runs=as.integer(runs),
                                               init=init,
                                               automatic_elbow=TRUE,
                                               random_state=as.integer(seed))

        elbow_metric_raw <- tensor$elbow_metric_raw

        rank <- as.integer(tensor$rank)
    }


    # Compute tensor factorization
    liana_message(str_glue("Decomposing the tensor..."),
                  verbose = verbose,
                  output = "message")
    tensor$compute_tensor_factorization(rank = as.integer(rank),
                                        random_state=as.integer(seed),
                                        ...)

    if(factors_only){
        res <- format_c2c_factors(tensor$factors)

        if(!is.null(elbow_metric_raw)){
            res$elbow_metric_raw <- elbow_metric_raw
        }

    } else{
         res <- tensor
        }

    if(!inplace){
        return(res)
    } else{
        sce@metadata$tensor_res <- res
        return(sce)
    }
}


#' Helper function to format factors from c2c output
#'
#' @details The parameters here would correspond to `order_labels`
#'
#' @param factors factors returned from the
#' `cell2cell.tensor.compute_tensor_factorization` function
#'
#' @param contexts name for `contexts` dimension
#'
#' @param interactions name for `interactions` dimension
#'
#' @param senders name for `senders` dimension
#'
#' @param receivers name for `receivers` dimension
#'
#' @param key_sep separator for the sample and condition names. These are
#' used to jointly name the contexts - technically the names of the
#' `context_df_dict` list passed to the `liana_tensor_c2c` function.
#'
#' @noRd
#'
#' @keywords internal
#'
format_c2c_factors <- function(factors,
                               contexts="contexts",
                               interactions="interactions",
                               senders="senders",
                               receivers="receivers"){
    # Format contexts
    factors[[contexts]] %<>%
        set_tidy_names(syntactic = TRUE, quiet = TRUE) %>%
        as_tibble(rownames="context") %>%
        mutate(across(where(is.character), ~as.factor(.x)))

    # Format interactions
    factors[[interactions]] %<>%
        set_tidy_names(syntactic = TRUE, quiet = TRUE) %>%
        as_tibble(rownames="lr") %>%
        arrange(lr) %>%
        mutate(lr = factor(lr, lr))

    # Format senders
    factors[[senders]] %<>%
        set_tidy_names(syntactic = TRUE, quiet = TRUE) %>%
        as_tibble(rownames="celltype") %>%
        mutate(celltype=factor(celltype, celltype))

    # Format receivers
    factors[[receivers]] %<>%
        set_tidy_names(syntactic = TRUE, quiet = TRUE) %>%
        as_tibble(rownames="celltype") %>%
        mutate(celltype=factor(celltype, celltype))

    return(factors)
}


#' Returns tensor cell2cell results
#' @param sce SingleCellExperiment with factors output from tensor-cell2cell
#' @param group_col context descriptor - to be obtained from `colData(sce)`
#' @param sample_col context/sample names - obtained from `colData(sce)`
#'
#' @export
get_c2c_factors <- function(sce, group_col=NULL, sample_col){
    factors <- sce@metadata$tensor_res

    if(is.null(group_col)) return(factors)

    factors$contexts <- .join_meta(sce,
                                   factors$contexts,
                                   sample_col = sample_col,
                                   group_col = group_col,
                                   .left_col="context")
    return(factors)

}


#' Function to plot an Overview of tensor-c2c results
#'
#' @param sce SingleCellExperiment with factors output from tensor-cell2cell
#' @inheritParams get_c2c_factors
#'
#' @export
#'
plot_c2c_overview <- function(sce, group_col, sample_col){

    factors <- get_c2c_factors(sce, group_col, sample_col)

    # Contexts
    contexts <- factors$contexts %>%
        pivot_longer(cols = -c("context", group_col),
                     names_to = "factor", values_to = "loadings"
        ) %>%
        ggplot(aes(x=context, y=loadings, fill=.data[[group_col]])) +
        geom_bar(stat="identity") +
        facet_grid(factor ~ .) +
        theme_bw(base_size = 14) +
        theme(axis.title.x=element_blank(),
              axis.text.x=element_blank(),
              axis.ticks.x=element_blank(),
              strip.text.y = element_blank(),
              plot.title = element_text(hjust = 0.5)) +
        ggtitle('Contexts') +
        ylab(NULL)

    # lr
    lr <- factors$interactions %>%
        pivot_longer(-lr, names_to = "factor", values_to = "loadings") %>%
        ggplot(aes(x=lr, y=loadings)) +
        geom_bar(stat="identity") +
        facet_grid(factor ~ .) +
        theme_bw(base_size = 14) +
        theme(axis.title.x=element_blank(),
              axis.text.x=element_blank(),
              axis.ticks.x=element_blank(),
              strip.background = element_blank(),
              strip.text.y = element_blank(),
              plot.title = element_text(hjust = 0.5)) +
        ggtitle('Interactions') +
        ylab(NULL)


    # Sender cells
    senders <- factors$senders %>%
        pivot_longer(cols = -celltype,
                     names_to = "factor", values_to = "loadings"
        ) %>%
        ggplot(aes(x=celltype, y=loadings,
                   fill=celltype)) +
        geom_bar(stat="identity") +
        facet_grid(factor ~ .) +
        theme_bw(base_size = 14) +
        theme(axis.title.x=element_blank(),
              axis.text.x=element_blank(),
              axis.ticks.x=element_blank(),
              strip.background = element_blank(),
              strip.text.y = element_blank(),
              plot.title = element_text(hjust = 0.5)) +
        ylab(NULL) +
        ggtitle('Senders')

    # Receiver cells
    receivers <- factors$receivers %>%
        pivot_longer(cols = -celltype,
                     names_to = "factor", values_to = "loadings"
        ) %>%
        ggplot(aes(x=celltype, y=loadings,
                   fill=celltype)) +
        geom_bar(stat="identity") +
        facet_grid(factor ~ .) +
        theme_bw(base_size = 14) +
        theme(axis.title.x=element_blank(),
              axis.text.x=element_blank(),
              strip.background = element_blank(),
              axis.ticks.x=element_blank(),
              strip.text.y = element_text(size=15, face = "bold"),
              plot.title = element_text(hjust = 0.5)) +
        ylab(NULL) +
        ggtitle('Receivers')

    # Assemble overview plot
    overview <- patchwork::wrap_plots(list(contexts,
                                           lr,
                                           senders,
                                           receivers
    ),
    ncol=4,
    nrow(1)) +
        patchwork::plot_layout(guides = "collect")

    grid::grid.draw(overview)
}


#' @title Generate boxplots with significance
#'
#' @param sce SingleCellExperiment with factors output from tensor-cell2cell
#' @inheritParams get_c2c_factors
#'
#' @param ... arguments passed to the test used.
#'
#' @export
plot_context_boxplot <- function(sce,
                                 sample_col,
                                 group_col,
                                 test="t.test",
                                 ...){

    factors <- get_c2c_factors(sce,
                               sample_col=sample_col,
                               group_col=group_col)

    ### Alternative
    contexts_data <- factors$contexts %>%
        select(!!all_of(group_col), starts_with("Factor")) %>%
        pivot_longer(-group_col,
                     names_to = "fact",
                     values_to = "loadings") %>%
        mutate(fact = as.factor(fact)) %>%
        group_by(fact) %>%
        group_nest(keep = TRUE) %>%
        mutate(test = map(data,
                            function(.x) broom::tidy(
                                exec(test,
                                     formula=loadings~.x[[group_col]],
                                     data=.x,
                                     ...
                                     ))
                            )
               ) %>%
        unnest(test) %>%
        mutate(p.adj = p.adjust(p.value, method = "fdr")) %>%
        mutate(across(where(is.numeric), ~round(.x, digits = 4)))

    all_facts_boxes <- pmap(contexts_data, function(data=data,
                                                    p.adj=p.adj,
                                                    fact=fact,
                                                    ...){
        data %>%
        ggplot(aes(x=.data[[group_col]], y=loadings, color=.data[[group_col]])) +
            geom_boxplot() +
            theme_minimal() +
            ggtitle(fact, str_glue("{str_to_title(test)}, adj.p = {p.adj}"))
    })

    return(all_facts_boxes)

}

#' @title Plot a Heatmap of context loadings
#'
#' @inheritParams plot_context_boxplot
#' @inheritDotParams ComplexHeatmap::Heatmap
#'
#' @returns a ComplexHeatmap object
#'
#' @export
plot_context_heat <- function(sce,
                              sample_col,
                              group_col,
                              ...){

    factors <- get_c2c_factors(sce,
                               sample_col = sample_col,
                               group_col = group_col)

    # Samples dictionary
    meta_dict <- factors$contexts %>%
        select(context, !!group_col) %>%
        deframe()

    contexts_mat <- factors$contexts %>%
        column_to_rownames("context") %>%
        select(starts_with("Factor")) %>%
        t()

    contexts_mat %>%
        ComplexHeatmap::Heatmap(
            top_annotation = ComplexHeatmap::HeatmapAnnotation(
                condition = stringr::str_to_title(meta_dict),
                show_annotation_name = FALSE,
                simple_anno_size = grid::unit(0.3, "cm")
                ),
            name = "Context\nloadings",
            ...)

}


#' Function to plot a UMAP of context loadings
#'
#' @inheritParams plot_context_heat
#' @inheritParams dplyr::top_n
#'
#' @inheritDotParams ComplexHeatmap::Heatmap
#'
#' @returns a ComplexHeatmap object
#'
#' @export
#'
plot_lr_heatmap <- function(sce,
                            lr_sep="^",
                            n = 5,
                            ...){

    factors <- get_c2c_factors(sce)

    # Top n Interactions per factor heatmap
    top_lrs <- factors$interactions %>%
        pivot_longer(-lr,
                     names_to = "fact",
                     values_to = "loadings") %>%
        group_by(fact) %>%
        top_n(wt=loadings, n=n) %>%
        pull(lr)

    lrs_mat <- factors$interactions %>%
        filter(lr %in% top_lrs) %>%
        mutate(lr = gsub(as.character(str_glue("\\{lr_sep}")),
                          " -> ", lr)) %>%
        as.data.frame() %>%
        column_to_rownames("lr") %>%
        as.matrix()

    lrs_mat %>%
        ComplexHeatmap::Heatmap(name = "Interaction\nLoadings",
                                ...)
}


#' Generate a geneset resource for each LR
#' @param sce SingleCellExperiment object with liana_tensor_c2c computed
#' @param resource resource with `source`, `target`, `weight` columns
#'
#' @export
#'
#' @returns a tibble in decoupleR format
generate_lr_geneset <- function(sce, resource, lr_sep="^"){

    # Take SingleCellExperiment object as param instead of lrs to avoid the conflict of declaring 'factors' as global variable
    factors <- get_c2c_factors(sce)
    lrs <- factors$interactions %>%
        separate(lr, sep=str_glue("\\{lr_sep}"), into=c("ligand", "receptor"))

    ligand_weights <- assign_lr_weights(lrs,
                                        resource = resource,
                                        entity = "ligand")
    receptor_weights <- assign_lr_weights(lrs,
                                          resource = resource,
                                          entity = "receptor")


    lrs <- lrs %>%
        select(ligand, receptor) %>%
        inner_join(ligand_weights, by="ligand") %>%
        inner_join(receptor_weights, by="receptor") %>%
        rowwise() %>%
        mutate(mor = .set_coh_mean(ligand_weight, receptor_weight,
                                   ligand_source, receptor_source)
        ) %>%
        na.omit() %>%
        dplyr::rename(set=ligand_source) %>%
        select(-receptor_source, -ligand_weight, -receptor_weight) %>%
        ungroup() %>%
        unite(col="lr", sep=lr_sep, ligand, receptor)

    return(lrs)
}




#' check for sign coherency
#' @noRd
#' @keywords internal
.sign_coh_mean <- function(vec){
    if(length(unique(sign(vec))) > 1){
        return(NA)
    } else {
        return(mean(vec))
    }
}

#' Check for sign and gene-set coherency
#' @noRd
#' @keywords internal
.set_coh_mean <- function(x, y, x_set, y_set){
    if(x_set!=y_set){
        return(NA)
    } else{
        weight = .sign_coh_mean(c(x, y))
    }
}


#' Function to calculate gini coefficients for source and target loadings
#'
#' @param loadings loadings for dimension of interest ('senders' or 'receivers')
#' formatted by `format_c2c_factors`
#'
#' @keywords internal
#'
#' @export
calculate_gini <- function(loadings){

    loadings %>%
        set_tidy_names() %>%
        as_tibble(rownames="celltype",
                  .name_repair = ~ vctrs::vec_as_names(...,
                                                       repair = "universal",
                                                       quiet = TRUE)) %>%
        pivot_longer(-celltype, names_to = "factor", values_to = "loadings") %>%
        group_by(factor) %>%
        summarise(gini = .gini(loadings))
}


#' Plot the product of loadings between the source and target loadings
#' within a factor
#'
#' @param factors factors as formatted by `format_c2c_factors`
#'
#' @param factor_of_int factor of interest e.g. Factor.8
#'
#' @inheritDotParams ComplexHeatmap::Heatmap
#'
#' @export
plot_c2c_cells <- function(sce,
                           factor_of_int,
                           ...){
    factors <- get_c2c_factors(sce)

    sender <- factors$senders %>%
        select(celltype, sender_loadings = !!factor_of_int)

    receiver <- factors$receivers %>%
        select(celltype, receiver_loadings = !!factor_of_int)

    comm <- expand_grid(sender = sender$celltype,
                        receiver = receiver$celltype) %>%
        left_join(sender, by=c("sender"="celltype")) %>%
        left_join(receiver, by=c("receiver"="celltype")) %>%
        mutate(loadings = sender_loadings * receiver_loadings)

    commat <- comm %>%
        select(sender, receiver, loadings) %>%
        pivot_wider(id_cols = sender,
                    names_from = receiver,
                    values_from = loadings) %>%
        as.data.frame() %>%
        column_to_rownames("sender") %>%
        as.matrix()

    commat %>%
        ComplexHeatmap::Heatmap(row_title = "Sender",
                                row_names_side = "left",
                                column_title = "Receiver",
                                ...)
}

#' Gini Coefficient Estimate
#' @param x vector
#'
#' @details adapted from DescTools::Gini
#' @noRd
.gini <- function(x){
    if (any(is.na(x)) || any(x < 0)) return(NA_real_)

    n <- length(x)
    x <- sort(x)

    res <- 2 * sum(x * 1:n) / (n*sum(x)) - 1 - (1/n)
    res <- n / (n - 1) * res

    return(max(0, res))
}


#' Helper function to deal with tensor sparsity and liana's scores as in Python
#' @inheritParams liana_tensor_c2c
#' @param lr_sep ligand-receptor separator; `^` by default.
#' @param invert boolean wheter to invert the score (TRUE by defeault)
#' @param invert_fun function used to invert scores
#' @param non_negative whether to set negative scores to 0
#' @param non_negative_fill the value to be used to fill negative values
#' @param outer_fraction controls the elements to include in the union scenario of the `how` options.
#' Only elements that are present at least in this fraction of samples/contexts will be included.
#' When this value is 0, considers all elements across the samples. When this value is 1, it acts as using `how='inner'`
preprocess_scores <- function(context_df_dict,
                              score_col = "magnitude_rank",
                              sender_col = "source",
                              receiver_col = "target",
                              ligand_col = "ligand.complex",
                              receptor_col = "receptor.complex",
                              outer_fraction = 0,
                              invert = TRUE,
                              invert_fun = function(x) 1 - x,
                              non_negative = TRUE,
                              non_negative_fill = 0,
                              lr_sep = '^',
                              verbose=TRUE
                              ){

    if(!score_col %in% colnames(context_df_dict[[1]])){
        stop(str_glue("{score_col} does not exist!"))
    }

    source.cells <- map(context_df_dict, function(sample) unique(sample[[sender_col]]))
    target.cells <- map(context_df_dict, function(sample) unique(sample[[receiver_col]]))

    all.cells.persample <- sapply(names(source.cells),
                                  function(sample.name) union(source.cells[[sample.name]],
                                                              target.cells[[sample.name]]))

    all.cells <- Reduce(union, unname(unlist(all.cells.persample)))

    cell.counts.persample <- sapply(all.cells,
                                    function(ct) length(which(sapply(all.cells.persample,
                                                                     function(x) ct %in% x))
                                                        ))
    cells.todrop <- names(which(cell.counts.persample < (outer_fraction*length(context_df_dict))))


    lrs.persample <- map(context_df_dict, function(sample){
        paste(sample[[ligand_col]], sample[[receptor_col]], sep = lr_sep)
    } )
    all.lrs <- Reduce(union, unname(unlist(lrs.persample)))
    lr.counts.persample <- sapply(all.lrs, function (lr) length(which(sapply(lrs.persample, function(x) lr %in% x))))
    lrs.todrop <- names(which(lr.counts.persample < (outer_fraction*length(context_df_dict))))

    context_df_dict <- map(names(context_df_dict), function(sample.name){
        ccc.sample <- context_df_dict[[sample.name]]

        if(invert){ # invert score
            liana_message(str_glue("Inverting `{score_col}`!"),
                          verbose = verbose,
                          output = "message")

            ccc.sample %<>%
                mutate({{ score_col }} := invert_fun(.data[[score_col]]))
        }

        if(non_negative){ # make non-negative
            ccc.sample[[score_col]][ccc.sample[[score_col]] < 0] <- non_negative_fill
        }

        # apply the outer_frac parameter
        ccc.sample <- ccc.sample[(!(ccc.sample[[sender_col]] %in% cells.todrop)) &
                                     (!(ccc.sample[[receiver_col]] %in% cells.todrop)), ]

        ccc.sample <- ccc.sample[!(paste(ccc.sample[[ligand_col]], ccc.sample[[receptor_col]],
                                       sep = lr_sep) %in% lrs.todrop), ]
        return(ccc.sample)

    }) %>%
        setNames(names(context_df_dict))

    return(context_df_dict)
}

#' Wrapper function to run `cell2cell_tensor` decomposition on a prebuilt tensor.
#'
#' @inheritParams liana_tensor_c2c
#'
#' @param tensor Tensor-cell2cell Prebuilt.Tensor class instance
#' @param tf_optimization indicates whether running the analysis in the
#' `'regular'` or the `'robust'` way. The regular way means that the
#' tensor decomposition is run 10 times per rank evaluated in the elbow analysis,
#' and 1 time in the final decomposition. Additionally,
#' the optimization algorithm has less number of iterations in the regular than the
#' robust case (100 vs 500) and less precision (tolerance of 1e-7 vs 1e-8).
#' The robust case runs the tensor decomposition 20 times per rank evaluated in the elbow analysis,
#' and 100 times in the final decomposition. Here we could use the `tf_optimization='regular'`,
#' which is faster but generates less robust results. We recommend using `tf_optimization='robust`,
#' which takes longer to run (more iteractions and more precise too).
#'
#' @param ... Dictionary containing keyword arguments for the c2c.compute_tensor_factorization function.
#' The function deals with `random_state` (seed) and `rank` internally.
#'
#' @returns an instance of the cell2cell.tensor.BaseTensor class (via reticulate).
#' If build_only is TRUE, then no rank selection or tensor decomposition is returned.
#' Otherwise, returns a tensor with factorization results.
#'
#' @export
#'
decompose_tensor <- function(tensor,
                             rank=NULL,
                             tf_optimization = 'robust',
                             seed = 1337,
                             upper_rank = 25,
                             elbow_metric = 'error',
                             smooth_elbow = FALSE,
                             init = 'svd',
                             svd = 'numpy_svd',
                             factors_only = TRUE,
                             verbose = TRUE,
                             ...){

    # Deal with rank
    rank <- if(is.null(rank)){ NULL } else {as.integer(rank)}

    reticulate::py_set_seed(seed)

    if (tf_optimization == 'robust'){
        elbow_runs = 20
        tf_runs = 100
        tol = 1e-8
        n_iter_max = 500
    }else if (tf_optimization == 'regular'){
        elbow_runs = 10
        tf_runs = 1
        tol = 1e-7
        n_iter_max = 100
    }

    # estimate factor rank
    elbow_metric_raw <- NULL
    if(is.null(rank)){
        liana_message(str_glue("Estimating ranks..."),
                      verbose = verbose,
                      output = "message")
        py$temp <- tensor$elbow_rank_selection(upper_rank=as.integer(upper_rank),
                                               init=init,
                                               svd=svd,
                                               automatic_elbow=TRUE,
                                               metric=elbow_metric,
                                               smooth=smooth_elbow,
                                               runs=as.integer(elbow_runs),
                                               n_iter_max=as.integer(n_iter_max),
                                               tol = as.numeric(tol),
                                               random_state=as.integer(seed))

        elbow_metric_raw <- tensor$elbow_metric_raw

        rank <- as.integer(tensor$rank)
    }

    # Compute tensor factorization
    liana_message(str_glue("Decomposing the tensor..."),
                  verbose = verbose,
                  output = "message")
    tensor$compute_tensor_factorization(rank = as.integer(rank),
                                        init = init,
                                        svd=svd,
                                        runs=as.integer(tf_runs),
                                        tol = as.numeric(tol),
                                        n_iter_max=as.integer(n_iter_max),
                                        random_state=as.integer(seed),
                                        normalize_loadings=TRUE,
                                        ...)

    if(factors_only){
        res <- format_c2c_factors(tensor$factors)

        if(!is.null(elbow_metric_raw)){
            res$elbow_metric_raw <- elbow_metric_raw
        }

    } else{
        res <- tensor
    }

    return(res)
}


# Env vars ----
.lianapy_packages <- c("python==3.8.8",
                       "pandas==1.4.2",
                       "rpy2==3.4.5")

.liana_pips <- c("cell2cell==0.6.8",
                 "anndata2ri==1.0.6")
  contents: read

jobs: #' Wrapper around `liana_wrap` to run liana for each sample.
#'
#' @param idents_col name of the cluster column
#'
#' @param sample_col name of the sample/context column
#'
#' @param verbose verbosity logical
#'
#' @param inplace logical (TRUE by default) if liana results are to be saved
#'  to the SingleCellExperiment object (`sce@metadata$liana_res`)
#'
#' @param aggregate_how if running multiple methods (default), then one cal
#' also choose to aggregate the CCC results by sample.
#'
#' @details takes a Seurat/SCE object and runs LIANA by sample/condition. The
#' key by which the samples are separated is build from the `condition_col` and
#' `sample_col`, separated by the `key_sep`.
#'
#' @inheritDotParams liana_wrap
#'
#' @export
#'
#' @returns If inplace is true returns a sce object with `liana_res` in
#' `sce@metadata`, else it returns a named list of tibble with liana results
#' per sample.
#'
liana_bysample <- function(sce,
                           idents_col,
                           sample_col,
                           verbose = TRUE,
                           inplace=TRUE,
                           aggregate_how=NULL,
                           ...){

    if(!is.factor(colData(sce)[[sample_col]])){
            liana_message(
                str_glue(
                    "`{sample_col}` was converted to a factor!"
                ), output = "message",
                verbose = verbose)
        }
    sce[[sample_col]] <- as.factor(sce[[sample_col]])

    if (!is.null(aggregate_how)){
        if(!(aggregate_how %in% c("both", "magnitude", "specificity"))){
            stop("Invalid `aggregate_how` parameter")
        }
    }

    # Map over key col
    liana_res <- map(levels(sce[[sample_col]]),
                     function(sample){

                         liana_message(str_glue("Current sample: {sample}"),
                                       output = "message",
                                       verbose = verbose)
                         # Subset to current sample
                         sce_temp <- sce[, sce[[sample_col]]==sample]

                         # Set cluster
                         colLabels(sce_temp) <- sce_temp[[idents_col]]

                         # Run LIANA on each
                         lr <- liana_wrap(sce=sce_temp, verbose = verbose, ...)

                         if(!is.null(aggregate_how)){
                             if(aggregate_how!="both"){
                                 lr <- lr %>%
                                     liana_aggregate(aggregate_how=aggregate_how,
                                                     verbose = verbose)
                             } else{
                                 lr <- lr %>%
                                     rank_aggregate(verbose = verbose)
                             }
                         }

                         return(lr)

                     }) %>%
        setNames(levels(sce[[sample_col]]))

    if(!inplace){
        return(liana_res)
    } else{
        sce@metadata$liana_res <- liana_res
        return(sce)
    }
}

#' Join sample descriptor column from SCE to another table
#' @param sce SingleCellExperiment
#' @param left (df) to join to colData per sample
#' @param sample_col unique identifier column from colData
#' @param group_col sample_col descriptor column
#' @param .left_col The columns by which we map `sample_col` if NULL, its set to
#' the same as `sample_col`.
#'
#' @noRd
.join_meta <- function(sce, left, sample_col, group_col, .left_col=NULL){

    if(is.null(.left_col)){
        .left_col <- sample_col
    }

    meta <- colData(sce) %>%
        as_tibble() %>%
        dplyr::select(!!sample_col, !!group_col) %>%
        distinct() %>%
        mutate( {{ group_col }} := as.factor(.data[[group_col]]))

    by <- sample_col
    names(by) <- .left_col

    left_join(left, meta, by=by)
}


#' Helper function to assign weights
#' @param lrs ligand_receptor tibble
#' @param resource resource
#' @param entity name of the entity
#'
#' @export
assign_lr_weights <- function(lrs,
                              resource,
                              entity="ligand"){

    entity_weight <- str_glue("{entity}_weight")
    entity_source <- str_glue("{entity}_source")

    entity_df <- lrs %>%
        pull(entity) %>%
        enframe(value="entity") %>%
        select(entity) %>%
        distinct() %>%
        liana::decomplexify("entity")

    entity_weights <- entity_df %>%
        left_join(resource, by = c("entity"="target")) %>%
        group_by(source, entity_complex) %>%
        # count number of subunits
        mutate(n_found = n()) %>%
        # count number of expected subunits x_y = 1 (+ 1)
        mutate(n_expected = str_count(entity_complex, "_") + 1) %>%
        filter(n_found==n_expected) %>%
        # only keep subunits which are sign-consistent
        summarise(weight = .sign_coh_mean(weight), .groups = "keep") %>%
        na.omit() %>%
        ungroup() %>%
        select({{ entity }} := entity_complex,
               {{ entity_source }} := source,
               {{ entity_weight }} := weight
        )


    return(entity_weights)
}


#' Filter nun-abundant cell types
#'
#' @inheritParams get_abundance_summary
#' @inheritParams plot_abundance_summary
#'
#' @export
#'
#' @return a filtered SingleCellExperiment Object
filter_nonabundant_celltypes <- function(sce,
                                         sample_col,
                                         idents_col,
                                         min_cells = 10,
                                         min_samples = 3,
                                         min_prop = 0.2,
                                         ctqc = NULL){

    # Calculate QC
    if(is.null(ctqc)){
        ctqc <- get_abundance_summary(sce,
                                      sample_col,
                                      idents_col,
                                      min_cells = min_cells,
                                      min_samples = min_samples,
                                      min_prop = min_prop
        )
    }

    plot_abundance_summary(ctqc)

    # Filter lowly-abundant celltypes from each sample
    keep_abundant <- ctqc %>%
        select(sample_col, idents_col, keep_min, keep_celltype) %>%
        filter(keep_min & keep_celltype) %>%
        ungroup()
    keep_abundant <- colData(sce) %>%
        as_tibble(rownames = "barcode") %>%
        select(barcode, sample_col = sample_col,idents_col = idents_col) %>%
        inner_join(keep_abundant, by = c("sample_col", "idents_col")) %>%
        pull(barcode)
    # Remove those cells which belong to cells not shared in enough samples
    sce <- sce[, keep_abundant]

    return(sce)
}


#' Function to get abundance summary
#'
#' @param sce SingleCellExperiment Object
#' @param sample_col column with sample ids
#' @param idents_col column with cell identity (cell type) ids
#' @param min_cells minimum cells per identity in each sample
#' @param min_samples minimum samples per cell identity
#' @param min_prop minimum proportion of samples in which a cell identity is
#' present (with at least `min_cells`)
#'
#' @returns a tibble
#'
#' @export
#'
#' @keywords internal
get_abundance_summary <- function(sce,
                                  sample_col,
                                  idents_col,
                                  min_cells = 10,
                                  min_samples = 3,
                                  min_prop = 0.2){
    colData(sce) %>%
        as_tibble() %>%
        dplyr::rename(sample_col = sample_col,
                      idents_col = idents_col) %>%
        # sample n
        mutate(sample_n = length(unique(sample_col))) %>%
        group_by(sample_col, idents_col) %>%
        # cells ct x sample
        mutate(cell_n = n()) %>%
        distinct_at(.vars = c("sample_col",
                              "sample_n",
                              "idents_col",
                              "cell_n")) %>%
        # keep cell type or not (per sample)
        mutate(keep_min = cell_n >= min_cells) %>%
        mutate(min_cells = min_cells) %>%
        ungroup() %>%
        # Keep celltype? (acc to minimum numbers across at least x samples
        # and at least x prop of the samples)
        group_by(idents_col) %>%
        mutate(keep_sum = sum(keep_min)) %>%
        mutate(sample_prop = keep_sum/sample_n) %>%
        mutate(keep_celltype = if_else((keep_sum >= min_samples) &
                                           (sample_prop >= min_prop),
                                       TRUE,
                                       FALSE)) %>%
        ungroup()
}

#' Function to Plot Abundance Summary
#'
#' @param ctqc cell type quality control summary obtained from
#' `get_abundance_summary`
#'
#' @param ncol number of columns for the facet wrap
#'
#' @return a ggplot2 object
#'
#' @export
#'
#' @keywords internal
plot_abundance_summary <- function(ctqc, ncol = 3){
    ctqc %>%
        ggplot(aes(x=sample_col, y=log10(cell_n), fill=keep_min)) +
        geom_bar(stat="identity", width=0.5) +
        scale_fill_manual(values = c('TRUE' = 'blue', 'FALSE' = 'red'),
                          guide="none") +
        geom_hline(yintercept = log10(unique(ctqc[["min_cells"]])),
                   linetype="dashed") +
        geom_text(
            mapping = aes(x = -Inf,
                          y = Inf,
                          label = str_glue("Prevalence: ",
                                           "{round(sample_prop, digits = 3)} ",
                                           "(N = {keep_sum})"),
                          color=keep_celltype),
            vjust=1.5, hjust=-0.1
        ) +
        scale_color_manual(values = c('TRUE' = 'black', 'FALSE' = 'red'),
                           guide="none") +
        facet_wrap(idents_col ~ ., ncol = ncol) +
        theme_bw() +
        theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
}

  build: #' LIANA wrapper function
#'
#' @param sce `SingleCellExperiment` object or `SeuratObject`
#'
#' @param method method(s) to be run via liana
#'
#' @param resource resource(s) to be used by the methods (`Consensus` by default), Use `all` to run all `human` resources in one go),
#'   or `custom` to run liana_wrap with an appropriately formatted custom resource, passed via `exernal_resource`
#'
#' @param idents_col the cell identities/labels to be used. By default set to NULL, and will used the active
#' Idents or colLabels from the seurat_object or SCE, respectively.
#'
#' @param external_resource external resource in OmniPath tibble format
#'
#' @param min_cells minimum cell per cell identity to be considered for analysis
#'
#' @param return_all whether to return all possible interactions. Any
#' interaction with `expr_prop` below the specific threshold will be
#' assigned to the *worst* possible score in those that pass the threshold.
#'  For example, p-values from CellPhoneDB will be assigned to max(pvalue)
#'   - likely 1, and lr_means will be assigned to min(lr_means).
#'  Note that this applies only to the internal methods of liana.
#'
#' @param supp_columns any supplementary/additional columns which are to be
#' returned by liana. Possibilities include: c("ligand.expr", "receptor.expr"
#' "ligand.stat", "receptor.stat", "ligand.pval", "receptor.pval",
#' "ligand.FDR", "receptor.FDR", etc)
#'
#' @param verbose logical whether to output messages and warnings (`TRUE` by default)
#'
#' @param assay assay to be used by Seurat, by default set to `NULL` and will use the DefaultAssay.
#'
#' @param .simplify if methods are run with only 1 resource, return a list
#'   of tibbles for each method (default), rather than a list of lists with
#'   method-resource combinations
#' @param base Default to NULL (i.e. log2-transformation is assumed
#'  for SCE, and log-tranformation for Seurat). This is a requred step for the
#'  calculation of the logFC method - ensures that any other preprocessing of
#'  the counts is preserved. One could also pass `NaN` if they wish to use the
#'  counts stored in the counts assay/slot, or any other number according to the
#'  base that was used for log-tranformation.
#'
#' @inheritDotParams liana_defaults
#' @inheritParams liana_pipe
#'
#' @import tibble
#' @importFrom magrittr %<>% %>%
#' @importFrom purrr map map2 safely compact
#'
#' @returns A list of method-resource results - i.e. provided resources are run
#' with each method
#' If only one resource is selected, a single tibble (with results for that
#'  resource) will be returned for each of the selected methods
#'
#' @details LIANA wrapper method that can be used to call each method with
#'  a given set of intercellular resources from the OmniPath universe.
#'  Please see `liana_defaults()` for more information about the
#'  default parameters passed used by `liana_wrap`, if you wish to modify them.
#'
#'
#' @export
#'
#' @examples
#' liana_path <- system.file(package = "liana")
#' # load testdata
#' testdata <- readRDS(file.path(liana_path , "testdata", "input", "testdata.rds"))
#' # run only 2 methods from liana
#' liana_res <- liana_wrap(testdata, method = c('cellphonedb', 'sca'),
#'                         resource = 'Consensus', # default resource
#'                         # example run with *only* 2 permutations for cpdb
#'                         permutation.params = list(nperms = 2))
liana_wrap <- function(sce,
                       method = c('natmi', 'connectome', 'logfc',
                                  'sca', 'cellphonedb'),
                       resource = c('Consensus'),
                       idents_col = NULL,
                       external_resource,
                       min_cells = 5,
                       return_all = FALSE,
                       supp_columns=NULL,
                       verbose = TRUE,
                       assay = NULL,
                       .simplify = TRUE,
                       cell.adj = NULL,
                       base = NULL,
                       ...){

  # Handle object
  sce <- liana_prep(sce,
                    idents_col = idents_col,
                    assay = assay,
                    min_cells = min_cells,
                    verbose = verbose)
  # If base is not passed use default base of Seurat or SingleCellExperiment
  base %<>% `%||%` (sce@int_metadata$base)

  # method to lower
  method %<>% stringr::str_to_lower()

  if(resource!='custom' & length(setdiff(resource, c(show_resources(), "all"))) > 0){
    stop(str_glue("{setdiff(resource, show_resources())} not part of LIANA "))
    }

  if(resource!='custom'){
    resource %<>% select_resource # if null OmniPath
  } else{
    resource = list('custom_resource' = external_resource)
  }

  # Check if any method is internal (i.e. call liana_pipe)
  if(any(map_lgl(method, function(m) !str_detect(m, "call_")))){

    # LIANA pipe map over resource
    lr_results <- resource %>%
      map(function(reso){

        if(is.null(reso)){
          liana_message("Resource was NULL and LIANA's internal methods were run with the `Consensus` resource",
                        verbose = verbose,
                        output = "warning")
          reso <- select_resource("Consensus")[[1]]
        }

        rlang::invoke(liana_pipe,
                      append(
                        list("sce" = sce,
                             "op_resource" =  decomplexify(reso),
                             verbose = verbose,
                             cell.adj = cell.adj,
                             base = base),
                        liana_defaults(...)[["liana_pipe"]]
                        )
                      )
        }) %>%
      setNames(names(resource))
  }

  .select_method(method) %>%
    map2(names(.),
         safely(function(.method, method_name){
           liana_message(str_glue("Now Running: {stringr::str_to_title(method_name)}"),
                         verbose = verbose)

           map2(resource, names(resource), function(reso, reso_name){
             if(method_name %in% c("call_squidpy", "call_cellchat")){
               # external calls (for complex-informed methods)
               args <- append(
                 list("sce" = sce,
                      "op_resource" = reso),
                 liana_defaults(...)[[method_name]]
                 )
               rlang::invoke(.method, args)

             } else if(method_name %in% c("call_connectome", "call_sca",
                                          "call_natmi", "call_italk")){
               # external calls (for methods which don't deal with complexes)
               args <- append(
                 list(sce = sce,
                      "op_resource" = reso %>% {if (!is.null(reso)) decomplexify(.) else .}),
                 liana_defaults(...)[[method_name]]
               )
               rlang::invoke(.method, args)

             } else if(method_name == "cellphonedb"){
               # get lr_res for this specific resource
               lr_res <- .filt_liana_pipe(lr_results[[reso_name]],
                                          method_name,
                                          return_all=return_all,
                                          ...)

               # permutation-based approaches
               perm_means <-
                 rlang::invoke(
                   get_permutations,
                   append(
                     list(lr_res = lr_res,
                          sce = sce,
                          verbose = verbose
                          ),
                     liana_defaults(...)[["permutation"]]
                     ))

               args <- pmap( # append multiple lists
                 list(
                   list(
                     list(lr_res = lr_res,
                          perm_means = perm_means,
                          verbose = verbose,
                          return_all = return_all,
                          supp_columns = supp_columns),
                     liana_defaults(...)[[method_name]],
                     liana_defaults(...)[["liana_call"]],
                     return_all = return_all
                     )
                   ), c) %>%
                 flatten

               rlang::invoke(.method, args)

             } else if(method_name == "cytotalk"){
               lr_res <- .filt_liana_pipe(lr_results[[reso_name]],
                                          method_name,
                                          return_all=return_all,
                                          ...)

               args <- pmap( # append multiple lists
                 list(
                   list(
                     list(
                       lr_res = lr_res,
                       sce = sce,
                       return_all = return_all,
                       supp_columns = supp_columns
                     ),
                     liana_defaults(...)[[method_name]],
                     liana_defaults(...)[["liana_call"]]
                     )
                 ), c) %>%
                 flatten

               rlang::invoke(.method, args)

            } else {
              # re-implemented non-permutation approaches
              args <- append(
                list(
                  "sce" = sce,
                  lr_res = .filt_liana_pipe(lr_results[[reso_name]],
                                            method_name,
                                            return_all=return_all,
                                            ...),
                  return_all = return_all,
                  supp_columns = supp_columns
                  ),
                liana_defaults(...)[["liana_call"]]
                )
              rlang::invoke(.method, args)
              }
             })
           }, quiet = FALSE)) %>%
    # format errors
    {
      `if`(.simplify,
           map(., function(elem)
             .list2tib(.list2tib(compact(elem)))),
           .)
    } %>% .list2tib()
}


#' Helper Function to Handle resource choices
#'
#' @param resource names of the resources. Passing `all` will return all
#' human resources (i.e. all resources, except MouseConsensus)
#'
#' @details This function simply reads omni_resources.rds and returns the resources.
#'    Any of the resources can also be obtained via the same file.
#'    or the `compile_ligrec` function, which querries and assmelbes the
#'    resources via `OmniPathR`.
#'
#'    `Default` - The Default (inbuilt) resource for each of the methods;
#'    if using the `call_*` functions, the default resource is used by
#'    passing *NULL* to the resource parameter.
#'    `Reshuffled` - a reshuffled (randomized control) version of ConnectomeDB
#'
#' @export
select_resource <- function(resource){
    omni_resources <-
        readRDS(system.file(package = 'liana', "omni_resources.rds"))

    if(tolower(resource)=="all"){
        omni_resources[show_resources()!="MouseConsensus"]
    } else{
        omni_resources[resource]
    }
}


#' Function to return the appropriate method(s) to be executed
#' @param method name of the method
#'
#' @return A list of method function names (to be called by the LIANA wrapper)
#'
#' @details Adapted from (jvelezmagic); [decoupleR](https://github.com/saezlab/decoupleR/)
#'
#' @noRd
.select_method <- function(method){
    available_method <-
        list(
            # liana_scores
            connectome = expr(get_connectome),
            logfc = expr(get_logfc),
            natmi = expr(get_natmi),
            sca = expr(get_sca),
            # liana_permutes
            cellphonedb = expr(get_cellphonedb),
            # cytotalk
            cytotalk = expr(get_cytotalk),
            # pipes (deprecated)
            call_squidpy = expr(call_squidpy),
            call_cellchat = expr(call_cellchat),
            call_sca = expr(call_sca),
            call_connectome = expr(call_connectome),
            call_natmi = expr(call_natmi),
            call_italk = expr(call_italk)

        )

    method %>%
        tolower() %>%
        match.arg(names(available_method), several.ok = TRUE) %>%
        available_method[.]
}




#' Helper Function to return the methods in LIANA
#'
#' @details methods starting with `call_*` were re-implemented in liana and
#'    albeit their original pipelines (and packages are still supported),
#'    we recommend using the liana re-implementations for efficiency
#'
#' @export
show_methods <- function(){
  names(.score_specs())
}

#' Helper Function to return the Resources in LIANA
#'
#' @export
show_resources <- function(){
    as.character(
      names(
        readRDS(
          system.file(
            package = 'liana', "omni_resources.rds"
            )
          )
        )
      )
}


#' Helper Function to  Handle list or not list method calls
#' @param res list of lists (e.g. Method-Resource Results from the LIANA pipe)
#' @param .x name of the element to pluck
#'
#' @return The first element of the list
#'
#' @noRd
.list2tib <- function(res, .x = NULL){
    if(length(res)==1){
        .x %<>% `%||%`(1)
        res %>% pluck(.x)
    } else if(is.character(.x)){
        res %>% pluck(.x)
    } else{ res }
}


#' Helper Function to do prop filtering of liana_pipe output
#' @param liana_res resutls from `liana_pipe`
#' @param method current method
#' @inheritDotParams liana_defaults
#'
#' @noRd
.filt_liana_pipe <- function(liana_res,
                             method,
                             return_all=FALSE,
                             ...){

  # Convert prop_filt logical to 0 or 1
  #  (step not required, but should be explicit)
  filt_or_not <- as.integer(liana_defaults(...)[[method]]$prop_filt)

  # set to value of expr_prop from defaults, or 0 if not to filter
  expr_prop <- liana_defaults(...)$expr_prop * filt_or_not

  if (!is.numeric(expr_prop) | expr_prop < 0 | expr_prop > 1) {
    stop("Expression Proportion should be a numeric value between 0 and 1")
  }

  if(expr_prop > 0){
    # If we filter missing subunits here, they are
    # then not aggregated in the method
    # hence we should filter the complexes, not the subunits
    non_expressed <- liana_res %>%
      group_by(ligand.complex, receptor.complex, source, target) %>%
      summarize(prop_min = min(ligand.prop, receptor.prop)) %>%
      filter(prop_min < expr_prop)

    if(!return_all){
      liana_res %>%
        anti_join(non_expressed, by=c("ligand.complex", "receptor.complex",
                                      "source", "target"))
    } else if(return_all){
      liana_res %>%
        mutate(to.filter = receptor.prop >= expr_prop &
                 ligand.prop >= expr_prop)
    }

  } else if(expr_prop == 0){
    liana_res
  } else{ # shouldn't happen (sanity check)
    stop("Expression Proportion is not a positive number")
  }

}
    runs-on: macos-latest
    strategy: #' Call NATMI Pipeline from R with Resources Querried from OmniPath [[DEPRECATED]]
#'
#' @param op_resource List of OmniPath resources
#' @param sce Seurat or SingleCellExperiment object
#' @param expr_file expression matrix file name
#' @param meta_file annotations (i.e. clusters) file name
#' @param output_dir NATMI output directory
#' @param .format bool whether to format output
#' @param .overwrite_data bool whether Extract and overwrite csv with
#'    data from Seurat Object
#' @param .natmi_path path of NATMI code and dbs (by default set to liana path)
#' @param assay Seurat assay to be used
#' @param reso_name name of the resource usually in the format list(name = op_resource)
#' @param num_cor number of cores to be used
#' @param conda_env name of the conda environment via which NATMI is called
#' @param assay.type logcounts by default, but it's converted back into counts
#' as suggested by the authors
#' @param .seed random seed
#' @param .delete_input_output logical whether to delete input and
#'  output after run.
#'
#'
#' @return DF with NATMI results
#'
#' @details
#'     This function will save NATMI dbs folder, then it will call the
#'     NATMI Python from the NATMI dir and save the output into a specified
#'     directory in NATMI's path.
#'     It will then load the csvs and format the output to a list of lists.
#'
#'     By default, NATMI's path is set to that of LIANA, but any alternative
#'     path can be passed
#'
#'==============================================================================
#' NATMI Arguments:
#'   --interDB INTERDB
#'                         lrc2p (default) has literature supported ligand-receptor pairs | lrc2a has putative and literature supported ligand-receptor pairs | the user-supplied interaction database can also be used by calling the name of database file without extension
#'   --interSpecies INTERSPECIES
#'                         human (default) | mouse | expandp | expanda
#'   --emFile EMFILE       the path to the normalised expression matrix file with row names (gene identifiers) and column names (cell-type/single-cell identifiers)
#'   --annFile ANNFILE     the path to the metafile in which column one has single-cell identifiers and column two has corresponding cluster IDs (see file 'toy.sc.ann.txt' as an example)
#'   --species SPECIES     human (default) | mouse | rat | zebrafish | fruitfly | chimpanzee | dog | monkey | cattle | chicken | frog | mosquito | nematode | thalecress | rice | riceblastfungus | bakeryeast | neurosporacrassa | fissionyeast | eremotheciumgossypii | kluyveromyceslactis, 21 species are supported
#'   --idType IDTYPE       symbol (default) | entrez(https://www.ncbi.nlm.nih.gov/gene) | ensembl(https://www.ensembl.org/) | uniprot(https://www.uniprot.org/) | hgnc(https://www.genenames.org/) | mgi(http://www.informatics.jax.org/mgihome/nomen/index.shtml) | custom(gene identifier used in the expression matrix)
#'   --coreNum CORENUM     the number of CPU cores used, default is one
#'   --out OUT             the path to save the analysis results
#' (Taken From NATMI's GitHub Page)
#'
#' Stats:
#' 1) The mean-expression edge weights
#' 2) The specificity-based edge weights
#' * a weight of 1 means both the ligand and receptor are only expressed
#'  in one cell type
#'
#' Note that `call_natmi` will write the expression matrix to CSV each time
#' its called, unless .overwrite_data is set to FALSE!
#' This can be an extremely time consuming step when working with large datasets
#'
#' Also, NATMI will sometimes create duplicate files, so please consider
#'  saving each run in a new folder. An easy fix would be to simply delete the
#'  output, but I am reluctant to automatically delete files via an R script.
#'
#'
#' @importFrom reticulate py_set_seed
#' @importFrom stringr str_glue
#' @importFrom SeuratObject GetAssayData Idents
#' @import dplyr reticulate
#'
#' @export
call_natmi <- function(
    sce,
    op_resource,
    expr_file = "em.csv",
    meta_file = "metadata.csv",
    output_dir = "NATMI_test",
    reso_name = "placeholder",
    assay = "RNA",
    num_cor = 4,
    conda_env = NULL,
    assay.type = "logcounts",
    .format = TRUE,
    .overwrite_data = TRUE,
    .seed = 1004,
    .natmi_path = NULL,
    .delete_input_output = FALSE){

    # Convert sce to seurat
    if(class(sce) == "SingleCellExperiment"){
        sce %<>% .liana_convert(., assay=assay)
    }

    # Get Reticulate path
    reticulate::use_condaenv(condaenv = conda_env %>% `%||%`("liana_env"),
                             conda = "auto",
                             required = TRUE)
    py$pd <- reticulate::import("pandas")
    python_path <- reticulate::py_discover_config()[[1]]
    reticulate::py_set_seed(.seed)

    .natmi_path %<>% `%||%`(system.file('NATMI/', package = 'liana'))
    .input_path = file.path(.natmi_path, 'data', 'input')
    .output_path = file.path(.natmi_path, 'data', 'output', output_dir)
    .csv_path = file.path(.input_path, expr_file)

    if(!dir.exists(file.path(.input_path))){
        print(str_glue("Input path created: {.input_path}"))
        dir.create(file.path(.input_path), recursive = TRUE)
    }

        print(str_glue("Output path created: {.output_path}"))
        dir.create(file.path(.output_path), recursive = TRUE)

    if(.overwrite_data || !file.exists(.csv_path)){
        print(str_glue("Writing EM to {.csv_path}"))
        if(assay.type=="counts"){
            write.csv(GetAssayData(object = sce,
                                   assay = "RNA",
                                   slot = "counts"),
                      file = .csv_path,
                      row.names = TRUE)
        } else{
            write.csv(100 * (exp(as.matrix(
                GetAssayData(object = sce,
                             assay = assay,
                             slot = "data"))) - 1),
                file = .csv_path,
                row.names = TRUE)
        }
    }

    print(str_glue("Writing Annotations to {.input_path}/{meta_file}"))
    write.csv(Idents(sce) %>%
                  enframe(name="barcode", value="annotation"),
              file = file.path(.input_path, meta_file),
              row.names = FALSE)

    print(str_glue("Saving resource to {.natmi_path}/lrdbs/{reso_name}"))
    # Deal with Default (i.e. NULL)
    if(is.null(op_resource)){
        reso_name <- "lrc2p"

    } else{
        # save resource to NATMI dir
        omni_to_NATMI(op_resource,
                      reso_name,
                      file.path(.natmi_path, "lrdbs"))
    }

    # submit native sys request
    system(str_glue("{python_path} {.natmi_path}/ExtractEdges.py ",
                    "--species human ",
                    "--emFile {.csv_path} ",
                    "--annFile {.input_path}/{meta_file} ",
                    "--interDB {.natmi_path}/lrdbs/{reso_name}.csv ",
                    "--coreNum {num_cor} ",
                    "--out {.output_path}/{reso_name}",
                    sep = " "))

    # load and format results
    natmi_results <- FormatNatmi(.output_path, reso_name, .format)

    if(.delete_input_output){
        system(str_glue("rm -r {.output_path}/{reso_name}"))
        system(str_glue("rm -r {.input_path}/"))
    }


    return(natmi_results)
}



#' Reform OmniPath Resource to NATMI format and save to location
#'
#' @param op_resource Resource formatted as OmniPath
#' @param reso_name name of the resource
#' @param natmi_db_path directory in which to save the resource
#'
#' @noRd
omni_to_NATMI <- function(op_resource,
                          reso_name = "placeholder",
                          natmi_db_path = "input/omnipath_NATMI"){

    write.csv(op_resource %>%
                  select("Ligand gene symbol" = source_genesymbol,
                         "Receptor gene symbol" = target_genesymbol) %>%
                  distinct() %>%
                  as.data.frame(),
              file = str_glue("{natmi_db_path}/{reso_name}.csv"),
              row.names = FALSE)
}


#' Load NATMI results from folder and format appropriately
#'
#' @param output_path NATMI output path
#' @param resource_names results for which resources to load
#' @param .format bool whether to format output
#'
#' @return A list of NATMI results per resource loaded from the output
#'     directory.
#'
#' @importFrom tibble enframe deframe
#' @importFrom magrittr %>%
#' @importFrom purrr map
#' @importFrom dplyr mutate select if_else
#' @importFrom readr read_csv
#' @importFrom tidyr separate
FormatNatmi <- function(output_path,
                        resource_names,
                        .format = TRUE){

    list.files(output_path,
               all.files = TRUE,
               recursive = TRUE,
               pattern ="Edges_") %>%
        enframe() %>%
        separate(value,
                 into = c("resource", "file"),
                 remove = FALSE,
                 extra = "drop",
                 sep="\\/") %>%
        filter(resource %in% resource_names) %>%
        mutate(value =  value %>% map(function(csv)
            read.csv(str_glue("{output_path}/{csv}")))) %>%
        select(resource, "result" = value) %>%
        mutate(
            result =
                if_else(
                    rep(.format, length(.data$result)),
                    result %>% map(function(df){
                        df %>%
                            select(
                                source = Sending.cluster,
                                target = Target.cluster,
                                ligand = Ligand.symbol,
                                receptor = Receptor.symbol,
                                edge_avg_expr = Edge.average.expression.weight,
                                edge_specificity = Edge.average.expression.derived.specificity
                            ) %>%
                            as_tibble()
                    }),
                    result)) %>%
        deframe() %>%
        plyr::rename(., c("lrc2p" = "Default"), # change this to default
                     warn_missing = FALSE) %>%
        .list2tib()
}
      matrix: #' Function Used to Calculate the Connectome-like `weight_sc` weights
#'
#' @param lr_res \link(liana::liana_pipe) results
#'
#' @noRd
#'
#' @return lr_res with an added `weight_sc` column
connectome_score <- function(lr_res,
                             score_col,
                             ...){

    lr_res %>%
        rowwise() %>%
        mutate( {{ score_col }} := mean(c(ligand.scaled, receptor.scaled)))
}


#' Function Used to Calculate the NATMI-like `edge_specificity` weights
#'
#' @param lr_res \link(liana::liana_pipe) results
#' @param score_col name of the score column
#'
#' @return lr_res with an added `edge_specificity` column
#'
#' @noRd
#'
#' @details In the original NATMI implementation NAs are filtered out, but
#' here replace NAs with 0s, as they are needed to account for complexes
natmi_score <- function(lr_res,
                        score_col,
                        ...){

    lr_res %>%
        rowwise() %>%
        mutate( prod_weight = ligand.expr * receptor.expr) %>%
        mutate( {{ score_col }} := ((ligand.expr*(ligand.sum^-1))) *
                    ((receptor.expr*(receptor.sum^-1)))) %>%
        mutate( {{ score_col }} := tidyr::replace_na(.data[[score_col]], 0))
}


#' Function Used to Calculate the logFC products (by default)
#'
#' @param lr_res \link(liana::liana_pipe) results
#' @param score_col name of the score column
#'
#' @noRd
#'
#' @return lr_res with an added `logfc_comb` column
logfc_score <- function(lr_res,
                        score_col,
                        ...){

    lr_res %>%
        rowwise() %>%
        mutate( {{ score_col }} := mean(c(ligand.log2FC, receptor.log2FC)))
}



#' Function Used to Calculate the SigneCellSignalR `LRscore` weights
#'
#' @param lr_res \link(liana::liana_pipe) results
#' @param score_col name of the score column
#'
#' @noRd
#'
#' @return lr_res with an added `LRscore` column
sca_score <- function(lr_res,
                      score_col,
                      ...){

    lr_res %>%
        rowwise() %>%
        mutate( {{ score_col }} :=
                    (ligand.expr^(1/2) * receptor.expr^(1/2))/
                    (global_mean + ligand.expr^(1/2) * receptor.expr^(1/2))
        )
}
        r-version: ['3.6.3', '4.1.1']

    steps: #' Helper Function to generate shuffled means
#'
#' @param lr_res liana_pipe results
#' @param sce SingleCellExperiment Object
#' @param nperms number of permutations
#' @param seed number used to set random seed
#' @inheritParams liana_pipe
#' @inheritParams map_custom
#' @param verbose logical for verbosity
#'
#' @return Returns a list of shuffled gene means by cluster
#'
#' @details This function could be made generalizable to any set of genes,
#'   depending on the set (currently lr_res genes) that is used to filter - i.e.
#'   it could be replaced with e.g. genes from TF regulons
get_permutations <- function(lr_res,
                             sce,
                             nperms = 1000,
                             seed = 1234,
                             parallelize = FALSE,
                             workers = 4,
                             assay.type = "logcounts",
                             verbose = TRUE){
    # remove genes absent in lr_res
    lr_genes <- union(lr_res$ligand, lr_res$receptor)
    sce <- sce[rownames(sce) %in% lr_genes, ]

    # shuffle columns
    set.seed(seed)
    shuffled_clusts <- map(1:nperms, function(perm){
        colLabels(sce) %>%
            as_tibble(rownames = "cell") %>%
            slice_sample(prop=1, replace = FALSE) %>%
            deframe()
    })

    # progress_bar
    if(verbose){
        progress_bar <- progress_estimated(nperms)
    } else{
        progress_bar <- NULL
    }


    # generate mean permutations
    perm <- map_custom(.x = shuffled_clusts,
                       .f = mean_permute,
                       sce = sce,
                       assay.type = assay.type,
                       pb = progress_bar,
                       parallelize = parallelize,
                       workers = workers)

    return(perm)
}


#' Function to calculate p-values as in CellPhoneDB
#'
#' @inheritParams get_permutations
#' @param lr_res liana pipe results
#' @param perm_means permutations obtained via `get_permutations`
#' @param score_col name of the score column
#' @param ... placeholder
#'
#' @returns lr_res + pvalue and lr.mean
#'
#' @keywords internal
cellphonedb_score <- function(lr_res,
                              perm_means,
                              parallelize,
                              workers,
                              score_col = "pvalue",
                              verbose = TRUE,
                              ...){
    og_res <- lr_res %>%
        select(ligand, receptor, source, target)

    if(verbose){
        progress_bar <- dplyr::progress_estimated(length(perm_means) * 2)
    } else{
        progress_bar <- NULL
    }

    perm_joined <- perm_means %>%
        map_custom(function(pmean){
            og_res %>%
                distinct() %>%
                liana:::join_means(means = pmean,
                                   source_target = "source",
                                   entity = "ligand",
                                   type = "expr",
                                   pb = progress_bar) %>%
                liana:::join_means(means = pmean,
                                   source_target = "target",
                                   entity = "receptor",
                                   type = "expr",
                                   pb = progress_bar) %>%
                replace(is.na(.), 0) %>%
                dplyr::rowwise() %>%
                dplyr::mutate(lr_mean = mean(c(ligand.expr, receptor.expr)))
        }, parallelize = parallelize, workers = workers) %>%
        bind_rows()

    # calculate quantiles using ecdf null_dists
    quantiles <- lr_res %>%
        group_by(source, target, ligand.complex, receptor.complex) %>%
        mutate(og_mean = mean(c(ligand.expr, receptor.expr))) %>%
        select(source, target,
               ligand.complex, ligand,
               receptor, receptor.complex,
               og_mean) %>%
        left_join(perm_joined, by = c("source", "target", "ligand", "receptor")) %>%
        group_by(ligand.complex, receptor.complex, source, target) %>%
        group_split() %>%
        map_dbl(function(interaction){
            null_dist <- ecdf(interaction$lr_mean)
            og_mean <- interaction %>% pull("og_mean") %>% unique()
            null_dist(og_mean) %>% pluck(1)
        })

    pvals_df <- lr_res %>%
        group_by(ligand.complex, receptor.complex, source, target) %>%
        group_keys() %>%
        mutate( {{ score_col }} :=  1 - quantiles)

    lr_res %<>%
        rowwise() %>%
        mutate(lr.mean = mean(c(ligand.expr, receptor.expr))) %>%
        left_join(pvals_df,
                  by = c("ligand.complex", "receptor.complex",
                         "source", "target")) %>%
        mutate({{ score_col }} := # replace pval of non-expressed rec and ligs
                   ifelse(ligand.expr == 0 || receptor.expr == 0,
                          1,
                          .data[[score_col]]))

    return(lr_res)
}




#' Function to calculate mean LR expression from shuffled cluster label matrices
#'  as done in CellPhoneDB
#'
#' @param sce single cell experiment object
#' @param col_labels cluster labels
#' @param pb progress bar object
#' @param assay.type assay type (counts, logcounts, etc)
#'
#' @importFrom dplyr progress_estimated
#'
#' @return Returns a list of means per gene calculated with reshuffled
#'    cluster/cell identity labels
#'
#' @keywords internal
mean_permute <- function(col_labels,
                         sce,
                         pb,
                         assay.type){
    if(!is.null(pb)){
        pb$tick()$print()
    }

    scuttle::summarizeAssayByGroup(sce,
                                   ids=col_labels,
                                   statistics = c("mean"),
                                   assay.type = assay.type)@assays@data$mean
}


#' Helper custom map function
#'
#' @inheritParams purrr::map
#' @param parallelize logical whether to parallelize
#' @param workers Number of workers to be used in parallelization
#' @param ... params passed to the called function and to `.f`
#'
#' @keywords internal
map_custom <- function(.x, .f, parallelize, workers, ...){
    if(parallelize){
        future::plan(future::multisession, workers = workers)
        furrr::future_map(.x = .x,
                          .f = .f,
                          .options = furrr::furrr_options(seed = TRUE),
                          ...)

    } else{
        purrr::map(.x = .x,
                   .f = .f,
                   ...)
    }
}
      - uses: actions/checkout@v4
      - name: Set up R ${{ #' Function to call SingleCellSignalR with databases from OmniPath [[DEPRECATED]]
#'
#' @param sce SingleCellExperiment or SeuratObject as input
#' @param op_resource OmniPath Intercell Resource DN
#' @param .format bool whether to format output
#' @param assay Seurat assay data to use
#' @param assay.type count slot (logcounts by default)
#' @param ... arguments passed to `SCAomni::cell_signaling`

#' @importFrom SeuratObject GetAssayData Idents
#' @importFrom magrittr %>% %<>%
#' @importFrom dplyr distinct select
#'
#' @details
#' Stats:
#' LRScore = sqrt(LR product)/mean(raw counts) * sqrt(LR product) where
#' expression of l > 0 and r > 0
#' LRScore = 1 is the highest (~ most likely hit), 0 is the lowest.
#'
#' @export
#'
#' @return An unfiltered SCA tibble
call_sca <- function(sce,
                     op_resource,
                     .format = TRUE,
                     assay = "RNA",
                     assay.type = "logcounts",
                     ...){

  # Convert sce to seurat
  if(class(sce) == "SingleCellExperiment"){
    sce %<>% .liana_convert(., assay=assay)
  }

  if(class(sce) == "Seurat" & assay.type=="logcounts"){
    assay.type = "data"
  }

  # Format OmnipathR resource
  if(!is.null(op_resource)){
    op_resource %<>% sca_formatDB
  } else{
    if(file.exists(system.file(package = "liana", "LRdb.rda"))){
      load(system.file(package = "liana", "LRdb.rda"))
      op_resource <- LRdb
    } else{
      stop("Could not locate LRdb.rda")
    }
  }

  # Prepare data from Seurat object
  input_data <-
    SeuratObject::GetAssayData(sce,
                         assay = assay,
                         slot = assay.type)
  labels <- SeuratObject::Idents(sce)

  # Compute interactions between cell clusters
  signal <- SCAomni::cell_signaling(data = input_data,
                                    genes = row.names(input_data),
                                    cluster = as.numeric(labels),
                                    c.names = levels(Idents(sce)),
                                    species = 'homo sapiens',
                                    LRdb = op_resource,
                                    int.type="autocrine", # includes both para and auto...
                                    write = FALSE,
                                    verbose = FALSE,
                                    ...
                                    )

  # Compute intercellular gene networks
  sca_res <- SCAomni::inter_network(data = input_data,
                                    signal = signal,
                                    genes = row.names(input_data),
                                    cluster = as.numeric(labels),
                                    c.names = levels(Idents(sce)),
                                    write = FALSE
                                    )
  if (.format) {
    sca_res %<>% FormatSCA
  }


  return(sca_res)
}



#' Helper function to format SingleCellSignalR results
#' @param sca_res Unformatted SCA results
#' @param remove.na bool whether to filter SCA output
#' @importFrom purrr pluck
#' @importFrom tidyr separate
#' @importFrom magrittr %>%
#' @importFrom dplyr select
#' @importFrom tibble as_tibble
#'
#' @export
FormatSCA <- function(sca_res, remove.na = TRUE) {
  sca_res <- sca_res %>%
    pluck("full-network") %>%
    separate(ligand,
             into = c("source", "ligand"),
             sep = "⊎") %>%
    separate(receptor,
             into = c("target", "receptor"),
             sep = "⊎") %>%
    select(source, ligand, target, receptor, LRscore) %>%
    as_tibble()
  return(sca_res)
}


#' Helper Function to convert Omni to LRdb Format
#'
#' @param op_resource OmniPath resource
#'
#' @export
#'
#' @keywords internal
sca_formatDB <- function(op_resource){
  op_resource %>%
  select(ligand = source_genesymbol,
         receptor = target_genesymbol,
         source = sources,
         PMIDs = references) %>%
    distinct()
} }}
        uses: r-lib/actions/setup-r@f57f1301a053485946083d7a45022b278929a78a
        with: #' Call Squidpy Pipeline via reticulate with OmniPath and format results [[DEPRECATED]]
#'
#' @param sce SingleCellExperiment or Seurat Object as input
#' @param op_resource Tibble or list of OmniPath resources, typically obtained via
#'    \code{\link{select_resource}}
#' @param seed seed passed to squidpy's ligrec function
#' @param conda_env python conda environment to run Squidpy; set to liana_env by default
#' @param ... kwargs passed to Squidpy; For more information see:
#'   \link{https://squidpy.readthedocs.io/en/latest/api/squidpy.gr.ligrec.html#squidpy.gr.ligrec}
#' @param assay assay name
#' @param assay.type count slot (logcounts by default)
#'
#' @import reticulate tibble
#' @importFrom tidyr pivot_longer
#' @importFrom dplyr left_join
#'
#' @details CellPhoneDBv2 algorithm re-implementation in Python.
#'
#' Note that `cluster_key` is a parameter passed to the Squidpy function,
#' by default this will be set to the default Ident of the Seurat object.
#'
#' @returns A list of Squidpy results for each resource
#'
#' @export
call_squidpy <- function(sce,
                         op_resource,
                         seed = 1004,
                         conda_env = NULL,
                         assay = "RNA",
                         assay.type = "logcounts",
                         ...){

    # Convert sce to seurat
    if(class(sce) == "SingleCellExperiment"){
        sce %<>% .liana_convert(., assay=assay)
    }

    if(class(sce) == "Seurat" & assay.type=="logcounts"){
        assay.type = "data"
    }

    if(is_tibble(op_resource)){
        op_resource <- list("placeholder" = op_resource)
    }

    kwargs <- list(...)
    kwargs$cluster_key %<>% `%||%`(.get_ident(sce@meta.data,
                                              SeuratObject::Idents(sce),
                                              class(sce)))
    kwargs$seed <- as.integer(seed)

    if(length(kwargs$cluster_key) == 0){
        stop("Squidpy: Cluster annotations missing! Please specificy a column")
    } else{
        message(str_glue("Squidpy: running with {kwargs$cluster_key} as cluster_key"))
    }

    if(!is.factor(sce@meta.data[[kwargs$cluster_key]])){
        sce@meta.data[[kwargs$cluster_key]] <-
            sce@meta.data %>%
            pull(kwargs$cluster_key) %>%
            as.factor()
        message(str_glue("Squidpy: {kwargs$cluster_key} was converted to factor"))
    }

    reticulate::use_condaenv(condaenv = conda_env %>% `%||%`("liana_env"),
                             conda = "auto",
                             required = TRUE)
    py$pd <- reticulate::import("pandas")

    if("DEFAULT" %in% toupper(names(op_resource))){
        op_resource$Default <- NULL
    }

    op_resources <- map(op_resource, function(x) x %>%
                            select(
                                uniprot_source = source,
                                unprot_target = target,
                                source = source_genesymbol,
                                target = target_genesymbol,
                                category_intercell_source,
                                category_intercell_target
                                )
                        ) %>%
        unname() # unname r list, so its passed as list to Python

    # Call Squidpy
    reticulate::source_python(system.file(package = 'liana', "squidpy_pipe.py"))
    py_set_seed(seed)

    # Check if assay meta.features match object rownames
    # if not assign a placeholder (Seurat-specific fix)
    if(nrow(Seurat::GetAssay(sce)[[]]) != nrow(sce) |
       ncol(sce@assays[[assay]]@meta.features)==0){
        message("Meta features were reassigned to match object")

        sce@assays[[assay]]@meta.features <-
            data.frame(row.names = rownames(sce),
                       placeholder = rownames(sce))
    }

    py$squidpy_results <- py$call_squidpy(op_resources,
                                          SeuratObject::GetAssayData(sce,
                                                                     assay=assay,
                                                                     slot=assay.type), # expr
                                          sce[[]], # meta
                                          Seurat::GetAssay(sce,
                                                           assay=assay)[[]], # feature_meta
                                          kwargs # passed to squidpy.gr.ligrec
                                          )

    squidpy_pvalues <- py$squidpy_results$pvalues %>% setNames(names(op_resource))
    squidpy_means <- py$squidpy_results$means %>% setNames(names(op_resource))
    squidpy_metadata <- py$squidpy_results$meta %>% setNames(names(op_resource))


    squidpy_results <- map(names(op_resource),
                           function(x)
                               FormatSquidpy(.name=x,
                                             .pval_list = squidpy_pvalues,
                                             .mean_list = squidpy_means,
                                             .meta_list = squidpy_metadata)) %>%
        setNames(names(op_resource)) %>%
        map(function(res) res %>%
                rename(ligand = source,
                       receptor = target) %>%
                separate(pair, sep = "_", into=c("source", "target")) %>%
                select(source, target,
                       ligand, receptor,
                       means, pvalue)) %>%
        .list2tib()

    return(squidpy_results)
}


#' Helper function to reformat Squidpy function r
#' @param .name omnipath resource name
#' @param .pval_list p-value results from different dbs as a list from squidpy
#' @param .mean_list mean list from squidpy
#'
#' @importFrom dplyr left_join
#'
#' @noRd
FormatSquidpy <- function(.name,
                          .pval_list,
                          .mean_list,
                          .meta_list){
    x_pval <- .pval_list[[.name]] %>%
        py_to_r() %>%
        pivot_longer(cols = 3:ncol(.),
                     values_to="pvalue",
                     names_to="pair")

    x_mean <- .mean_list[[.name]] %>%
        py_to_r() %>%
        pivot_longer(cols = 3:ncol(.),
                     values_to = "means",
                     names_to = "pair")

    x_meta <- .meta_list[[.name]] %>% py_to_r()

    res_formatted <- left_join(x_pval, x_mean,
                               by = c("source", "target", "pair")) %>%
        left_join(x_meta, by = c("source", "target"))

    return(res_formatted)
}
          r-version: ${{ matrix.r-version }}
      - name: Install dependencies
        run: |
          install.packages(c("remotes", "rcmdcheck"))
          remotes::install_deps(dependencies = TRUE)
        shell: Rscript {0}
      - name: Check
        run: rcmdcheck::rcmdcheck(args = "--no-manual", error_on = "error")
        shell: Rscript {0}
