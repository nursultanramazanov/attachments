# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.
#
# See https://github.com/r-lib/actions/tree/master/examples#readme for
# additional example workflows available for the R community.

name: R

on: dmvn <- function(y, mu, sigma, siginv = NULL, ldsi = NULL, logscale = FALSE) {
  ## Density of the multivariate normal distribution.
  ## Args:
  ##   y: A numeric vector or matrix containing the data whose
  ##     density is desired.
  ##   mu:  A vector.  The mean of the distribution.
  ##   sigma: A symmetric, positive definite matrix.  The variance
  ##     matrix of the distribution.
  ##   siginv: The inverse of sigma, or NULL.  If siginv is non-NULL
  ##     then sigma will not be used.
  ##   ldsi:  The log determinant of siginv, or NULL.
  ##   logscale: If TRUE the density is returned on the log scale.
  ##     Otherwise the density is returned on the probability density
  ##     scale.
  ##
  ## Returns:
  ##   The density of y, or of each row of y.
  if (is.vector(y)) {
    y <- matrix(y, nrow = 1)
  }
  stopifnot(is.numeric(mu),
            length(mu) == ncol(y))

  if (is.null(siginv)) {
    stopifnot(is.matrix(sigma),
              nrow(sigma) == ncol(sigma),
              nrow(sigma) == length(mu))
    R <- chol(sigma)
    ## sigma = t(R) %*% R
    ldsi <- -2 * sum(log(diag(R)))

    R.inv <- t(solve(R))
    ## Each column of Y is y[i, ] - mu
    Y <- t(y) - mu
    ## sigma.inverse = t(R.inv) %*% R.inv
    Y <- R.inv %*% Y
    qforms <- colSums(Y ^2)
  } else {
    stopifnot(is.matrix(siginv),
              nrow(siginv) == ncol(siginv),
              nrow(siginv) == length(mu))
    if (is.null(ldsi)) {
      R <- chol(siginv)
      ldsi <- 2 * sum(log(diag(R)))
    }
    qforms <- mahalanobis(y, center = mu, cov = siginv, inverted = TRUE)
  }
  d <- length(mu)
  log2pi <- log(2 *pi)
  ans <- -(d/2) * log2pi + .5 * ldsi - .5 * qforms
  if (logscale) {
    return(ans)
  } else {
    return(exp(ans))
  }
}
  push: ## An example of the external legend idiom
##
## labels <- c("foo", "bar", "baz")
## par(oma = rep(4, 4), mar = rep(0, 4)
## ExternalLegendLayout(3, 4, labels)
##
## for (i in 1:3) {
##   for (j in 1:4) {
##     plot(rnorm(10), pch = i) } }
## AddExternalLegend(labels, pch = 1:3)

ExternalLegendLayout <- function(nrow,
                                 ncol,
                                 legend.labels,
                                 legend.location = c("top", "right"),
                                 outer.margin.lines = rep(4, 4),
                                 gap.between.plots = rep(0, 4),
                                 legend.cex = 1,
                                 x.axis = TRUE,
                                 y.axis = TRUE) {
  ## Prepare an array of plots to receive an external legend.  This
  ## must be called prior to making any of the plots.  This function
  ## will allocates an empty plotting region for an external legend on
  ## the top or the right of a grid of plots.  It uses a call to
  ## layout() to do the layout, so it cannot be used in conjunction
  ## with par(mfrow).
  ##
  ## Args:
  ##   nrow:  The number of rows of plots
  ##   ncol:  The number of columns of plots
  ##   legend.labels: The labels (legend text) that will be used in
  ##     the legend.  These are needed at layout time so enough room
  ##     can be left for when the legend is actually added.
  ##   legend.location: The margin in which to place the legend.
  ##     Either "top" or "right".
  ##   outer.margin.lines: A vector of length four giving the number
  ##     of lines of text desired for the outer margins of the plot.
  ##     See the 'oma' argument of 'par'.  This can also be specified
  ##     as a single number, to be repeated 4 times.
  ##   gap.between.plots: A vector of length 4 giving the number of
  ##     lines of text to leave between grid panels.  See the 'mar'
  ##     argument of 'par'.  This can also be specified as a single
  ##     number, to be repeated 4 times.
  ##   legend.cex: The scale factor that will be used for legend text.
  ##     This must match the scale factor used in add.external.legend.
  ##   x.axis:  Will any plots have a horizontal axis?
  ##   y.axis:  Will any plots have a vertical axis?
  if (!is.null(legend.location)) {
    legend.location <- match.arg(legend.location)
  }
  layout.matrix <- matrix(1:(nrow * ncol),
                          byrow = TRUE,
                          nrow = nrow,
                          ncol = ncol)

  if (length(outer.margin.lines) == 1) {
    outer.margin.lines <- rep(outer.margin.lines, 4)
  }
  stopifnot(length(outer.margin.lines) == 4)

  if (length(gap.between.plots) == 1) {
    gap.between.plots <- rep(gap.between.plots, 4)
  }
  stopifnot(length(gap.between.plots) == 4)

  opar <- par(oma = outer.margin.lines, mar = gap.between.plots)
  if (is.null(legend.location)) {
    layout(layout.matrix)
  } else if (legend.location == "top") {
    layout.matrix <- rbind(nrow * ncol + 1, layout.matrix)
    legend.buffer <- max(strheight(legend.labels,
                                   units = "inches",
                                   cex = legend.cex))
    legend.buffer <- legend.buffer * 1 * 2.54
    ## The legend.buffer is the height of the legend text in centimeters.
    if (x.axis) {
      ## Leave some room for an axis on top of the plot.
      legend.buffer <- legend.buffer + 0.5
    }
    layout(layout.matrix, heights = c(lcm(legend.buffer), rep(1, nrow)))
  } else if (legend.location == "right") {
    layout.matrix <- cbind(nrow * ncol + 1, layout.matrix)
    legend.buffer <- max(strwidth(legend.labels,
                                  units = "inches",
                                  cex = legend.cex))
    legend.buffer <- legend.buffer * 2.54 + legend.cex
    layout(layout.matrix, widths = c(rep(1, ncol), lcm(legend.buffer)))
  }
  return(opar)
}

AddExternalLegend <- function(legend.labels,
                              legend.location = c("top", "right"),
                              legend.cex = 1,
                              bty = "n",
                              ...) {
  ## Adds an external legend to a plotting region containing multiple
  ## panels.  The legend can be placed either on the top of the
  ## plotting region or to the right.  You have to call
  ## external.legend.layout and produce the entire grid of plots
  ## before calling this function.
  ##
  ## Args:
  ##   legend.location: Either "top" or "right".  The margin in which
  ##     to place the legend.  This must match the argument given to
  ##     external.legend.layout.
  ##   legend.labels:  The entries in the legend.  A character vector.
  ##   legend.cex:  The scale factor applied to the legend labels.
  ##   bty: Type of box to draw around the legend.  Can be "n" (for no
  ##     box) or "o" for a box.  See 'legend'.
  ##   ...:  Extra arguments passed to 'legend.
  if (is.null(legend.location)) {
    return(invisible(NULL))
  }
  legend.location <- match.arg(legend.location)
  ## Regardless of the margins around the other plots, we don't want
  ## any margins around the 'fake plot' containing the legend.
  opar <- par(mar = rep(0, 4))
  on.exit(par(opar))
  plot(1, xlim = c(0, 1),
       ylim = c(0, 1),
       xlab = "",
       ylab = "",
       type = "n",
       axes = FALSE,
       xpd = NA)
  if (legend.location == "top") {
    xjust <- 0.5
    yjust <- 0
    legend.x <- 0.5
    legend.y <- 1
  }
  else {
    xjust <- 1
    yjust <- 0.5
    legend.x <- 1
    legend.y <- 0.5
  }
  legend(legend.x,
         legend.y,
         legend = legend.labels,
         horiz = (legend.location == "top"),
         xjust = xjust,
         yjust = yjust,
         cex = legend.cex,
         xpd = NA,
         bty = bty,
         ...)
}
    branches: [ "main" ]
  pull_request: ## A collection of utilities for formatting error messages.

ToString <- function(object, ...) {
  ## Args:
  ##   object:  An R object to be printed.
  ##   ...: extra arguments passed to 'print'
  ## Returns:
  ##   A character string, suitable for passing to an error message, containing
  ##   the value of the object, as rendered by the object's 'print' method.
  UseMethod("ToString")
}

ToString.default <- function(object, ...) {
  ## Args:
  ##   object:  An R object to be printed.
  ##   ...: extra arguments passed to 'print'
  ## Returns:
  ##   A character string, suitable for passing to an error message, containing
  ##   the value of the object, as rendered by the object's 'print' method.
  output <- capture.output(print(object, ...))
  return(paste(paste(output, collapse = "\n"), "\n"))
}

ToString.table <- function(object, ...) {
  ## Args:
  ##   object:  A table whose entries are to be written to a string.
  ##   ...: extra arguments passed to 'print'
  ## Returns:
  ##   A character string containing the formatted entries of 'object', suitable
  ##   for passing to an error message.
  stopifnot(is.table(object))
  tab.string <- capture.output(print(object, ...))[-1]
  tab.string[1] <- paste("\nvalues: ", tab.string[1])
  tab.string[2] <- paste("counts: ", tab.string[2], "\n")
  return(paste(tab.string, collapse = "\n"))
}
    branches: [ "main" ]

permissions: RVectorFunction <- function(f, ...) {
  ## Args:
  ##   f: A scalar-valued function of a vector-valued argument.  The function
  ##     can depend on other arguments as long as the vector valued argument
  ##     appears in the first position.
  ##   ...: Optional, named, extra arguments to be passed to f.  These arguments
  ##     are fixed at the time this object is created.  For the purpose of
  ##     evaluating f, these arguments do not update.
  ## 
  ## Returns:
  ##   A list containing the information needed to evaluate 'f' in C++ code.
  stopifnot(is.function(f))
  dots <- list(...)
  if (length(dots) >= 1) {
    ## Handling extra arguments in C++ is hard, so wrap them up here in R.
    fwrapper <- function(x) {
      return(f(x, ...))
    }
  } else {
    ## Wrapping the function like this also ensures we know its name.
    fwrapper <- f
  }
  ans <- list(
    function.name = ("fwrapper"),
    env = environment(fwrapper),
    thefun = fwrapper)
  class(ans) <- "RVectorFunction"
  return(ans);
}

  contents: read

jobs: GenerateFactorData <- function(factor.levels.list, sample.size) {
  ## This function is intended to be used for generating fake data to
  ## test other functions.
  ## Args:
  ##   factor.levels.list: A named list.  Each list element is a
  ##     character vector giving the levels of the factors to be
  ##     sampled.  The list names will become the variable names.
  ##   sample.size:  The number of rows in the generated data frame.
  ##
  ## Returns:
  ##   A data frame  with sample.size rows and length(variable.names)
  ##   columns.  Each column is a factor.

  stopifnot(is.numeric(sample.size) &&
            length(sample.size) == 1 &&
            sample.size > 0)
  stopifnot(is.list(factor.levels.list))
  repeated.levels <- any(sapply(factor.levels.list, anyDuplicated))
  if (repeated.levels) {
    stop("All factor levels in factor.levels.list must be unique")
  }

  if (is.null(names(factor.levels.list))) {
    names(factor.levels.list) <- make.names(seq_along(factor.levels.list))
  }
  variable.names <- names(factor.levels.list)

  ans <- list()
  for (v in 1:length(factor.levels.list)) {
    level.names <- as.character(factor.levels.list[[v]])
    values <- factor(sample(level.names,
                            replace = TRUE,
                            size = sample.size),
                     levels = level.names)
    ans[[variable.names[v]]] <- values
  }
  return(as.data.frame(ans))
}
  build: .CollapseTable <- function(counts, max.levels, alphabetical = TRUE) {
  ## Truncates a table to have at most max.levels of entries.  The
  ## other entries will be collapsed into a single level called
  ## "other".  If alphabetical == TRUE then the returned table will be
  ## sorted alphabetically according to the table name.  Otherwise it
  ## will be sorted by frequency, in decreasing order.
  if (length(counts) <= max.levels) {
    return(if (alphabetical) .OrderAlphabetically(counts)
           else .OrderByFrequency(counts))
  }
  index <- rev(order(counts))
  new.tab <- counts[index][1:(max.levels - 1)]
  other <- sum(counts[index][-(1:max.levels - 1)])
  if (alphabetical) {
    alpha.index <- order(names(new.tab))
    new.tab <- new.tab[alpha.index]
  }
  new.tab <- c(new.tab, other)

  ## Make sure the last entry has a name, and its name is 'other'
  names(new.tab)[length(new.tab)] <- "other"

  return(new.tab)
}

.OrderAlphabetically <- function(counts) {
  ## Orders the 'table' object counts alphabetically by name.
  index <- order(names(counts))
  return(counts[index])
}

.OrderByFrequency <- function(counts) {
  ## Puts the 'table' object counts in decreasing order by frequency.
  return(rev(sort(counts)))
}

histabunch <- function(x, gap = 1, same.scale = FALSE, boxes = FALSE,
                       min.continuous = 12,
                       max.factor = 40,
                       vertical.axes = FALSE, ...){
  ## Plot a bunch of histograms describing the data in x.
  ## Args:
  ##   x:  A matrix or data frame containing the variables to be plotted.
  ##   gap:  The gap between the plots, measured in lines of text.
  ##   same.scale: Logical value indicating whether the histograms
  ##     should all be plotted on the same scale.
  ##   boxes: Logical value indicating whether boxes should be drawn
  ##     around the histograms.
  ##   min.continuous: Numeric variables with more than min.continuous
  ##     unique values will be plotted as continuous.  Otherwise they
  ##     will be plotted as factors.
  ##   max.factor: Factors with more than 'max.factor' levels will be
  ##     beautified (ha!) by combining their remaining levels into an
  ##     "other" category.
  ##   vertical.axes: Logical value indicating whether the histograms
  ##     should be given vertical "Y" axes.
  ##   ...: extra arguments passed to hist (for numeric variables) or
  ##     barplot (for factors).
  stopifnot(is.data.frame(x) || is.matrix(x))
  number.of.variables <- ncol(x)
  number.of.rows <- max(1, floor(sqrt(number.of.variables)))
  number.of.columns <- ceiling(number.of.variables / number.of.rows)

  if (!is.null(names(x))) {
    vnames <- names(x)
  } else if (!is.null(dimnames(x)[[2]])) {
    vnames <- colnames(x)
  } else {
    vnames <- paste("V", 1:number.of.variables, sep="")
  }

  is.continuous <- function(x){
    if (is.factor(x)) return(FALSE)
    if (!is.numeric(x)) return(FALSE)
    if (length(unique(x)) < min.continuous) return(FALSE)
    return(TRUE)
  }

  hist.continuous <- function(x, xlim=NULL, title="", ...) {
    fin <- is.finite(x)
    x <- x[fin]
    if (is.null(xlim)) xlim <- range(x)
    hist(x, xlim=xlim, axes=FALSE, col="lightgray", ylab = "", main=title, ...)
    axis(1)
  }

  plot.all.missing <- function(title) {
    ## A stub plot indicating that all data are missing.
    plot(c(0,0), type = "n", main=title, axes=FALSE)
    text(x=1.5, y=0, lab="MISSING")
  }

  hist.factor <- function(x, title="", ...) {
    ## histogram of a factor variable.
    x <- as.factor(x[!is.na(x)])
    counts <- .CollapseTable(table(x), max.factor, alphabetical = TRUE)
    midpoints <- barplot(counts,
                         col="lightgray",
                         main=title,
                         axes = vertical.axes,
                         names.arg = "",
                         ylim = range(c(0, counts)) * 1.02,
                         ...)
    abline(h = 0)
    axis(side = 1, at = as.numeric(midpoints), labels = names(counts),
         lwd = 0, lwd.ticks = 1)
  }

  hist.variable <- function(x, title, xlim, ...){
    if (!any(is.finite(x))) {
      plot.all.missing(title)
      return()
    }
    if (is.continuous(x)) {
      hist.continuous(x, xlim, title, ...)
    } else hist.factor(as.factor(x), title, ...)
    if (boxes) box()
  }

  get.range <- function(x){
    nc <- ncol(x)
    xlim <- NULL
    for (i in 1:nc) {
      if (is.continuous(x[,i])){
        fin <- is.finite(x[,i])
        y <- x[fin,i]
        rng <- range(y)
        if (is.null(xlim)) xlim <- rng
        else xlim <- range(c(xlim, rng))
      }
    }
    return(xlim)
  }

  my.margins <- c(3, gap/2, 2, gap/2)
  if (vertical.axes) my.margins[2] <- 2
  original.par <- par(mfrow=c(number.of.rows, number.of.columns),
                      mar = my.margins,
                      oma = rep(2, 4),
                      xpd = !boxes)
  on.exit(par(original.par))

  if (same.scale) xlim <- get.range(x)
  else xlim=NULL

  count <- 0
  for (j in 1 : number.of.rows) {
    for (k in 1 : number.of.columns) {
      count <- count + 1
      if (count > number.of.variables) break
      hist.variable(x[,count], xlim = xlim, title=vnames[count], ...)
      if (vertical.axes) {
        axis(2)
      }
    }
  }
  return(invisible(NULL))
}
    runs-on: macos-latest
    strategy: dInverseWishart <- function(Sigma, sum.of.squares, nu, logscale = FALSE,
                            log.det.sumsq = log(det(sum.of.squares))) {
  ## Inverse Wishart density function
  ## Args:
  ##   Sigma:  The argument at which to evaluate the density.  A variance matrix.
  ##   sum.of.squares: A positive definite matrix.  Typically this is
  ##     the sum of squares that is the sufficient statistic for the
  ##     inverse Wishart distribution.
  ##   nu: A positive scalar giving the "degrees of freedom" parameter
  ##     for the distribution.  This must satisfy nu > nrow(Sigma) - 1.
  ##   logscale: Logical.  If TRUE then the log of the density is
  ##     returned.  Otherwise the density is returned on the absolute
  ##     scale.
  ##   log.det.sumsq: If this function is to be called many times with
  ##     the same value of sum.of.squares, then precomputing
  ##     log(det(sum.of.squares)) can save considerable time.
  ## Returns:
  ##   The scalar value of the density function (or its log) evaluated
  ##   at the argument.
  dimension <- ncol(Sigma)
  stopifnot(nu > dimension - 1)
  stopifnot(nrow(Sigma) == dimension,
            dim(sum.of.squares) == dim(Sigma))
  Sigma.chol <- chol(Sigma)
  logdet.Sigma <- 2 * sum(log(diag(Sigma.chol)))
  if (is.null(log.det.sumsq)) {
    log.det.sumsq <- log(det(sum.of.squares))
  }
  siginv <- chol2inv(Sigma.chol)
  ans <- .5 * nu * log.det.sumsq -
      .5 * (nu + dimension + 1) * logdet.Sigma -
      .5 * TraceProduct(sum.of.squares, siginv) -
      .5 * nu * dimension * log(2) -
      lmgamma(.5 * nu, dimension)
  if (logscale) return(ans)
  return(exp(ans))
}

dWishart <- function(W, Sigma, nu, logscale = FALSE) {
  ## Evaluates the density of the Wishart distribution.
  ##
  ## Args:
  ##   W: The argument of the distribution (i.e. the random variable).
  ##     A positive definite matrix.
  ##   Sigma: The variance of the generating normal distribution.  See
  ##     the Details section below.
  ##   nu: A positive scalar giving the 'degrees.of.freedom' parameter
  ##     of the Wishart distribution.  The distribution is only
  ##     defined for nu >= nrow(W) - 1.
  ##   logscale: Logical.  If TRUE then the log of the density is
  ##     returned.  Otherwise the density is returned on the absolute
  ##     scale.
  ##
  ## Returns:
  ##   The scalar value of the density function (or its log) evaluated
  ##   at the argument.
  ##
  ## Details:
  ##
  ##   If 'nu' is a scalar then a Wishart random variable can be
  ##   thought of as the sum of 'nu' outer products of zero-mean
  ##   multivariate normal deviates, each with the same variance
  ##   matrix Sigma.  The mean of the distribution is 'nu * Sigma'.
  sigma.chol <- chol(Sigma);
  siginv <- chol2inv(sigma.chol)
  sigma.logdet <- 2 * sum(log(diag(sigma.chol)))
  W.logdet <- 2 * sum(log(diag(chol(W))))
  dimension <- nrow(W)
  log2 <- 0.69314718055994528623
  ans <- .5 * (nu - dimension - 1) * W.logdet -
      TraceProduct(siginv, W) / 2 -
      .5 * nu * dimension * log2 -
      .5 * nu * sigma.logdet -
      lmgamma(nu/2, dimension)
  if (logscale) return(ans)
  return(exp(ans))
}

rWishart <- function(nu,  scale.matrix, inverse = FALSE) {
  ## Generates a single draw from the Wishart or inverse Wishart
  ## distribution.  The Wishart distribution is generated by taking
  ## 'nu' draws from the MVN(0, Sigma) and adding their outer
  ## products.
  ##
  ## The inverse Wishart distribution is the conjugate prior for Sigma
  ## in a multivariate normal model.
  ##
  ## Args:
  ##   nu: The degrees of freedom parameter in the Wishart or inverse
  ##     Wishart distribution.  The distribution requires nu > dimension - 1.
  ##   scale.matrix: For the Wishart, 'scale.matrix' is the 'Sigma'
  ##     parameter of the generating multivariate normal distribution.
  ##     For the inverse Wishart, scale.matrix is the INVERSE of the
  ##     "sum of squares" matrix portion of the Mvn sufficient
  ##     statistics.
  ##   inverse: Logical.  If TRUE then simulate from the Wishart
  ##     distribution.  Otherwise simulate from the inverse: Wishart
  ##     distribution.
  dimension = nrow(scale.matrix)
  R <- matrix(0, nrow = dimension, ncol = dimension)
  R[upper.tri(R)] <- rnorm(dimension * (dimension - 1) / 2)
  diag(R) <- sqrt(rchisq(dimension, df = (nu + 1) - (1:dimension)))
  R <- R %*% chol(scale.matrix)
  if (!inverse) return(t(R) %*% R)  # draw of siginv
  return(chol2inv(R))
}

TraceProduct <- function(A, B, b.is.symmetric = FALSE) {
  ## Returns the trace of the product of the two matrices A and B.
  ## Args:
  ##   A:  The matrix on the left hand side of the product.
  ##   B:  The matrix on the right hand side of the product.
  ##   b.is.symmetric: Logical.  A TRUE value indicates that B is a
  ##     symmetric matrix.  A slight computational savings is possible
  ##     if B is symmetric.
  ## Returns:
  ##   A scalar value giving trace(A %*% B).
  stopifnot(is.matrix(A))
  stopifnot(is.matrix(B))

  ## The trace of AB is sum_i AB(i, i).
  ## AB(i, i) is sum_j A(i, j) * B(j, i).
  ## Therefore, trace(AB) = sum_i sum_j A(i, j) * B(j, i).  This is
  ## the elementwise product of A times B.transpose.
  if (b.is.symmetric) {
    return(sum(A * B))
  } else {
    return(sum(A * t(B)))
  }
}
      matrix: rinvgamma <- function(n, shape, rate) {
  ## Returns n draws from the inverse gamma distribution, parameterized so that
  ## if theta ~ InverseGamma(shape, rate) then 1 / theta ~ Gamma(shape, rate),
  ## meaning that 1/theta has mean shape / rate and variance shape / rate^2.
  ##
  ## Args:
  ##   n:  The desired number of draws.
  ##   shape:  The shape parameter.
  ##   rate: The rate parameter.  NOTE: The term 'rate' is used to match the
  ##     corresponding parameter in 'rgamma.' Much of the rest of the world
  ##     calls this parameter the 'scale' parameter.
  ##
  ## Returns:
  ##   A vector of length n containing the draws.
  return(1.0 / rgamma(n, shape, rate))
}

dinvgamma <- function(x, shape, rate, logscale = FALSE) {
  ## Density of the inverse gamma distribution, parameterized so that if theta ~
  ## InverseGamma(shape, rate) then E(1/theta) = shape/rate and Var(1/theta) =
  ## shape/rate^2.
  ##
  ## Args:
  ##   x:  A vector of deviates where the density is to be evaluated.
  ##   shape:  Shape parameter.
  ##   rate:  Rate parameter.  NOTE: The term 'rate' is used to match the
  ##     corresponding parameter in 'rgamma.' Much of the rest of the world
  ##     calls this parameter the 'scale' parameter.
  ##   logscale: Logical.  If TRUE then the density is returned on the log
  ##     scale.  If FALSE the density is returned on the probability scale.
  ##
  ## Returns:
  ##   A vector with length matching x containing the density values.
  ans <- dgamma(1.0 / x, shape, rate, log = logscale)
  if (logscale) {
    ans <- ans - 2 * log(x)
  } else {
    ans <- ans / x^2
  }
  return(ans)
}

pinvgamma <- function(x, shape, rate, lower.tail = TRUE, logscale = FALSE) {
  ## Density of the inverse gamma distribution, parameterized so that if theta ~
  ## InverseGamma(shape, rate) then E(1/theta) = shape/rate and Var(1/theta) =
  ## shape/rate^2.
  ##
  ## No Jacobian is needed for the CDF.  If X is inverse gamma, then 1/X is
  ## gamma.  Thus Pr(X < x) = Pr(1/x < 1/X) = 1 - pgamma(1/x).  Simply call
  ## pgamma(1/x) and negate the lower.tail argument.
  ##
  ## Args:
  ##   x:  A vector of deviates where the density is to be evaluated.
  ##   shape:  Shape parameter.
  ##   rate:  Rate parameter.  NOTE: The term 'rate' is used to match the
  ##     corresponding parameter in 'rgamma.' Much of the rest of the world
  ##     calls this parameter the 'scale' parameter.
  ##   lower.tail: Logical.  If TRUE then the probability to the left of x is
  ##     returned.  If FALSE then the probability to the right of x is returned.
  ##   logscale: Logical.  If TRUE then the density is returned on the log
  ##     scale.  If FALSE the density is returned on the probability scale.
  ##
  ## Returns:
  ##   A vector with length matching x containin the density values.
  return(pgamma(1/x, shape, rate, lower.tail = !lower.tail,
                log.p = logscale))
}

qinvgamma <- function(p, shape, rate, lower.tail = TRUE, logscale = FALSE) {
  ## Args:
  ##   p: A vector of CDF values (if lower.tail is TRUE) or survivor function
  ##     values (if lower.tail = FALSE) from the inverse gamma distribution.
  ##   shape:  Shape parameter.
  ##   rate:  Rate parameter.  NOTE: The term 'rate' is used to match the
  ##     corresponding parameter in 'rgamma.' Much of the rest of the world
  ##     calls this parameter the 'scale' parameter.
  ##   lower.tail: Logical.  If TRUE then deviates are constructed using
  ##     probability counting from zero (i.e. using the CDF).  If FALSE then
  ##     deviates are constructed using probability counting from infinity
  ##     (i.e. the survivor function).
  ##   logscale: Logical.  If TRUE then the density is returned on the log
  ##     scale.  If FALSE the density is returned on the probability scale.
  ##
  ## Returns:
  ##   A vector of deviates corresponding to the probabilities in 'p'.
  return(1.0 / qgamma(p, shape, rate, lower.tail = !lower.tail,
                      log.p = logscale))
}
        r-version: ['3.6.3', '4.1.1']

    steps: IsOdd <- function(x) (x - 1)%%2 == 0
IsEven <- function(x) x%%2 == 0
      - uses: actions/checkout@v4
      - name: Set up R ${{ lmgamma <- function(y, dimension) {
  ## Log of the multivariate gamma distribution of order 'dimension'.
  ## This function appears as part of the normalizing constant for the
  ## Wishart distribution.
  stopifnot(is.numeric(dimension),
            length(dimension) == 1,
            dimension == as.integer(dimension),
            dimension >= 1)
  stopifnot(is.numeric(y), length(y) == 1)
  j <- 1:dimension
  normalizing.constant <- (dimension * (dimension - 1) / 4) * log(pi)
  ans <- sum(lgamma(y + (1 - j) / 2))
  return(ans + normalizing.constant)
} }}
        uses: r-lib/actions/setup-r@f57f1301a053485946083d7a45022b278929a78a
        with: LogIntegratedGaussianLikelihood <- function(suf, prior) {
  ## Return the log of the integrated Gaussian likelihood with respect to the
  ## normal inverse gamma prior 'prior'.
  ##
  ## Args:
  ##   suf:  An object of class GaussianSuf.
  ##   prior:  An object of class NormalInverseGammaPrior.
  ##
  ## Returns:
  ##   A scalar, giving the log of the integrated Gaussian likelihood.
  n <- suf$n
  if (n > 0) {
    ybar <- suf$sum / n
  } else {
    ybar <- 0
  }
  if (n > 1) {
    sample.variance <- (suf$sumsq - n * ybar^2) / (n - 1)
  } else {
    sample.variance <- 0
  }
  kappa <- prior$mu.guess.weight
  mu0 <- prior$mu.guess
  df <- prior$sigma.prior$prior.df
  ss <- prior$sigma.prior$prior.guess^2 * df

  posterior.mean <- (n * ybar + kappa * mu0) / (n + kappa)
  DF <- df + n
  SS <- ss + (n - 1) * sample.variance + n * (ybar - posterior.mean)^2 +
    kappa * (mu0 - posterior.mean)^2
  return( - .5 * n * log(2 * pi) + .5 * log(kappa / (n + kappa)) +
            lgamma(DF/2) - lgamma(df / 2) +
            .5 * df * log(ss / 2) - .5 * DF * log(SS / 2))
}


          r-version: ${{ MatchDataFrame <- function(data.to.match, data.to.permute) {
  ## Given two data frames with the same data, but with rows and
  ## columns in potentially different orders, produce a pair of
  ## permutations such that data.to.permute[row.permutation, column.permutation]
  ## matches data1 as close as possible.
  ##
  ## Args:
  ##   data.to.match:  The data frame to be matched.
  ##   data.to.permute:  The data frame to be permuted.
  ##
  ## Returns:
  ##   A list containing two vectors
  ##   * column.permutation: a vector of indices such that the columns
  ##     of data.to.permute[, column.permutation] are in the same
  ##     order as the columns of data.to.match.
  ##   * row.permutation: a vector of indices such that the rows of
  ##     data.to.permute[row.permutation, ] match the rows of
  ##     data.to.match.

  if (nrow(data.to.match) != nrow(data.to.permute) ||
      ncol(data.to.match) != ncol(data.to.permute)) {
    stop("Data are of different sizes")
  }
  column.permutation <- match(colnames(data.to.match),
                              colnames(data.to.permute),
                              nomatch = NA)
  if (any(is.na(column.permutation))) {
    stop("Not all columns could be matched.")
  }

  data.to.permute <- data.to.permute[, column.permutation]
  data.to.permute.row.strings <- apply(
      data.to.permute, 1, paste0, collapse = "|")
  data.to.match.row.strings <- apply(
      data.to.match, 1, paste0, collapse = "|")
  row.permutation <- match(data.to.match.row.strings,
                           data.to.permute.row.strings,
                           nomatch = NA)
  if (any(is.na(row.permutation))) {
    stop("Not all rows could be matched.")
  }
  return(list(column.permutation = column.permutation,
              row.permutation = row.permutation))
} }}
      - name: Install dependencies
        run: |
          install.packages(c("remotes", "rcmdcheck"))
          remotes::install_deps(dependencies = TRUE)
        shell: Rscript {0}
      - name: Check
        run: rcmdcheck::rcmdcheck(args = "--no-manual", error_on = "error")
        shell: Rscript {0}
