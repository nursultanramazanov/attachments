# This workflow will install Python dependencies, run tests and lint with a single version of Python
# For more information see: https://docs.github.com/en/actions/automating-builds-and-tests/building-and-testing-python

name: Python application

on: MIT License

Copyright (c) 2020 Unofficial-SchoolMouv

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
  push: import schoolmouv

# Videos
my_video = schoolmouv.video('https://www.schoolmouv.fr/cours/la-liberte-politique/cours-video')
my_video.run()
results = my_video.result # result found (list) (direct urls to mp4s)
my_video.download(results[0],'/path/to/folder',save_as='myvideo.mp4') # Default filename here is 'La liberte politique.mp4' (in this case)
my_video.see(results[0]) # Open in default browser

# PDFs
my_pdf = schoolmouv.pdf('https://www.schoolmouv.fr/cours/echantillonnage2/fiche-de-revision')
my_pdf.run()
result = my_pdf.result # result found (str) (direct url to pdf)
my_pdf.download(result,'/path/to/folder',save_as='mypdf.pdf') # Default filename is 'Echantillonage 2.pdf' (in this case)
my_pdf.see(result)
    branches: [ "main" ]
  pull_request: bs4
requests
    branches: [ "main" ]

permissions: """
@author:t0pl
Warning: gibberish code
This tool isn't affiliated to SchoolMouv in any way
"""
import requests
from bs4 import BeautifulSoup
import json
import os
import webbrowser


class resource:
    """Parent class
    Argument : url (str)
    Functions : validate -> bool : validation tests
                download -> None : download 'url' into 'into' (folder) as 'save_as' (filename, default:None)
                relevant_filename -> str : suggests a nice formatted filename
    """

    def __init__(self, url: str):
        self.url = url.split("#")[0].split("?")[0]

    def validate(self, url: str):
        # no to be used for security improvement
        pass

    def download(self, url: str, into: str, save_as=None, overwrite=False):
        if type(url) != str:
            print(f'URL needs to be a string, not a {type(url).__name__}')
            return False
        if not os.path.exists(into):
            print(
                f'No such folder, consider changing the value passed in the \'into\' parameter')
            return False
        assert self.validate(url)
        _ = requests.get(url)
        assert _.status_code == 200
        save_as = self.relevant_filename(url) if save_as == None else save_as
        abs_path = os.path.abspath(os.path.join(into, save_as))
        if os.path.exists(abs_path) and not overwrite:
            print("File already exists, set overwrite to True to overwrite it anyway")
            return False
        with open(abs_path, 'wb') as file_to_write:
            file_to_write.write(_.content)

    def relevant_filename(self, url: str):
        _ = ''
        __ = url.split('/')[-2].capitalize().replace('-', ' ')
        already_done = 0
        for caract in __:
            if already_done == 0 and caract.isnumeric():
                _ += ' '+caract
                already_done += 1
            else:
                _ += caract
        _ = _.replace('  ', ' ')
        return _+'.pdf' if url.endswith('.pdf') else _+'.mp4'

    def see(self, url: str):
        success = webbrowser.open_new_tab(url)
        if not success:
            return success


class video(resource):
    """
    Argument : url (str), for eg: https://www.schoolmouv.fr/cours/little-red-riding-hood/cours-video
    Functions : extract_json
                get_source
                get_direct_links
                get_soup
                ----------------
                validate
                download
    """

    def __init__(self, url: str):
        super().__init__(url)
        self.url = url
        self.useful_headers = {
            'Accept': '*/*',
            'Accept-Encoding': 'gzip, deflate, br',
            'Accept-Language': 'en-US,en;q=0.9,zh-CN;q=0.6,zh;q=0.5',
            'DNT': '1',
            'Referer': self.url,
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4130.0 Safari/537.36'
        }
        self.basic_headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4130.0 Safari/537.36 Edg/84.0.502.0'
        }

    def get_soup(self, url, headers={}):
        headers = self.basic_headers if headers == {} else headers
        for _ in range(5):
            po = requests.get(url, headers=headers)
            if po.status_code == 200:
                break
        return BeautifulSoup(po.content, 'html.parser')

    def extract_json(self, mess_up):
        mess_up = str(mess_up)
        mess_up = mess_up.split('};')[0]+'}'
        try:
            mess_up = '{'+mess_up.split('= {')[1]
        except IndexError:
            mess_up = '{'+mess_up.split('={')[1]
        mess_up = json.loads(mess_up)
        return mess_up

    def get_source(self, mess_up):
        assert 'sheet' in mess_up.keys()
        _r = []
        for _ in mess_up['sheet']['resources']:
            _source = mess_up['sheet']['resources'][_]['source']
            _r.append(_source)
        return list(set(_r))

    def get_direct_links(self, json_):
        # print(json_)
        assert 'request' in json_.keys()
        return list(set([i['url'] for i in json_['request']['files']['progressive']]))
        #keys : ['profile', 'width', 'mime', 'fps', 'url', 'cdn', 'quality', 'id', 'origin', 'height']

    def run(self):
        # 1st part
        # GET https://www.schoolmouv.fr/cours/little-red-riding-hood/cours-video
        soup = self.get_soup(self.url)
        script_tag_containing_json = [
            i for i in soup.find_all('script') if str(i).count("{") > 9]
        #assert len(script_tag_containing_json)==1
        # parsing json from <script> tag
        self.script_tag_containing_json = self.extract_json(
            script_tag_containing_json[0])
        # extract unique 9-digit id, different for each video
        sources = self.get_source(self.script_tag_containing_json)

        # 2nd part
        for _source in sources:
            assert len(_source) == 9 and _source.isalnum()
            # GET https://player.vimeo.com/video/9-DIGIT_ID?app_id=schoolmouv_app_id
            soup__ = self.get_soup(
                f'https://player.vimeo.com/video/{_source}', headers=self.useful_headers)  # ?app_id=122963
            script_tag_containing_mp4 = [
                i for i in soup__.find_all('script') if '.mp4' in str(i)]
            #assert len(script_tag_containing_mp4_content) == 1
            self.script_tag_containing_mp4 = self.extract_json(
                script_tag_containing_mp4)
            self.result = self.get_direct_links(self.script_tag_containing_mp4)

    def validate(self, url: str) -> bool:
        return url.endswith('.mp4') and url.startswith('https://vod-progressive.akamaized.net')


class pdf(resource):
    """
    Argument : url (str), for eg: https://www.schoolmouv.fr/cours/little-red-riding-hood/fiche-de-cours
    Functions : run
                download
    """

    def __init__(self, url):
        super().__init__(url)
        self.valids = [
            'scientifique',
            'mouvement-litteraire',
            'schema-bilan',
            'fiche-methode-bac',
            'fiche-de-revision',
            'demonstration',
            'repere',
            'personnages-historique',
            'lecon',
            'fiche-materiel',
            'evenement-historique',
            'savoir-faire',
            'fiche-methode',
            'bien-rediger',
            'fiche-pratique',
            'auteur',
            'philosophe',
            'formule-ses',
            'figure-de-style',
            'fiche-annale',
            'definition',
            'algorithme',
            'fiche-calculatrice',
            'courant-philosophique',
            'fiche-methode-brevet',
            'fiche-de-cours',
            'genre-litteraire',
            'registre-litteraire',
            'carte',
            'fiche-de-lecture',
            'fiche-oeuvre',
            'notion'
        ]
        self.url = url

    def run(self):
        if len([i for i in self.valids if i in self.url]) > 0:
            if self.url.startswith("https://www.schoolmouv.fr/"):
                TO_BE_REPLACED = "www.schoolmouv.fr/eleves" if "/eleves/" in self.url else "www.schoolmouv.fr"
                self.result = f"{self.url.replace(TO_BE_REPLACED,'pdf-schoolmouv.s3.eu-west-1.amazonaws.com')}.pdf"

    def validate(self, url: str) -> bool:
        return url.endswith('.pdf') and url.startswith('https://pdf-schoolmouv.s3.eu-west-1.amazonaws.com/')
  contents: read

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4
    - name: Set up Python 3.10
      uses: actions/setup-python@v3
      with:
        python-version: "3.10"
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install flake8 pytest
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
    - name: Lint with flake8
      run: |
        # stop the build if there are Python syntax errors or undefined names
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        # exit-zero treats all errors as warnings. The GitHub editor is 127 chars wide
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
    - name: Test with pytest
      run: |
        pytest
