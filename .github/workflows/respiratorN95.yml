# This workflow uses actions that are not certified by GitHub.  They are
# provided by a third-party and are governed by separate terms of service,
# privacy policy, and support documentation.
#
# This workflow will install a prebuilt Ruby version, install dependencies, and
# run tests and linters.
name: "Ruby on Rails CI"
on: FROM rocker/verse

ARG R_VERSION
ARG BUILD_DATE
ARG CRAN
ENV BUILD_DATE ${BUILD_DATE:-2020-05-20}
ENV R_VERSION=${R_VERSION:-3.6.3} \
    CRAN=${CRAN:-https://cran.rstudio.com} \ 
    TERM=xterm

# Set the locale
#RUN sed -i -e 's/# en_US.UTF-8 UTF-8/en_US.UTF-8 UTF-8/' /etc/locale.gen && \
#    locale-gen
ENV LANG en_US.UTF-8  
ENV LANGUAGE en_US:en  
ENV LC_ALL en_US.UTF-8   


RUN useradd docker \
        && mkdir /home/docker \
        && chown docker:docker /home/docker \
        && addgroup docker staff

RUN  apt-get update \
        && DEBIAN_FRONTEND="noninteractive" apt-get install -y --no-install-recommends \
  apt-utils \
  pandoc-citeproc lmodern

RUN R -e 'BiocManager::install("Icens")'

RUN install2.r --error \
    magrittr \ 
    interval \ 
    cgam \ 
    icenReg \ 
    km.ci \ 
    flexsurv \ 
    caret \ 
    tableone \ 
    PropCIs

WORKDIR /n95_refit

RUN git clone https://github.com/cryanking/n95_refit.git /n95_refit

RUN R -e 'rmarkdown::render("/n95_refit/n95_report.Rmd")' 



  push: Sex,Title,Respirator,Days Worn,Sterilizations,Uses,Uses per day,Fits well,Mask quality,Qualitative Fit
Male,Resident,3M 1804 Vflex,1,0,6,6,Yes,Like New,Fail
Male,Attending,3M 1804 Vflex,2,1,10,5,Yes,Like New,Pass
Female,Attending,3M 1804 Vflex,3,1,9,3,Yes,Like New,Fail
Female,Attending,3M 1804 Vflex,3,1,9,3,Yes,Like New,Pass
Male,Resident,3M 1804 Vflex,3,1,6,2,Yes,Like New,Pass
Female,CRNA,3M 1804 Vflex,3,0,9,3,Yes,Like New,Pass
Female,CRNA,3M 1804 Vflex,4,1,8,2,Yes,Like New,Fail
Female,CRNA,3M 1804 Vflex,4,1,6,1.5,Yes,Like New,Fail
Female,CRNA,3M 1804 Vflex,4,0,9,2.25,No,Good,Fail
Male,Attending,3M 1804 Vflex,4,0,60,15,Yes,Like New,Pass
Male,Attending,3M 1804 Vflex,4,0,60,15,Yes,Like New,Pass
Male,Attending,3M 1804 Vflex,4,0,10,2.5,Yes,Like New,Pass
Female,Resident,3M 1804 Vflex,4,0,20,5,Yes,Like New,Pass
Male,Resident,3M 1804 Vflex,5,2,20,4,Yes,Good,Fail
Female,CRNA,3M 1804 Vflex,5,1,10,2,No,Good,Fail
Female,Resident,3M 1804 Vflex,5,0,30,6,Yes,Like New,Fail
Female,CRNA,3M 1804 Vflex,5,1,12,2.4,Yes,Good,Fail
Female,CRNA,3M 1804 Vflex,5,1,10,2,No,Poor,Fail
Female,CRNA,3M 1804 Vflex,5,2,10,2,Yes,Like New,Fail
Female,CRNA,3M 1804 Vflex,5,1,12,2.4,Yes,Like New,Fail
Male,Resident,3M 1804 Vflex,5,0,20,4,Yes,Like New,Pass
Male,CRNA,3M 1804 Vflex,5,1,20,4,Yes,Like New,Pass
Male,CRNA,3M 1804 Vflex,5,0,16,3.2,Yes,Good,Pass
Female,CRNA,3M 1804 Vflex,6,1,18,3,Yes,Good,Fail
Female,CRNA,3M 1804 Vflex,6,0,12,2,Yes,Like New,Fail
Male,CRNA,3M 1804 Vflex,6,0,18,3,Yes,Like New,Pass
Female,Resident,3M 1804 Vflex,6,0,6,1,Yes,Like New,Pass
Female,Resident,3M 1804 Vflex,6,3,30,5,Yes,Good,Pass
Female,CRNA,3M 1804 Vflex,6,1,16,2.66666666666667,No,Like New,Pass
Female,CRNA,3m 1860 Teal,6,0,12,2,Yes,Like New,Pass
Female,CRNA,3M 1804 Vflex,7,0,15,2.14285714285714,Yes,Good,Fail
Female,CRNA,3M 1804 Vflex,7,0,15,2.14285714285714,Yes,Good,Fail
Male,Resident,3M 1804 Vflex,7,0,14,2,Yes,Good,Fail
Female,CRNA,3M 1804 Vflex,7,2,28,4,Yes,Poor,Fail
Male,Attending,3M 1804 Vflex,7,1,40,5.71428571428571,Yes,Like New,Pass
Male,CRNA,3M 1804 Vflex,7,0,20,2.85714285714286,Yes,Like New,Pass
Female,Resident,3M 1804 Vflex,7,0,15,2.14285714285714,Yes,Like New,Pass
Female,CRNA,3M 1804 Vflex,8,1,32,4,Yes,Good,Fail
Male,CRNA,3M 1804 Vflex,8,3,24,3,Yes,Good,Pass
Female,CRNA,3M 1804 Vflex,9,0,40,4.44444444444444,No,Good,Fail
Male,Attending,3M 1804 Vflex,10,0,60,6,Yes,Good,Fail
Male,CRNA,3M 1804 Vflex,10,1,15,1.5,Yes,Like New,Fail
Male,Resident,3M 1804 Vflex,10,1,36,3.6,Yes,Good,Pass
Female,Attending,3M 1804 Vflex,10,0,25,2.5,Yes,Good,Pass
Female,Fellow,3M 1804 Vflex,10,0,20,2,Yes,Like New,Pass
Male,CRNA,3M 1804 Vflex,10,0,10,1,Yes,Like New,Pass
Male,CRNA,3M 1804 Vflex,10,1,15,1.5,Yes,Like New,Pass
Female,Attending,3m 1860 Teal,10,1,60,6,Yes,Like New,Pass
Female,CRNA,3m 1860 Teal,10,1,60,6,Yes,Poor,Pass
Male,Attending,3M 1804 Vflex,11,2,40,3.63636363636364,Yes,Good,Fail
Male,Resident,3M 1804 Vflex,11,2,15,1.36363636363636,No,Good,Fail
Female,Attending,3M 1804 Vflex,12,1,60,5,No,Good,Fail
Female,CRNA,3M 1804 Vflex,12,1,15,1.25,No,Good,Fail
Male,CRNA,3M 1804 Vflex,12,1,40,3.33333333333333,Yes,Good,Fail
Female,CRNA,3M 1804 Vflex,12,1,15,1.25,Yes,Good,Fail
Female,Attending,3M 1804 Vflex,12,1,50,4.16666666666667,Yes,Good,Pass
Male,Attending,3M 1804 Vflex,12,0,12,1,Yes,Like New,Pass
Male,CRNA,3M 1804 Vflex,12,2,30,2.5,Yes,Good,Pass
Female,Fellow,3m 1860 Teal,13,0,26,2,Yes,Good,Fail
Female,CRNA,3m 1860 Teal,13,1,35,2.69230769230769,Yes,Poor,Fail
Female,Resident,3M 1804 Vflex,14,1,20,1.42857142857143,Yes,Like New,Pass
Male,Resident,3M 1804 Vflex,14,2,15,1.07142857142857,Yes,Like New,Pass
Female,CRNA,3m 1860 Teal,14,1,50,3.57142857142857,Yes,Good,Pass
Female,CRNA,3M 1804 Vflex,15,3,30,2,No,Good,Fail
Female,CRNA,3M 1804 Vflex,15,1,30,2,Yes,Good,Fail
Female,CRNA,3m 1860 Teal,15,1,40,2.66666666666667,Yes,Good,Fail
Male,Resident,3M 1804 Vflex,15,1,30,2,Yes,Good,Pass
Female,CRNA,3m 1860 Teal,15,1,50,3.33333333333333,Yes,Like New,Pass
Female,CRNA,3M 1804 Vflex,20,3,35,1.75,Yes,Poor,Fail
Female,Resident,3M 1804 Vflex,20,4,35,1.75,No,Good,Fail
Female,CRNA,3M 1804 Vflex,20,2,40,2,No,Good,Pass
Female,CRNA,3M 1804 Vflex,30,6,180,6,No,Good,Fail
Female,CRNA,3m 1860 Teal,40,2,60,1.5,Yes,Like New,Fail
Male,CRNA,3m 1860 Teal,60,4,180,3,Yes,Good,Pass
    branches: [ "main" ]
  pull_request: 
@article{vandormael_estimating_2019,
        title = {Estimating trends in the incidence rate with interval censored data and time-dependent covariates:},
        url = {https://journals.sagepub.com/doi/full/10.1177/0962280219829892},
        doi = {10.1177/0962280219829892},
        shorttitle = {Estimating trends in the incidence rate with interval censored data and time-dependent covariates},
        abstract = {We propose a multiple imputation method for estimating the incidence rate with interval censored data and time-dependent (and/or time-independent) covariates. T...},
        journaltitle = {Statistical Methods in Medical Research},
        author = {Vandormael, Alain and Tanser, Frank and Cuadros, Diego and Dobra, Adrian},
        urldate = {2020-05-25},
        date = {2019-02-19},
        langid = {english},
        note = {Publisher: {SAGE} {PublicationsSage} {UK}: London, England},
        file = {Snapshot:/home/ryan/Zotero/storage/YU742AJ5/0962280219829892.html:text/html}
}

@article{heller_proportional_2011,
        title = {Proportional hazards regression with interval censored data using an inverse probability weight},
        volume = {17},
        issn = {1380-7870},
        url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5499516/},
        doi = {10.1007/s10985-010-9191-8},
        abstract = {The prevalence of interval censored data is increasing in medical studies due to the growing use of biomarkers to define a disease progression endpoint. Interval censoring results from periodic monitoring of the progression status. For example, disease progression is established in the interval between the clinic visit where progression is recorded and the prior clinic visit where there was no evidence of disease progression. A methodology is proposed for estimation and inference on the regression coefficients in the Cox proportional hazards model with interval censored data. The methodology is based on estimating equations and uses an inverse probability weight to select event time pairs where the ordering is unambiguous. Simulations are performed to examine the finite sample properties of the estimate and a colon cancer data set is used to demonstrate its performance relative to the conventional partial likelihood estimate that ignores the interval censoring.},
        pages = {373--385},
        number = {3},
        journaltitle = {Lifetime data analysis},
        shortjournal = {Lifetime Data Anal},
        author = {Heller, Glenn},
        urldate = {2020-05-25},
        date = {2011-07},
        pmid = {21191653},
        pmcid = {PMC5499516},
        file = {PubMed Central Full Text PDF:/home/ryan/Zotero/storage/GA62YYSW/Heller - 2011 - Proportional hazards regression with interval cens.pdf:application/pdf}
}

@article{wang_flexible_2016,
        title = {A Flexible, Computationally Efficient Method for Fitting the Proportional Hazards Model to Interval-Censored Data},
        volume = {72},
        issn = {0006-341X},
        url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4803641/},
        doi = {10.1111/biom.12389},
        abstract = {The proportional hazards model ({PH}) is currently the most popular regression model for analyzing time-to-event data. Despite its popularity, the analysis of interval-censored data under the {PH} model can be challenging using many available techniques. This paper presents a new method for analyzing interval-censored data under the {PH} model. The proposed approach uses a monotone spline representation to approximate the unknown nondecreasing cumulative baseline hazard function. Formulating the {PH} model in this fashion results in a finite number of parameters to estimate while maintaining substantial modeling flexibility. A novel expectation-maximization ({EM}) algorithm is developed for finding the maximum likelihood estimates of the parameters. The derivation of the {EM} algorithm relies on a two-stage data augmentation involving latent Poisson random variables. The resulting algorithm is easy to implement, robust to initialization, enjoys quick convergence, and provides closed-form variance estimates. The performance of the proposed regression methodology is evaluated through a simulation study, and is further illustrated using data from a large population-based randomized trial designed and sponsored by the United States National Cancer Institute.},
        pages = {222--231},
        number = {1},
        journaltitle = {Biometrics},
        shortjournal = {Biometrics},
        author = {Wang, Lianming and {McMahan}, Christopher S. and Hudgens, Michael G. and Qureshi, Zaina P.},
        urldate = {2020-05-25},
        date = {2016-03},
        pmid = {26393917},
        pmcid = {PMC4803641},
        file = {PubMed Central Full Text PDF:/home/ryan/Zotero/storage/Y76LRP5W/Wang et al. - 2016 - A Flexible, Computationally Efficient Method for F.pdf:application/pdf}
}

@article{bouaziz_regression_2018,
        title = {Regression modelling of interval censored data based on the adaptive ridge procedure},
        url = {http://arxiv.org/abs/1812.09158},
        abstract = {We consider the Cox model with piecewise constant baseline hazard to deal with a mixed case of left-censored, interval-censored and right-censored data. Estimation is carried out with the {EM} algorithm by treating the true event times as unobserved variables. This estimation procedure is shown to produce a block diagonal Hessian matrix of the baseline parameters. Taking advantage of this interesting feature of the estimation procedure a L0 penalised likelihood method is implemented in order to automatically determine the number and locations of the cuts of the baseline hazard. The method is directly extended to the inclusion of exact observations and to a cure fraction. Statistical inference of the model parameters is derived from likelihood theory. Through simulation studies, the penalisation technique is shown to provide a good ﬁt of the baseline hazard and precise estimations of the resulting regression parameters. The method is illustrated on a dental dataset where the eﬀect of covariates on the risk of ankylosis for replanted teeth is assessed.},
        journaltitle = {{arXiv}:1812.09158 [stat]},
        author = {Bouaziz, Olivier and Lauridsen, Eva and Nuel, Grégory},
        urldate = {2020-05-25},
        date = {2018-12-21},
        langid = {english},
        eprinttype = {arxiv},
        eprint = {1812.09158},
        keywords = {Statistics - Methodology},
        file = {Bouaziz et al. - 2018 - Regression modelling of interval censored data bas.pdf:/home/ryan/Zotero/storage/TBRSNCJG/Bouaziz et al. - 2018 - Regression modelling of interval censored data bas.pdf:application/pdf}
}

@article{zhao_simultaneous_2019,
        title = {Simultaneous Estimation and Variable Selection for Interval-Censored Data With Broken Adaptive Ridge Regression},
        rights = {© 2019 American Statistical Association},
        issn = {10.1080/01621459.2018.1537922},
        url = {https://amstat.tandfonline.com/doi/abs/10.1080/01621459.2018.1537922},
        abstract = {(2020). Simultaneous Estimation and Variable Selection for Interval-Censored Data With Broken Adaptive Ridge Regression. Journal of the American Statistical Association: Vol. 115, No. 529, pp. 204-216.},
        journaltitle = {Journal of the American Statistical Association},
        author = {Zhao, Hui and Wu, Qiwei and Li, Gang and Sun, Jianguo},
        urldate = {2020-05-25},
        date = {2019-04-22},
        langid = {english},
        note = {Publisher: Taylor \& Francis}
}

@article{li_adaptive_2019,
        title = {Adaptive lasso for the Cox regression with interval censored and possibly left truncated data:},
        url = {https://journals.sagepub.com/doi/full/10.1177/0962280219856238},
        doi = {10.1177/0962280219856238},
        shorttitle = {Adaptive lasso for the Cox regression with interval censored and possibly left truncated data},
        abstract = {We propose a penalized variable selection method for the Cox proportional hazards model with interval censored data. It conducts a penalized nonparametric maxim...},
        journaltitle = {Statistical Methods in Medical Research},
        author = {Li, Chenxi and Pak, Daewoo and Todem, David},
        urldate = {2020-05-25},
        date = {2019-06-16},
        langid = {english},
        note = {Publisher: {SAGE} {PublicationsSage} {UK}: London, England}
}

@book{groeneboom_information_1992,
        title = {Information Bounds and Nonparametric Maximum Likelihood Estimation},
        isbn = {978-3-7643-2794-1},
        url = {https://www.springer.com/gp/book/9783764327941},
        series = {Oberwolfach Seminars},
        abstract = {This book contains the lecture notes for a {DMV} course presented by the authors at Gunzburg, Germany, in September, 1990. In the course we sketched the theory of information bounds for non parametric and semiparametric models, and developed the theory of non parametric maximum likelihood estimation in several particular inverse problems: interval censoring and deconvolution models. Part I, based on Jon Wellner's lectures, gives a brief sketch of information lower bound theory: Hajek's convolution theorem and extensions, useful minimax bounds for parametric problems due to Ibragimov and Has'minskii, and a recent result characterizing differentiable functionals due to van der Vaart (1991). The differentiability theorem is illustrated with the examples of interval censoring and deconvolution (which are pursued from the estimation perspective in part {II}). The differentiability theorem gives a way of clearly distinguishing situations in which 1 2 the parameter of interest can be estimated at rate n / and situations in which this is not the case. However it says nothing about which rates to expect when the functional is not differentiable. Even the casual reader will notice that several models are introduced, but not pursued in any detail; many problems remain. Part {II}, based on Piet Groeneboom's lectures, focuses on non parametric maximum likelihood estimates ({NPMLE}'s) for certain inverse problems. The first chapter deals with the interval censoring problem.},
        publisher = {Birkhäuser Basel},
        author = {Groeneboom, P. and Wellner, J. A.},
        urldate = {2020-05-26},
        date = {1992},
        langid = {english},
        doi = {10.1007/978-3-0348-8621-5},
        file = {Snapshot:/home/ryan/Zotero/storage/69R843P3/9783764327941.html:text/html}
}

@article{lindsey_study_1998,
        title = {A study of interval censoring in parametric regression models},
        volume = {4},
        issn = {1380-7870},
        doi = {10.1023/a:1009681919084},
        abstract = {Parametric models for interval censored data can now easily be fitted with minimal programming in certain standard statistical software packages. Regression equations can be introduced, both for the location and for the dispersion parameters. Finite mixture models can also be fitted, with a point mass on right (or left) censored observations, to allow for individuals who cannot have the event (or already have it). This mixing probability can also be allowed to follow a regression equation. Here, models based on nine different distributions are compared for three examples of heavily censored data as well as a set of simulated data. We find that, for parametric models, interval censoring can often be ignored and that the density, at centres of intervals, can be used instead in the likelihood function, although the approximation is not always reliable. In the context of heavily interval censored data, the conclusions from parametric models are remarkably robust with changing distributional assumptions and generally more informative than the corresponding non-parametric models.},
        pages = {329--354},
        number = {4},
        journaltitle = {Lifetime Data Analysis},
        shortjournal = {Lifetime Data Anal},
        author = {Lindsey, J. K.},
        date = {1998},
        pmid = {9880994},
        keywords = {Animals, Biometry, Breast Neoplasms, Data Interpretation, Statistical, Disease-Free Survival, Female, Fishes, {HIV} Infections, Humans, Incidence, Models, Statistical, Normal Distribution, Regression Analysis, Statistics, Nonparametric, Survival Rate, Zinc}
}

@article{liao_cgam_2019,
        title = {cgam: An R Package for the Constrained Generalized Additive Model},
        volume = {89},
        rights = {Copyright (c) 2019 Xiyue Liao, Mary C. Meyer},
        issn = {1548-7660},
        url = {https://www.jstatsoft.org/index.php/jss/article/view/v089i05},
        doi = {10.18637/jss.v089.i05},
        shorttitle = {cgam},
        pages = {1--24},
        number = {1},
        journaltitle = {Journal of Statistical Software},
        
        urldate = {2020-05-26},
        date = {2019-05-10},
        langid = {english},
        note = {Number: 1},
        keywords = {constrained generalized additive model, graphical routine, isotonic regression, iteratively re-weighted cone projection, partial linear, R, spline regression},
        file = {Full Text PDF:/home/ryan/Zotero/storage/DUNV9JW5/Liao and Meyer - 2019 - cgam An R Package for the Constrained Generalized.pdf:application/pdf;Snapshot:/home/ryan/Zotero/storage/M8M2A7XS/v089i05.html:text/html}
}

@article{jackson_flexsurv_2016,
        title = {flexsurv: A Platform for Parametric Survival Modeling in R},
        volume = {70},
        rights = {Copyright (c) 2016 Christopher Jackson},
        issn = {1548-7660},
        url = {https://www.jstatsoft.org/index.php/jss/article/view/v070i08},
        doi = {10.18637/jss.v070.i08},
        shorttitle = {flexsurv},
        pages = {1--33},
        number = {1},
        journaltitle = {Journal of Statistical Software},
        author = {Jackson, Christopher},
        urldate = {2020-05-26},
        date = {2016-05-12},
        langid = {english},
        note = {Number: 1},
        keywords = {multi-state models, multistate models, survival},
        file = {Full Text:/home/ryan/Zotero/storage/H4NEZ4GC/Jackson - 2016 - flexsurv A Platform for Parametric Survival Model.pdf:application/pdf;Snapshot:/home/ryan/Zotero/storage/LC9NLU55/v070i08.html:text/html}
}

@article{anderson-bergman_icenreg_2017,
        title = {{icenReg}: Regression Models for Interval Censored Data in R},
        volume = {81},
        rights = {Copyright (c) 2017 Clifford Anderson-Bergman},
        issn = {1548-7660},
        url = {https://www.jstatsoft.org/index.php/jss/article/view/v081i12},
        doi = {10.18637/jss.v081.i12},
        shorttitle = {{icenReg}},
        pages = {1--23},
        number = {1},
        journaltitle = {Journal of Statistical Software},
        author = {Anderson-Bergman, Clifford},
        urldate = {2020-05-26},
        date = {2017-11-13},
        langid = {english},
        note = {Number: 1},
        keywords = {accelerated failure time, interval censoring, non-parametric, proportional hazards, proportional odds, semi-parametric regression, survival analysis},
        file = {Full Text:/home/ryan/Zotero/storage/88DZJ3VM/Anderson-Bergman - 2017 - icenReg Regression Models for Interval Censored D.pdf:application/pdf;Snapshot:/home/ryan/Zotero/storage/9PCIZ4VD/v081i12.html:text/html}
}
    branches: [ "main" ]
jobs: library(magrittr)
library(tidyverse)
library(survival)
library("interval")
library(cgam)
library(icenReg)
library("km.ci")
library(flexsurv)
library(tableone)
set.seed(101)

missing_packages <- setdiff(c("caret", "tableone", "rmarkdown", "knitr", "bookdown") , rownames(installed.packages() ) ) 

if(length(missing_packages) > 0) {
stop(paste("install" , paste0(missing_packages, collapse =" , ") ))
}
##############
#### data load and procesing
##############
prelim.df <- read_csv(file="Final Pilot Data.csv")

## this variable controls the minimum amount of time a mask is assumed to function; the analysis assumes ALL masks functioned before this time since all users had passed fit tests and masks undergo factory qc. it is expressed in days
immortal_time <- 0.5

## drop the redundant column
names(prelim.df) %<>% make.names
prelim.df %<>% rename(fit.fail = Qualitative.Fit)
prelim.df %<>% mutate(fit.fail = fit.fail == "Fail")
prelim.df %<>% mutate_if( .predicate=is.character, factor)
prelim.df %<>% mutate_at(vars(one_of("fit.fail","Days.Worn", "Sterilizations", "Uses")), as.integer  )
prelim.df %<>% mutate(left=if_else(fit.fail==1, immortal_time, as.numeric(Days.Worn)  ) , right=if_else(fit.fail==1, as.numeric(Days.Worn), as.numeric(max(Days.Worn )*3 )  )   )

##############
### cross-sectional analysis
##############

## this is my preferred estimate
cross_fit <- cgam(fit.fail ~ s.incr(Days.Worn) , family=binomial(), data=prelim.df )
dummy_data <- data.frame(Days.Worn = 4:20)
dummy_data <- cbind(dummy_data, predict(cross_fit, newData=dummy_data, interval="confidence")[c("fit", "lower", "upper")] %>% as.data.frame )

dummy_data %<>% filter(Days.Worn %in% c(5,10,15) )
dummy_data



## supplement plot comparing methods
## black = non-parametric monotone decreasing (no smoothness constrain), identical to the nonparametric survival estimator
## red = smooth monotone decreasing (spline basis, constrained)
## blue = smooth no monotone requirement (spline bases)
## conclusion: extremely similar, observed fit failure pretty flat across time
cross_fit <- cgam(fit.fail ~ incr(Days.Worn) , family=binomial(), data=prelim.df )
dummy_data <- data.frame(Days.Worn = 4:20)
dummy_data <- cbind(dummy_data, predict(cross_fit, newData=dummy_data, interval="confidence")[c("fit", "lower", "upper")] %>% as.data.frame )
plot(dummy_data$Days.Worn, dummy_data$fit , xlab="Days Used", ylab="Failure probability", ylim=c(0,1), xlim=c(2,20), type="b", pch=19)
lines(dummy_data$Days.Worn, dummy_data$lower, lty=2)
lines(dummy_data$Days.Worn, dummy_data$upper, lty=2)

cross_fit <- cgam(fit.fail ~ s.incr(Days.Worn) , family=binomial(), data=prelim.df )
dummy_data <- data.frame(Days.Worn = 4:20)
dummy_data <- cbind(dummy_data, predict(cross_fit, newData=dummy_data, interval="confidence")[c("fit", "lower", "upper")] %>% as.data.frame )
points(dummy_data$Days.Worn, dummy_data$fit , col='red', type="b", pch=19)
lines(dummy_data$Days.Worn, dummy_data$lower, col='red', lty=2)
lines(dummy_data$Days.Worn, dummy_data$upper, col='red', lty=2)


cross_fit <- glm(fit.fail ~ ns(Days.Worn) , family=binomial(), data=prelim.df )
dummy_data <- data.frame(Days.Worn = 4:20)
dummy_data <- cbind(dummy_data, predict(cross_fit, newdata=dummy_data, se.fit=TRUE)[c("fit", "se.fit")] %>% as.data.frame )

points(dummy_data$Days.Worn, cross_fit$family$linkinv(dummy_data$fit) , col='blue', type="b", pch=19)
dummy_data %<>% mutate( lower=cross_fit$family$linkinv(fit - 1.96*se.fit), upper=cross_fit$family$linkinv(fit+1.96*se.fit))
lines(dummy_data$Days.Worn, dummy_data$lower, col='blue', lty=2)
lines(dummy_data$Days.Worn, dummy_data$upper, col='blue', lty=2)




## supplement plot comparing methods
## black = nonparametric survival estimator with bootstrap (interval package)
## red = parametric survival (generalized gamma)
## blue = monotone smooth spline
## conclusion: survival model forces the early survival upwards
npm_out <- icfit( Surv( left, right, type = "interval2") ~ 1, data = prelim.df, conf.int=TRUE, control = icfitControl(B=2000,seed=1234))
fs_1 <- flexsurvreg(Surv(left, right, type="interval2")~1, data=prelim.df, dist="gengamma")
cross_fit <- cgam(I(1L-fit.fail) ~ s.decr(Days.Worn) , family=binomial(), data=prelim.df )
# fs_2 <- flexsurvspline(Surv(left, right, type="interval2")~1, data=prelim.df, timescale="log", k=1L) ## opaque error



npm_out %>% plot(xlim=c(2,20))
lines(fs_1)
dummy_data <- data.frame(Days.Worn = 2:20)
dummy_data <- cbind(dummy_data, predict(cross_fit, newData=dummy_data, interval="confidence")[c("fit", "lower", "upper")] %>% as.data.frame )
lines(dummy_data$Days.Worn, dummy_data$fit , col='blue', lwd=2)
lines(dummy_data$Days.Worn, dummy_data$lower, col='blue', lty=2)
lines(dummy_data$Days.Worn, dummy_data$upper, col='blue', lty=2)

##ICsurv method, is similar
if(FALSE) {
exp_res<-ICsurv::fast.PH.ICsurv.EM(d1=rep(0L, nrow(prelim.df)), d3=rep(0L, nrow(prelim.df)), d2=rep(1L, nrow(prelim.df)), Li=prelim.df$left, Ri=prelim.df$right, Xp=matrix(runif(nrow(prelim.df)), ncol=1) , n.int=3, order=3, g0=rep(1, 3+3) , b0=rep(0,1L), tol=0.001, equal=TRUE, t.seq=4:20)

points(dummy_data$Days.Worn, 1.-exp_res$hz, col="green", type="b", pch=19)
}

## same calculation, different package to check
if(FALSE) {
alt_np <- ic_np(cbind(left, right)~0, data=prelim.df )
getSCurves(alt_np )
}



## supplement plot: comparison of parametric survival families
## conclusion : very similar , generalized gamma probably the best fitting

## to show added uncertainty from the distribution choice
npm_out %>% plot(xlim=c(2,20))
lines(fs_1, type = "survival", col="red")

fs2 <- flexsurvreg(Surv(left, right, type="interval2")~1, data = prelim.df, dist="gompertz")
lines(fs2, type = "survival", col="blue")

fs2 <- flexsurvreg(Surv(left, right, type="interval2")~1, data = prelim.df, dist="weibull")
lines(fs2, type = "survival", col="green")



## supplement plot: comparison of interval censored and "traditional" survival analysis
## conclusion: traditional survival badly biased (as expected)
npm_out %>% plot(xlim=c(2,20))
lines(km.ci(survfit(Surv(time=Days.Worn, event=fit.fail)~1, data=prelim.df) ), col='red')




## analytical claims:
## 1: # steralizations doesn't matter conditional on number of days
## survival semi-para: 0.17 +- 0.27 log scale
## cross-sectional semi-para: .34 +- .34
np_reg <- ic_sp(cbind(left, right)~Sterilizations, data=prelim.df, bs_samples = 1000  )
np_reg %>% summary

cross_fit <- glm(fit.fail ~ ns(Days.Worn) , family=binomial(), data=prelim.df )
cross_fit2 <- glm(fit.fail ~ ns(Days.Worn) +Sterilizations  , family=binomial(), data=prelim.df )
anova(cross_fit2, cross_fit, test="LRT")
cross_fit2 %>% summary
glm(fit.fail ~ Sterilizations , family=binomial(), data=prelim.df ) %>% summary


## 2: number of times donned doesn't matter
##  survival semi-para: -0.005 +- 0.23 log scale
##  cross sectional: -0.0007505  0.0243780
np_reg2a <- ic_sp(cbind(left, right)~Uses, data=prelim.df, bs_samples = 1000  )
np_reg2a %>% summary

cross_fit <- glm(fit.fail ~ ns(Days.Worn) , family=binomial(), data=prelim.df )
cross_fit2 <- glm(fit.fail ~ ns(Days.Worn) +Uses  , family=binomial(), data=prelim.df )
anova(cross_fit2, cross_fit, test="LRT")
cross_fit2 %>% summary
glm(fit.fail ~ Uses , family=binomial(), data=prelim.df ) %>% summary

## 2b per day
## 0.01764 0.1975
## -0.05921    0.22283
np_reg2b <- ic_sp(cbind(left, right)~I(Uses/Days.Worn), data=prelim.df, bs_samples = 1000  )
np_reg2b %>% summary

cross_fit <- glm(fit.fail ~ ns(Days.Worn) , family=binomial(), data=prelim.df )
cross_fit2 <- glm(fit.fail ~ ns(Days.Worn) +I(Uses/Days.Worn)  , family=binomial(), data=prelim.df )
anova(cross_fit2, cross_fit, test="LRT")
cross_fit2 %>% summary
glm(fit.fail ~ I(Uses/Days.Worn) , family=binomial(), data=prelim.df ) %>% summary

## 3: assessment of fit probably does matter
##  -1.071  2.412 decent sized effect!
##  -1.8021     0.8696 p 0.02249 by lrt
##  about the same in marginal model -1.8137     0.8574    0.0344 * (p=.033 by fet)

np_reg3 <- ic_sp(cbind(left, right)~Fits.well, data=prelim.df, bs_samples = 1000  )
np_reg3 %>% summary

cross_fit <- glm(fit.fail ~ ns(Days.Worn) , family=binomial(), data=prelim.df )
cross_fit2 <- glm(fit.fail ~ ns(Days.Worn) +Fits.well  , family=binomial(), data=prelim.df )
anova(cross_fit2, cross_fit, test="LRT")
cross_fit2 %>% summary
glm(fit.fail ~ Fits.well , family=binomial(), data=prelim.df ) %>% summary
prelim.df %>% group_by(Fits.well) %>% summarize(mean(fit.fail ), n())
prelim.df %>% group_by(fit.fail) %>% summarize(mean(as.integer(Fits.well )-1), n())
fisher.test(prelim.df$Fits.well, prelim.df$fit.fail)

## also available as a test: the method matters, the more conservative one does not reject, the more analytical one is marginal
## p=.052, .145
np_test3 <- ictest(Surv( left, right, type = "interval2") ~ Fits.well, data = prelim.df)
np_test3 <- ictest(Surv( left, right, type = "interval2") ~ Fits.well, data = prelim.df, method="wsr.mc")


## plot the difference
## no obvious change in time, both are pretty flat. it's just an offset
# alt_np3 <- icfit( Surv( left, right, type = "interval2") ~ Fits.well, data = prelim.df, conf.int=TRUE, control = icfitControl(B=2000,seed=1234))
# alt_np3 %>% plot(xlim=c(2,20)) # this plot is hard to control

cross_fit2 <- cgam(I(1L-fit.fail) ~ s.decr(Days.Worn)*Fits.well  , family=binomial(), data=prelim.df )

npm_out %>% plot(xlim=c(2,20))

dummy_data <- data.frame(Days.Worn = 4:20 , Fits.well =prelim.df$Fits.well %>% unique %>% magrittr::extract(1) )
dummy_data <- cbind(dummy_data, predict(cross_fit2, newData=dummy_data, interval="confidence")[c("fit", "lower", "upper")] %>% as.data.frame )
lines(dummy_data$Days.Worn, dummy_data$fit , col='red', lwd=2)
lines(dummy_data$Days.Worn, dummy_data$lower, col='red', lty=2)
lines(dummy_data$Days.Worn, dummy_data$upper, col='red', lty=2)

dummy_data <- data.frame(Days.Worn = 4:20 , Fits.well =prelim.df$Fits.well %>% unique %>% magrittr::extract(2) )
dummy_data <- cbind(dummy_data, predict(cross_fit2, newData=dummy_data, interval="confidence")[c("fit", "lower", "upper")] %>% as.data.frame )
lines(dummy_data$Days.Worn, dummy_data$fit , col='blue', lwd=2)
lines(dummy_data$Days.Worn, dummy_data$lower, col='blue', lty=2)
lines(dummy_data$Days.Worn, dummy_data$upper, col='blue', lty=2)


# dummy_data <- cbind(dummy_data, predict(cross_fit2, newdata=dummy_data, se.fit=TRUE)[c("fit", "se.fit")] %>% as.data.frame )
# lines(dummy_data$Days.Worn, cross_fit2$family$linkinv(dummy_data$fit) , col='blue')
# dummy_data %<>% mutate( lower=cross_fit$family$linkinv(fit - 1.96*se.fit), upper=cross_fit$family$linkinv(fit+1.96*se.fit))
# lines(dummy_data$Days.Worn, dummy_data$lower, col='blue', lty=2)
# lines(dummy_data$Days.Worn, dummy_data$upper, col='blue', lty=2)

# dummy_data <- data.frame(Days.Worn = 4:20 , Fits.well =prelim.df$Fits.well %>% unique %>% magrittr::extract(2) )
# dummy_data <- cbind(dummy_data, predict(cross_fit2, newdata=dummy_data, se.fit=TRUE)[c("fit", "se.fit")] %>% as.data.frame )
# lines(dummy_data$Days.Worn, cross_fit2$family$linkinv(dummy_data$fit) , col='red')
# dummy_data %<>% mutate( lower=cross_fit$family$linkinv(fit - 1.96*se.fit), upper=cross_fit$family$linkinv(fit+1.96*se.fit))
# lines(dummy_data$Days.Worn, dummy_data$lower, col='red', lty=2)
# lines(dummy_data$Days.Worn, dummy_data$upper, col='red', lty=2)
# 


#############
## plots by # donned
## supplemental: comparison of methods
prelim.df2 <-prelim.df %>% mutate(left=if_else(fit.fail==1, 1, as.numeric(Uses)  ) , right=if_else(fit.fail==1, as.numeric(Uses), as.numeric(max(Uses )*3 )  )   )

npm_out2 <- icfit( Surv( left, right, type = "interval2") ~ 1, data = prelim.df2, conf.int=TRUE, control = icfitControl(B=2000,seed=1234))

fs3 <- flexsurvreg(Surv(left, right, type="interval2")~1, dist="gengamma", data=prelim.df2)
npm_out2 %>% plot( xlim=c(2,50) )
lines(fs3, col="blue")

## for purposes of this plot, uses are only drawn out to 50. the right outlier makes the spline fit unstable
cross_fit3 <- cgam(I(1L-fit.fail) ~ s.decr(Uses) , family=binomial(), data=prelim.df %>% mutate(Uses = pmin(Uses, 70)) )
dummy_data <- data.frame(Uses = 6:50)
dummy_data <- cbind(dummy_data, predict(cross_fit3, newData=dummy_data, interval="confidence")[c("fit", "lower", "upper")] %>% as.data.frame )
lines(dummy_data$Uses, dummy_data$fit , col='red', lwd=2)
lines(dummy_data$Uses, dummy_data$lower, col='red', lty=2)
lines(dummy_data$Uses, dummy_data$upper, col='red', lty=2)


save(file="n95_intermediates.Rdata", prelim.df, prelim.df2, npm_out2, npm_out, np_test3, np_reg3, np_reg2b, np_reg2a, np_reg)




prelim.df %>% group_by(fit.fail) %>% summarize(sum(as.integer(Fits.well )-1), n())

temp <- prelim.df %>% filter(fit.fail==1) %>% summarize(sum(as.integer(Fits.well )-1), n()) %>% unlist
prop.test(x=temp[1], n=temp[2]) %>% extract2("conf.int") %>% multiply_by(100) %>% round


temp <- prelim.df %>% filter(fit.fail==1) %>% mutate(Mask.quality=Mask.quality %in% c("Like New", "Good") ) %>% summarize(sum(as.integer(Mask.quality )), n()) %>% unlist
prop.test(x=temp[1], n=temp[2]) %>% extract2("conf.int") %>% multiply_by(100) %>% round


# PropCIs::scoreci(x=temp[1], n=temp[2], conf.level=0.95) %>% extract2("conf.int") %>% multiply_by(100) %>% round

with(prelim.df, cor(Uses, Days.Worn, method="spearman") )
with(prelim.df, summary(lm(Uses~ Days.Worn) ))


prelim.df %>% select(fit.fail, Fits.well ) %>% table
temp_conf <- with(prelim.df, caret::confusionMatrix(reference=factor(!fit.fail, labels=c("Yes", "No")), data=Fits.well %>% fct_recode(Yes="No", No="Yes" )))

prelim.df %>% mutate(Mask.quality=Mask.quality %in% c("Poor") ) %>% select(Mask.quality, fit.fail ) %>% table

with(prelim.df  %>% mutate(Mask.quality=factor(!(Mask.quality %in% c("Poor")) , labels=c("Yes", "No" ) )), caret::confusionMatrix(reference=factor(fit.fail, labels=c("Yes", "No")), data=Mask.quality))

# temp_t1 <- table1(~Sex + Title + respirator + Days.Worn + Sterilizations + Uses + I(Uses/Days.Worn ) +Fits.well + Mask.quality | factor(fit.fail, labels=c("Yes", "No"))  , data=prelim.df)

factor_vars<- c('Sex' , 'Title' , 'Respirator', 'Fits.well', 'Mask.quality'  )

con_vars<- c( 'Days.Worn', 'Sterilizations', 'Uses',  'Uses.per.day' )
non_vars <- c( 'Days.Worn', 'Sterilizations', 'Uses',  'Uses.per.day' )
tab3 <- CreateTableOne(vars = c(con_vars,factor_vars) , strata = "fit.fail" , data = prelim.df%>%  mutate( Uses.per.day=Uses/Days.Worn ) %>% mutate(fit.fail=factor(fit.fail, labels=c("Pass", "Fail")) ) , factorVars = factor_vars )
temp <- capture.output(x <- print(tab3 , showAllLevels = TRUE, contDigits=1, printToggle=FALSE, nonnormal = non_vars))

temp <- print(tab3, showAllLevels = TRUE, contDigits=1)

pdf(file="failure_prob.pdf")
par( mar=c(4.1, 4.1, 1, 3.1) )
cross_fit <- cgam(fit.fail ~ incr(Days.Worn) , family=binomial(), data=prelim.df )
dummy_data <- data.frame(Days.Worn = 2:20)
dummy_data <- cbind(dummy_data, predict(cross_fit, newData=dummy_data, interval="confidence")[c("fit", "lower", "upper")] %>% as.data.frame )


temp_hist <- hist(prelim.df  %>% select(Days.Worn) %>% unlist ,breaks = seq(from=0.5, to=60.5), plot=T, axes=F, xlab=NULL, ylab=NULL, xlim=c(1.5,20) , main=NULL, col= rgb(0.6,1.0,1.0,alpha=0.5), border=rgb(0.6,1.0,1.0,alpha=0.5), freq=TRUE)

axis(4)

par(new=T)

plot(dummy_data$Days.Worn, dummy_data$fit*100 , xlab="Days worn", ylab="Failure probability (%)", ylim=c(0,100), xlim=c(1.5,20), type="l", col="black", lwd=2)
lines(dummy_data$Days.Worn, dummy_data$lower*100, lty=2, col="black", lwd=2)
lines(dummy_data$Days.Worn, dummy_data$upper*100, lty=2, col="black", lwd=2)


mtext(side=4, text="Count of Days Used", line=2)
par(new=F)


dev.off()

prelim.df %>% mutate(broken_days = cut(Days.Worn, breaks=c(1, 5, 8, 12, 25)) ) %>% select(broken_days) %>% table

# prelim.df %>% mutate(broken_days = cut(Days.Worn, breaks=c(1, 5, 8, 12, 25)) ) %>% group_by(broken_days) %>% summarize(n=n() , mean.failure=mean(fit.fail )%>% round(2), lcb=prop.test(x=sum(fit.fail), n=n())$conf.int[1]%>% round(2), ucb=prop.test(x=sum(fit.fail), n=n())$conf.int[2]%>% round(2) ) %>% {knitr::kable(x=.,format="html")}



with(prelim.df , scatter.smooth(Days.Worn, fit.fail ))


  test: ---
output: 
  bookdown::pdf_document2:
    fig_caption: true
    toc: false
    keep_tex: yes
title: "Web Appendix for Probability of Fit Failure with Reuse of N95 Respirators"
author: 
 -"

date: "`r format(Sys.time(), '%B %d, %Y')`"
bibliography: n95.bib

---

```{r echo=FALSE, message=FALSE, results='hide'}
library(magrittr)
if(file.exists("n95_intermediates.Rdata"))  {
load("n95_intermediates.Rdata")
library("magrittr")
library("tidyverse")
library("survival")
library("rmarkdown")
library("interval")
library("cgam")
library("icenReg")
library("km.ci")
library("flexsurv")
library("bookdown")
library("tableone")
library("PropCIs")
} else {
source("n95_report.R")
}
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(dev = 'pdf')
```



# Modeling assumptions and strategy
The sample is generated cross-sectionally, but can also be thought of as survival data.
Each fit test provides interval censored information: masks observed to fail a fit test at time *t* failed at some point in $\left(0 , t\right)$ (masks are assumed to have been initially functional). 
Masks that pass the fit test fail some time in the future $(t, t_\textrm{max})$.
For survival analysis we assume that each mask is independent with failure hazard from from a common distribution.
Our parametric survival model fits a 3-parameter generalized gamma hazard to the interval censored data.

Non-parametric or semi-parametric estimators which do not assume a functional form of the hazard are common in traditional survival analysis, and are available for interval censored data as well.
However, non-parametric estimates (NPMLE) for interval censored data are not unique; in some regions any baseline hazard matching continuity requirements is equally supported by the data.
Confidence intervals for interval censored baseline hazards are an active area of research [@wang_flexible_2016; @zhao_simultaneous_2019], with completely non-parametric estimation methods yielding slow $n^\frac{1}{3}$ convergence without a known asymptotic law [@groeneboom_information_1992].
Several semi-parametric methods have recently been shown to have $n^\frac{1}{2}$ convergence with Gaussian asymptotics making them amenable to bootstrapping [@wang_flexible_2016; @bouaziz_regression_2018; @zhao_simultaneous_2019; @li_adaptive_2019].
Proportional hazards regression was used to model factors other than duration of use in this framework.

Modeling the data as cross-sectional observations of fit passing versus failure as a function of time is also supportable because no participant-mask pair is observed more than once and there is minimal information to support extrapolation from before the earliest test time.
Because only a very small number of individuals are tested on more than one mask, we do not model or adjust for participant effects.
Integrated b-splines and constrained step functions allow modeling the failure log-odds as a monotone increasing function of time in a traditional logistic regression analysis.
This approach yields much better studied statistical behavior; however, given the modest sample size the probability statements produced should be taken as approximate.
The cross-sectional model does not encode any behavior before the earliest test time (e.g. that all masks initially fit).
We found that the cross-sectional model and non-parametric and semi-parametric survival models yield essentially identical point estimates when tuned appropriately, which is anticipated based on the use of step functions and splines to model the baseline hazard in the survival routines.

Factors beyond use duration were analyzed with proportional hazards regression (interval survival) or logistic regression (cross sectional).
Calculations were performed in R 3.6.3 with package flexsurv [@jackson_flexsurv_2016] for parametric survival modeling, icenReg [@anderson-bergman_icenreg_2017] for non-parametric survival modeling, and cgam [@liao_cgam_2019] for monotone logistic regression. 
Reported confidence intervals are at the 0.95 level.
Because this was an exploratory study, no pre-determined p-value threshold was applied.
Code and data to recreate this report can be found at https://github.com/cryanking/n95_refit

# Results
```{r echo=FALSE}
cross_fit <- cgam(fit.fail ~ s.incr(Days.Worn) , family=binomial(), data=prelim.df )
dummy_data <- data.frame(Days.Worn = c(4,10,15))
dummy_data <- cbind(dummy_data, predict(cross_fit, newData=dummy_data, interval="confidence")[c("fit", "lower", "upper")] %>% as.data.frame )
```

```{r echo=FALSE, messages=FALSE, results='asis'}
factor_vars<- c('Sex' , 'Title' , 'Respirator', 'Fits.well', 'Mask.quality'  )
non_vars <- c( 'Days.Worn', 'Sterilizations', 'Uses' )
con_vars<- c( 'Days.Worn', 'Sterilizations', 'Uses' )
tab3 <- CreateTableOne(vars = c(con_vars,factor_vars) , strata = "fit.fail" , data = prelim.df%>%  mutate(fit.fail=factor(fit.fail, labels=c("Pass", "Fail")) )  , factorVars = factor_vars)
temp <- capture.output(x <- print(tab3 , showAllLevels = TRUE, contDigits=0, printToggle=FALSE, nonnormal=TRUE, exact=T))

tab2 <- CreateTableOne(vars ='Uses.per.day' , strata = "fit.fail" , data = prelim.df%>%  mutate( Uses.per.day=Uses/Days.Worn ) %>% mutate(fit.fail=factor(fit.fail, labels=c("Pass", "Fail")) )  )

temp <- capture.output(x2<- print(tab2 , showAllLevels = TRUE, contDigits=1, printToggle=FALSE, nonnormal=FALSE, exact=T))

x<- rbind(x[1:length(con_vars), ,drop=FALSE], x2[-1,,drop=FALSE], x[-c(1:length(con_vars)), ,drop=FALSE] )

x <- x[,seq(ncol(x)-1)]
rownames(x) <- gsub(rownames(x), pattern=".", fixed=TRUE, replacement=" " )
    knitr::kable(x, caption="\\label{tab:desc}Descriptive statistics stratified by fit test failure. P-values for quantitative variables by Mann-Whitney U, factor variables by Fisher's exact test.")
```

Table \@ref(tab:desc) provides descriptive statistics.
Notably, male participants were less likely to fail fit tests both marginally and adjusting for the number of days worn (OR = `r temp <- glm(fit.fail ~ ns(Days.Worn) + Sex, data=prelim.df); temp2<- temp %>% coef %>% exp %>% extract2(3) %>% round(1); temp2 <- paste(temp2, "95% CI", paste(temp%>% confint %>% exp %>% magrittr::extract(3,1:2) %>% round(1), collapse=" to ") ); temp2   `).
Figure \@ref(fig:hists) displays histograms of number of days worn, number of times used, and number of times sterilized.
Surprisingly, the use duration and intensity was not markedly different between failed and passed mask fits.
Breaking the data into groups by number of days worn, the failure fraction is displayed in Table \@ref(tab:broken).
Table \@ref(tab:broken) shows that the failure fraction at all times is high; approximately 50% in all time categories.

```{r echo=FALSE, fig.show="hold", fig.keep="last", fig.cap="\\label{fig:hists}Mask use histograms."}
par(mfrow=c(3,1), oma=c(0,0,0,0), mar=c(2, 3, 2,0))
hist(prelim.df  %>% select(Days.Worn) %>% unlist ,breaks = seq(from=0.5, to=60.5), plot=T, main="Days Worn", xlab=NULL, col= rgb(0.6,1.0,1.0,alpha=0.5))
hist(prelim.df  %>% select(Uses) %>% unlist , breaks=20, plot=T, main="Times used", xlab=NULL, col= rgb(0.6,1.0,1.0,alpha=0.5))
hist(prelim.df  %>% select(Sterilizations) %>% unlist ,  plot=T, main="Times sterilized", xlab=NULL, col= rgb(0.6,1.0,1.0,alpha=0.5))
par(mfrow=c(1,1))
```


```{r echo=FALSE, results='asis' }
prelim.df %>% mutate(day_group = cut(Days.Worn, breaks=c(0.5, 5, 8, 12, 61)) ) %>% group_by(day_group) %>% summarize(n=n() , mean.failure=mean(fit.fail )%>% round(2), lower.conf=PropCIs::scoreci(x=sum(fit.fail), n=n(), conf.level=0.95)$conf.int[1]%>% round(2), upper.conf=PropCIs::scoreci(x=sum(fit.fail), n=n(), conf.level=0.95)$conf.int[2]%>% round(2) ) %>% {knitr::kable(x=.,format="latex", caption="\\label{tab:broken}Failure fractions by duration worn. Confidence intervals by Wilson's score method. ")}
```

Figure \@ref(fig:basicsurvival) displays mask survival as a function of days worn using cross-sectional approaches.
A monotone fit (I-splines) and natural spline (no restrictions) can be seen to agree well with non-parametric monotone methods.
The failure fraction at day `r dummy_data[1, "Days.Worn"]%>% as.integer` is `r dummy_data[1, "fit"]%>% round(2)` (95\% CI `r round(dummy_data[1,c("lower", "upper")],2)`). At day `r dummy_data[2, "Days.Worn"]%>% as.integer` the failure has increased to `r dummy_data[2, "fit"]%>% round(2)` (95\% CI `r round(dummy_data[2,c("lower", "upper")],2)`) and day `r dummy_data[3, "Days.Worn"]%>% as.integer` to `r dummy_data[3, "fit"]%>% round(2)` (95\% CI `r round(dummy_data[3,c("lower", "upper")],2)`).


```{r echo=FALSE, fig.show="hold", fig.keep="last", fig.cap="\\label{fig:basicsurvival} Comparison of cross sectional logistic regression models for mask Failure by number of days worn. Black = non-parametric monotone (step functions), Red = semi-parametric smooth with monotone constraint, Blue = semi-parametric smooth (no monotone requirement). Dashed lines 95% point-wise confidence limits. Fit with cgam package."}
cross_fit <- cgam(fit.fail ~ incr(Days.Worn) , family=binomial(), data=prelim.df )
dummy_data <- data.frame(Days.Worn = 4:20)
dummy_data <- cbind(dummy_data, predict(cross_fit, newData=dummy_data, interval="confidence")[c("fit", "lower", "upper")] %>% as.data.frame )
plot(dummy_data$Days.Worn, dummy_data$fit , xlab="Days worn", ylab="Failure probability", ylim=c(0,1), xlim=c(4,20), type="l")
lines(dummy_data$Days.Worn, dummy_data$lower, lty=2)
lines(dummy_data$Days.Worn, dummy_data$upper, lty=2)

cross_fit <- cgam(fit.fail ~ s.incr(Days.Worn) , family=binomial(), data=prelim.df )
dummy_data <- data.frame(Days.Worn = 4:20)
dummy_data <- cbind(dummy_data, predict(cross_fit, newData=dummy_data, interval="confidence")[c("fit", "lower", "upper")] %>% as.data.frame )
points(dummy_data$Days.Worn, dummy_data$fit , col='red', type="l")
lines(dummy_data$Days.Worn, dummy_data$lower, col='red', lty=2)
lines(dummy_data$Days.Worn, dummy_data$upper, col='red', lty=2)


cross_fit <- glm(fit.fail ~ ns(Days.Worn) , family=binomial(), data=prelim.df )
dummy_data <- data.frame(Days.Worn = 4:20)
dummy_data <- cbind(dummy_data, predict(cross_fit, newdata=dummy_data, se.fit=TRUE)[c("fit", "se.fit")] %>% as.data.frame )

points(dummy_data$Days.Worn, cross_fit$family$linkinv(dummy_data$fit) , col='blue', type="l")
dummy_data %<>% mutate( lower=cross_fit$family$linkinv(fit - 1.96*se.fit), upper=cross_fit$family$linkinv(fit+1.96*se.fit))
lines(dummy_data$Days.Worn, dummy_data$lower, col='blue', lty=2)
lines(dummy_data$Days.Worn, dummy_data$upper, col='blue', lty=2)
```

Figure \@ref(fig:comparesurv) compares interval censored survival-based analyses and the cross-sectional analysis.
The parametric model diverges from the non-parametric MLE at the extremes of time, as it requires a smoother change between the initial state (0 failure) to the early observed times.
The generalized gamma and Weibull parametric families fit well.
Figure \@ref(fig:comparepara) displays the results with gamma and weibull hazards.


```{r echo=FALSE, fig.show="hold", fig.keep="last", fig.cap="\\label{fig:comparesurv}Comparison of survival and cross-sectional models for mask failure by number of days worn. Black = non-parametric survival with interval censoring (grey regions = indeterminate MLE), Red = generalized gamma survival model with interval censoring, Blue = cross sectional monotone smooth. Dashed lines 95% point-wise confidence limits. "}
npm_out %>% plot(xlim=c(4,20), XLAB="Days worn", YLAB="Failure probability", dtype="cdf")
fs_1 <- flexsurvreg(Surv(left, right, type="interval2")~1, data=prelim.df, dist="gengamma")
cross_fit <- cgam(fit.fail ~ s.incr(Days.Worn) , family=binomial(), data=prelim.df )
dummy_data <- data.frame(Days.Worn = 4:20)
dummy_data <- cbind(dummy_data, predict(cross_fit, newData=dummy_data, interval="confidence")[c("fit", "lower", "upper")] %>% as.data.frame )
lines(dummy_data$Days.Worn, dummy_data$fit , col='blue', lwd=2)
lines(dummy_data$Days.Worn, dummy_data$lower, col='blue', lty=2)
lines(dummy_data$Days.Worn, dummy_data$upper, col='blue', lty=2)

failure_probs<- summary(fs_1, type="survival", t=4:20, se=TRUE, ci=TRUE)[[1]]

lines(failure_probs$time, 1-failure_probs$est, col="red")
lines(failure_probs$time, 1-failure_probs$lcl, col="red", lty=2)
lines(failure_probs$time, 1-failure_probs$ucl, col="red", lty=2)
```

```{r echo=FALSE, fig.show="hold", warning=FALSE , message=FALSE, fig.keep="last", fig.cap="\\label{fig:comparepara}Comparison of parametric family survival models. Black = non-parametric survival (grey regions = indeterminate MLE), Red = generalized gamma survival, Blue = Weibull. Dashed lines 95% point-wise confidence limits. Fit with cgam package."}
npm_out %>% plot(xlim=c(4,20), XLAB="Days worn", YLAB="Failure probability", dtype="cdf")
lines(failure_probs$time, 1-failure_probs$est, col="red")
lines(failure_probs$time, 1-failure_probs$lcl, col="red", lty=2)
lines(failure_probs$time, 1-failure_probs$ucl, col="red", lty=2)


fs_1 <- flexsurvreg(Surv(left, right, type="interval2")~1, data = prelim.df, dist="weibull")

failure_probs<- summary(fs_1, type="survival", t=4:20, se=TRUE, ci=TRUE)[[1]]
lines(failure_probs$time, 1-failure_probs$est, col="blue")
lines(failure_probs$time, 1-failure_probs$lcl, col="blue", lty=2)
lines(failure_probs$time, 1-failure_probs$ucl, col="blue", lty=2)
```

We also computed a traditional Kaplan-Meier curve treating the data as right censored only (assuming that participants joined the experiment about when their masks failed).
This is displayed in Figure \@ref(fig:comparekm), which shows much lower estimated early failure fractions as the later failures are no longer considered a possible early failure.

```{r echo=FALSE, fig.show="hold", warning=FALSE , message=FALSE, fig.keep="last", fig.cap="\\label{fig:comparekm}Comparison of interval censored and traditional survival estimates of mask failure by number of days worn. Black = non-parametric interval censored survival (grey regions = indeterminate MLE), Red = right censored only (Kaplan-Meier)"}
npm_out %>% plot(xlim=c(4,20), XLAB="Days worn", YLAB="Failure probability", dtype="cdf")

lines(km.ci(survfit(Surv(time=Days.Worn, event=fit.fail)~1, data=prelim.df) ), col='red', fun='F')
```

Similar analysis for failure by number of times donned is shown in Figure \@ref(fig:comparedon).
The failure fraction is similarly flat.
Number of times used was fairly correlated with number of days worn (spearman correlation = `r  with(prelim.df, cor(Uses, Days.Worn, method="spearman") )%>% round(2)`, p `r with(prelim.df, wilcox.test(Uses, Days.Worn))$p.value %>% format.pval(eps=.001)`).


```{r echo=FALSE, fig.show="hold", warning=FALSE , message=FALSE, fig.keep="last", fig.cap="\\label{fig:comparedon}Comparison of survival and cross sectional models for mask failure by number of times used. Black = non-parametric interval censored survival (grey regions = indeterminate MLE), Red = cross-sectional analysis, Blue = generalized gamma survival"}
npm_out2 %>% plot(xlim=c(6,50), XLAB="Times used", YLAB="Failure probability", dtype="cdf")
fs_1 <- flexsurvreg(Surv(left, right, type="interval2")~1, dist="gengamma", data=prelim.df2)
failure_probs<- summary(fs_1, type="survival", t=6:50, se=TRUE, ci=TRUE)[[1]]

lines(failure_probs$time, 1-failure_probs$est, col="blue")
lines(failure_probs$time, 1-failure_probs$lcl, col="blue", lty=2)
lines(failure_probs$time, 1-failure_probs$ucl, col="blue", lty=2)

cross_fit3 <- cgam(fit.fail ~ incr(Uses) , family=binomial(), data=prelim.df )
dummy_data <- data.frame(Uses = 6:55)
dummy_data <- cbind(dummy_data, predict(cross_fit3, newData=dummy_data, interval="confidence")[c("fit", "lower", "upper")] %>% as.data.frame )
lines(dummy_data$Uses, dummy_data$fit , col='red', lwd=2)
lines(dummy_data$Uses, dummy_data$lower, col='red', lty=2)
lines(dummy_data$Uses, dummy_data$upper, col='red', lty=2)
```
```{r echo=FALSE}
cross_fit <- glm(fit.fail ~ ns(Days.Worn) , family=binomial(), data=prelim.df )
cross_fit2 <- glm(fit.fail ~ ns(Days.Worn) +Sterilizations  , family=binomial(), data=prelim.df )
basic <- glm(fit.fail ~ Sterilizations , family=binomial(), data=prelim.df )
cross_fit3 <- glm(fit.fail ~ ns(Days.Worn) +I(Uses/Days.Worn)  , family=binomial(), data=prelim.df )

t1 <- np_reg %>% summary %>% extract2("summaryParameters") %>% as.vector %>% extract2(1) 
t2 <- np_reg %>% summary %>% extract2("summaryParameters") %>% as.vector %>% extract2(3) 
t3 <- np_reg2b %>% summary %>% extract2("summaryParameters") %>% as.vector %>% extract2(1)
t4 <- np_reg2b %>% summary %>% extract2("summaryParameters") %>% as.vector %>% extract2(3) 

```

Alternative factors contributing to fit failure analyzed included number of sterilizations and intensity of use (number of times donned per day). 
Using the logistic regression model, the number of sterilizations was found to have a modest effect with modest precision (OR `r cross_fit2 %>% coefficients %>% as.vector %>% extract2(3) %>% exp %>% round(1)` 95\% CI `r cross_fit2 %>% confint %>% magrittr::extract(3,1:2) %>% exp %>% round(1) %>% unname`).
The number of times donned per day was found to have a negligible effect with modest precision (OR `r cross_fit3 %>% coefficients %>% as.vector %>% extract2(3) %>% exp %>% round(1)` 95\% CI `r cross_fit3 %>% confint %>% magrittr::extract(3,1:2) %>% exp %>% round(1) %>% unname`).
In cox analysis, the number of sterilizations was found to have a small effect with modest precision (cox B =`r t1 %>% round(2)`, 95\% CI `r t1 %>% subtract(1.96*t2) %>% round(2) ` to  `r t1 %>% add(1.96*t2) %>% round(2) ` ).
The number of times donned per day was found to have a negligible effect with modest precision (cox B =`r t3 %>% round(2)`, 95\% CI `r t3 %>% subtract(1.96*t4) %>% round(2) ` to  `r t3 %>% add(1.96*t4) %>% round(2) ` ).


```{r echo=FALSE}
local_data <- prelim.df %>% group_by(Fits.well) %>% summarize(mfit=mean(fit.fail ), nfit=n(), lower=PropCIs::scoreci(x=sum(fit.fail), n=n(), conf.level=0.95)$conf.int[1], upper=PropCIs::scoreci(x=sum(fit.fail), n=n(), conf.level=0.95)$conf.int[2] )
local_data2 <- prelim.df %>%mutate(Fits.well = Fits.well == "No") %>% group_by(fit.fail) %>% summarize(mfit=mean(Fits.well ), nfit=n(), lower=PropCIs::scoreci(x=sum(Fits.well), n=n(), conf.level=0.95)$conf.int[1], upper=PropCIs::scoreci(x=sum(Fits.well), n=n(), conf.level=0.95)$conf.int[2] )
temp_conf <- with(prelim.df, caret::confusionMatrix(reference=factor(!fit.fail, labels=c("Yes", "No")), data=Fits.well %>% fct_recode(Yes="No", No="Yes" )))
local_data3 <- prelim.df %>% mutate(qual2=Mask.quality %in% c("Like New", "Good") ) %>% group_by(fit.fail) %>% summarize(mfit=mean(qual2 ), nfit=n(), lower=PropCIs::scoreci(x=sum(qual2), n=n(), conf.level=0.95)$conf.int[1], upper=PropCIs::scoreci(x=sum(qual2), n=n(), conf.level=0.95)$conf.int[2] )
local_data4 <- prelim.df %>% mutate(qual2=Mask.quality %in% c("Like New") ) %>% select(fit.fail, qual2 ) %>% table %>% fisher.test
```
Although imperfect, participants were able to somewhat discriminate poorly fitting masks.
Figure \@ref(fig:split) displays the survival stratified by perceived fit.
Among the `r local_data[1,3]` participants reporting a poor fit, `r local_data[1,2] %>% round(2) %>% multiply_by(100)`% failed the fit test (95% CI `r local_data[1,4]%>% round(2) %>% multiply_by(100)` to `r local_data[1,5]%>% round(2) %>% multiply_by(100)`).
Among the `r local_data[2,3]` participants reporting a good fit, `r local_data[2,2] %>% round(2)%>% multiply_by(100)`% failed the fit test (95% CI `r local_data[2,4]%>% round(2) %>% multiply_by(100)` to `r local_data[2,5]%>% round(2) %>% multiply_by(100)`, p `r fisher.test(prelim.df$Fits.well, prelim.df$fit.fail) %>% extract2("p.value") %>% format.pval(digits=2)` by Fisher's exact test).
Reversing the direction of conditioning, among those passing the fit test, `r local_data2[1,2] %>% round(2) %>% multiply_by(100)`% believed their mask was poorly fitting (95% CI `r local_data2[1,4]%>% round(2) %>% multiply_by(100)` to `r local_data2[1,5]%>% round(2) %>% multiply_by(100)`). 
Among those failing the fit test, `r local_data2[2,2] %>% round(2)%>% multiply_by(100)`% believed their mask to be poorly fitting (95% CI `r local_data2[2,4]%>% round(2) %>% multiply_by(100)` to `r local_data2[2,5]%>% round(2) %>% multiply_by(100)`).
The user's impression had a sensitivity of `r temp_conf[['byClass']]['Sensitivity'] %>% multiply_by(100) %>% round`%, specificity of `r temp_conf[['byClass']]['Specificity'] %>% multiply_by(100) %>% round`%, and positive and negative predictive values of  `r temp_conf[['byClass']]['Pos Pred Value'] %>% multiply_by(100) %>% round`% and  `r temp_conf[['byClass']]['Neg Pred Value'] %>% multiply_by(100) %>% round`%.
Test administrators also judged mask quality.
As seen in Table \@ref(tab:desc), very few masks were judged to be poor quality, but "Like New" and "Good" quality masks were `r local_data3[2,2] %>% round(2)%>% multiply_by(100)`% of the failed masks (95% CI `r local_data3[2,4]%>% round(2) %>% multiply_by(100)` to `r local_data3[2,5]%>% round(2) %>% multiply_by(100)`).
"Like New" masks were much less likely to fail, OR = `r local_data4$estimate %>% round(1)` (95% CI =`r local_data4$conf.int[1] %>% round(1)` to `r local_data4$conf.int[2] %>% round(1)`, p `r local_data4$p.value%>% format.pval(eps=0.001)`).

```{r echo=FALSE, fig.show="hold", warning=FALSE , message=FALSE, fig.keep="last", fig.cap="\\label{fig:split}Comparison of mask failure by days worn stratified by user perceived fit. Black = entire study non-parametric interval censored survival (grey regions = indeterminate MLE), Red= smooth cross-sectional model among self-perceived good fit, Blue = smooth cross-sectional model among self-perceived bad fit "}
cross_fit2 <- cgam(fit.fail ~ s.incr(Days.Worn)*Fits.well  , family=binomial(), data=prelim.df )

npm_out %>% plot(xlim=c(4,20), XLAB="Days worn", YLAB="Failure probability", dtype="cdf")

dummy_data <- data.frame(Days.Worn = 4:20 , Fits.well =prelim.df$Fits.well %>% unique %>% magrittr::extract(1) )
dummy_data <- cbind(dummy_data, predict(cross_fit2, newData=dummy_data, interval="confidence")[c("fit", "lower", "upper")] %>% as.data.frame )
lines(dummy_data$Days.Worn, dummy_data$fit , col='red', lwd=2)
lines(dummy_data$Days.Worn, dummy_data$lower, col='red', lty=2)
lines(dummy_data$Days.Worn, dummy_data$upper, col='red', lty=2)

dummy_data <- data.frame(Days.Worn = 4:20 , Fits.well =prelim.df$Fits.well %>% unique %>% magrittr::extract(2) )
dummy_data <- cbind(dummy_data, predict(cross_fit2, newData=dummy_data, interval="confidence")[c("fit", "lower", "upper")] %>% as.data.frame )
lines(dummy_data$Days.Worn, dummy_data$fit , col='blue', lwd=2)
lines(dummy_data$Days.Worn, dummy_data$lower, col='blue', lty=2)
lines(dummy_data$Days.Worn, dummy_data$upper, col='blue', lty=2)
```

<!--
# Conclusions

In this data, mask fit failure was high for all durations of use and varied minimally by duration and number of uses.
This surprising finding has several potential explanations.
First and most concerning, mask fit failure could occur more frequently early in the use cycle among those where it will fail.
Use patterns or facial morphology may tend to early failure, while others are able to maintain a good fit for long duration of use.
Alternatively, our results could be generated if fit test failure were poorly measured (false failures) or related to inappropriate donning during the test, which would produce a uniform failure fraction.
However, in our re-testing protocol individuals were given new masks immediately after a failed fit and almost uniformly passed the fit test, which makes isolated inappropriate donning or test error a less likely explanation.
Strong selection bias where individuals joined the study when they believed their mask failed could generate similar uniform failure fractions, but is not consistent with the majority of participants believing their mask fit was acceptable.
If clearly failed masks were removed from the population before the experiment, the failure fraction would tend to be artificially decreased (or made more uniform).
However, during the period of the study N95 mask shortages were critical, and discarding masks appears to have been uncommon.
Because few individuals trained in mask fitting were available, re-testing was not readily available outside of our initiative, and participants had little ability to verify that a mask fit had failed.
As seen in Figure \@ref(fig:hists), individuals continued to use masks for long durations even before sterilization was available due to these shortages and lack of testing availability.
-->

# References




    runs-on: ---
output: 
  bookdown::html_document2:
    fig_caption: true
    toc: false
    self_contained: no
title: "Web Appendix for Probability of Fit Failure with Reuse of N95 Respirators"
author: 
 - 
date: "`r format(Sys.time(), '%B %d, %Y')`"
bibliography: n95.bib

---

```{r echo=FALSE, message=FALSE, results='hide'}
library(magrittr)
if(file.exists("n95_intermediates.Rdata"))  {
load("n95_intermediates.Rdata")
library("magrittr")
library("tidyverse")
library("survival")
library("rmarkdown")
library("interval")
library("cgam")
library("icenReg")
library("km.ci")
library("flexsurv")
library("bookdown")
library("tableone")
library("PropCIs")
} else {
source("n95_report.R")
}
```

```{r setup, include=FALSE}
library('Cairo')
knitr::opts_chunk$set(dev = 'CairoSVG')
```



# Modeling assumptions and strategy
The sample is generated cross-sectionally, but can also be thought of as survival data.
Each fit test provides interval censored information: masks observed to fail a fit test at time *t* failed at some point in $\left(0 , t\right)$ (masks are assumed to have been initially functional). 
Masks that pass the fit test fail some time in the future $(t, t_\textrm{max})$.
For survival analysis we assume that each mask is independent with failure hazard from from a common distribution.
Our parametric survival model fits a 3-parameter generalized gamma hazard to the interval censored data.

Non-parametric or semi-parametric estimators which do not assume a functional form of the hazard are common in traditional survival analysis, and are available for interval censored data as well.
However, non-parametric estimates (NPMLE) for interval censored data are not unique; in some regions any baseline hazard matching continuity requirements is equally supported by the data.
Confidence intervals for interval censored baseline hazards are an active area of research [@wang_flexible_2016; @zhao_simultaneous_2019], with completely non-parametric estimation methods yielding slow $n^\frac{1}{3}$ convergence without a known asymptotic law [@groeneboom_information_1992].
Several semi-parametric methods have recently been shown to have $n^\frac{1}{2}$ convergence with Gaussian asymptotics making them amenable to bootstrapping [@wang_flexible_2016; @bouaziz_regression_2018; @zhao_simultaneous_2019; @li_adaptive_2019].
Proportional hazards regression was used to model factors other than duration of use in this framework.

Modeling the data as cross-sectional observations of fit passing versus failure as a function of time is also supportable because no participant-mask pair is observed more than once and there is minimal information to support extrapolation from before the earliest test time.
Because only a very small number of individuals are tested on more than one mask, we do not model or adjust for participant effects.
Integrated b-splines and constrained step functions allow modeling the failure log-odds as a monotone increasing function of time in a traditional logistic regression analysis.
This approach yields much better studied statistical behavior; however, given the modest sample size the probability statements produced should be taken as approximate.
The cross-sectional model does not encode any behavior before the earliest test time (e.g. that all masks initially fit).
We found that the cross-sectional model and non-parametric and semi-parametric survival models yield essentially identical point estimates when tuned appropriately, which is anticipated based on the use of step functions and splines to model the baseline hazard in the survival routines.

Factors beyond use duration were analyzed with proportional hazards regression (interval survival) or logistic regression (cross sectional).
Calculations were performed in R 3.6.3 with package flexsurv [@jackson_flexsurv_2016] for parametric survival modeling, icenReg [@anderson-bergman_icenreg_2017] for non-parametric survival modeling, and cgam [@liao_cgam_2019] for monotone logistic regression. 
Reported confidence intervals are at the 0.95 level.
Because this was an exploratory study, no pre-determined p-value threshold was applied.

# Results
```{r echo=FALSE}
cross_fit <- cgam(fit.fail ~ s.incr(Days.Worn) , family=binomial(), data=prelim.df )
dummy_data <- data.frame(Days.Worn = c(4,10,15))
dummy_data <- cbind(dummy_data, predict(cross_fit, newData=dummy_data, interval="confidence")[c("fit", "lower", "upper")] %>% as.data.frame )
```

```{r desc, echo=FALSE, messages=FALSE, results='asis'}
factor_vars<- c('Sex' , 'Title' , 'Respirator', 'Fits.well', 'Mask.quality'  )
non_vars <- c( 'Days.Worn', 'Sterilizations', 'Uses' )
con_vars<- c( 'Days.Worn', 'Sterilizations', 'Uses' )
tab3 <- CreateTableOne(vars = c(con_vars,factor_vars) , strata = "fit.fail" , data = prelim.df%>%  mutate(fit.fail=factor(fit.fail, labels=c("Pass", "Fail")) )  , factorVars = factor_vars)
temp <- capture.output(x <- print(tab3 , showAllLevels = TRUE, contDigits=0, printToggle=FALSE, nonnormal=TRUE, exact=T))

tab2 <- CreateTableOne(vars ='Uses.per.day' , strata = "fit.fail" , data = prelim.df%>%  mutate( Uses.per.day=Uses/Days.Worn ) %>% mutate(fit.fail=factor(fit.fail, labels=c("Pass", "Fail")) )  )

temp <- capture.output(x2<- print(tab2 , showAllLevels = TRUE, contDigits=1, printToggle=FALSE, nonnormal=FALSE, exact=T))

x<- rbind(x[1:length(con_vars), ,drop=FALSE], x2[-1,,drop=FALSE], x[-c(1:length(con_vars)), ,drop=FALSE] )

x <- x[,seq(ncol(x)-1)]
rownames(x) <- gsub(rownames(x), pattern=".", fixed=TRUE, replacement=" " )
    knitr::kable(x, caption="Descriptive statistics stratified by fit test failure. P-values for quantitative variables by Mann-Whitney U, factor variables by Fisher's exact test.")
```

Table \@ref(tab:desc) provides descriptive statistics.
Notably, male participants were less likely to fail fit tests both marginally and adjusting for the number of days worn (OR = `r temp <- glm(fit.fail ~ ns(Days.Worn) + Sex, data=prelim.df); temp2<- temp %>% coef %>% exp %>% extract2(3) %>% round(1); temp2 <- paste(temp2, "95% CI", paste(temp%>% confint %>% exp %>% magrittr::extract(3,1:2) %>% round(1), collapse=" to ") ); temp2   `).
Figure \@ref(fig:hists) displays histograms of number of days worn, number of times used, and number of times sterilized.
Surprisingly, the use duration and intensity was not markedly different between failed and passed mask fits.
Breaking the data into groups by number of days worn, the failure fraction is displayed in Table \@ref(tab:broken).
Table \@ref(tab:broken) shows that the failure fraction at all times is high; approximately 50% in all time categories.

```{r hists, echo=FALSE, fig.show="hold", fig.keep="last", fig.cap="Mask use histograms."}
par(mfrow=c(3,1), oma=c(0,0,0,0), mar=c(2, 3, 2,0))
hist(prelim.df  %>% select(Days.Worn) %>% unlist ,breaks = seq(from=0.5, to=60.5), plot=T, main="Days Worn", xlab=NULL, col= rgb(0.6,1.0,1.0,alpha=0.5))
hist(prelim.df  %>% select(Uses) %>% unlist , breaks=20, plot=T, main="Times used", xlab=NULL, col= rgb(0.6,1.0,1.0,alpha=0.5))
hist(prelim.df  %>% select(Sterilizations) %>% unlist ,  plot=T, main="Times sterilized", xlab=NULL, col= rgb(0.6,1.0,1.0,alpha=0.5))
par(mfrow=c(1,1))
```


```{r broken, echo=FALSE, results='asis' }
prelim.df %>% mutate(day_group = cut(Days.Worn, breaks=c(0.5, 5, 8, 12, 61)) ) %>% group_by(day_group) %>% summarize(n=n() , mean.failure=mean(fit.fail )%>% round(2) %>% multiply_by(100), lower.conf= paste( "(" , PropCIs::scoreci(x=sum(fit.fail), n=n(), conf.level=0.95)$conf.int[1]%>% round(2)%>% multiply_by(100), ",", PropCIs::scoreci(x=sum(fit.fail), n=n(), conf.level=0.95)$conf.int[2]%>% round(2)%>% multiply_by(100) , ")" ) ) %>% set_colnames(c("days worn", "n", "failed %", "CI")) %>% {knitr::kable(x=., align="c", format="html", caption="Failure fractions by duration worn. Confidence intervals by Wilson's score method. ")}
```

Figure \@ref(fig:basicsurvival) displays mask survival as a function of days worn using cross-sectional approaches.
A monotone fit (I-splines) and natural spline (no restrictions) can be seen to agree well with non-parametric monotone methods.
The failure fraction at day `r dummy_data[1, "Days.Worn"]%>% as.integer` is `r dummy_data[1, "fit"]%>% round(2)` (95\% CI `r round(dummy_data[1,c("lower", "upper")],2)`). At day `r dummy_data[2, "Days.Worn"]%>% as.integer` the failure has increased to `r dummy_data[2, "fit"]%>% round(2)` (95\% CI `r round(dummy_data[2,c("lower", "upper")],2)`) and day `r dummy_data[3, "Days.Worn"]%>% as.integer` to `r dummy_data[3, "fit"]%>% round(2)` (95\% CI `r round(dummy_data[3,c("lower", "upper")],2)`).


```{r basicsurvival, echo=FALSE, fig.show="hold", fig.keep="last", fig.cap="Comparison of cross sectional logistic regression models for mask Failure by number of days worn. Black = non-parametric monotone (step functions), Red = semi-parametric smooth with monotone constraint, Blue = semi-parametric smooth (no monotone requirement). Dashed lines 95% point-wise confidence limits. Fit with cgam package."}
cross_fit <- cgam(fit.fail ~ incr(Days.Worn) , family=binomial(), data=prelim.df )
dummy_data <- data.frame(Days.Worn = 4:20)
dummy_data <- cbind(dummy_data, predict(cross_fit, newData=dummy_data, interval="confidence")[c("fit", "lower", "upper")] %>% as.data.frame )
plot(dummy_data$Days.Worn, dummy_data$fit , xlab="Days worn", ylab="Failure probability", ylim=c(0,1), xlim=c(4,20), type="l")
lines(dummy_data$Days.Worn, dummy_data$lower, lty=2)
lines(dummy_data$Days.Worn, dummy_data$upper, lty=2)

cross_fit <- cgam(fit.fail ~ s.incr(Days.Worn) , family=binomial(), data=prelim.df )
dummy_data <- data.frame(Days.Worn = 4:20)
dummy_data <- cbind(dummy_data, predict(cross_fit, newData=dummy_data, interval="confidence")[c("fit", "lower", "upper")] %>% as.data.frame )
points(dummy_data$Days.Worn, dummy_data$fit , col='red', type="l")
lines(dummy_data$Days.Worn, dummy_data$lower, col='red', lty=2)
lines(dummy_data$Days.Worn, dummy_data$upper, col='red', lty=2)


cross_fit <- glm(fit.fail ~ ns(Days.Worn) , family=binomial(), data=prelim.df )
dummy_data <- data.frame(Days.Worn = 4:20)
dummy_data <- cbind(dummy_data, predict(cross_fit, newdata=dummy_data, se.fit=TRUE)[c("fit", "se.fit")] %>% as.data.frame )

points(dummy_data$Days.Worn, cross_fit$family$linkinv(dummy_data$fit) , col='blue', type="l")
dummy_data %<>% mutate( lower=cross_fit$family$linkinv(fit - 1.96*se.fit), upper=cross_fit$family$linkinv(fit+1.96*se.fit))
lines(dummy_data$Days.Worn, dummy_data$lower, col='blue', lty=2)
lines(dummy_data$Days.Worn, dummy_data$upper, col='blue', lty=2)
```

Figure \@ref(fig:comparesurv) compares interval censored survival-based analyses and the cross-sectional analysis.
The parametric model diverges from the non-parametric MLE at the extremes of time, as it requires a smoother change between the initial state (0 failure) to the early observed times.
The generalized gamma and Weibull parametric families fit well.
Figure \@ref(fig:comparepara) displays the results with gamma and weibull hazards.


```{r comparesurv, echo=FALSE, fig.show="hold", fig.keep="last", fig.cap="Comparison of survival and cross-sectional models for mask failure by number of days worn. Black = non-parametric survival with interval censoring (grey regions = indeterminate MLE), Red = generalized gamma survival model with interval censoring, Blue = cross sectional monotone smooth. Dashed lines 95% point-wise confidence limits. "}
npm_out %>% plot(xlim=c(4,20), XLAB="Days worn", YLAB="Failure probability", dtype="cdf")
fs_1 <- flexsurvreg(Surv(left, right, type="interval2")~1, data=prelim.df, dist="gengamma")
cross_fit <- cgam(fit.fail ~ s.incr(Days.Worn) , family=binomial(), data=prelim.df )
dummy_data <- data.frame(Days.Worn = 4:20)
dummy_data <- cbind(dummy_data, predict(cross_fit, newData=dummy_data, interval="confidence")[c("fit", "lower", "upper")] %>% as.data.frame )
lines(dummy_data$Days.Worn, dummy_data$fit , col='blue', lwd=2)
lines(dummy_data$Days.Worn, dummy_data$lower, col='blue', lty=2)
lines(dummy_data$Days.Worn, dummy_data$upper, col='blue', lty=2)

failure_probs<- summary(fs_1, type="survival", t=4:20, se=TRUE, ci=TRUE)[[1]]

lines(failure_probs$time, 1-failure_probs$est, col="red")
lines(failure_probs$time, 1-failure_probs$lcl, col="red", lty=2)
lines(failure_probs$time, 1-failure_probs$ucl, col="red", lty=2)
```

```{r comparepara, echo=FALSE, fig.show="hold", warning=FALSE , message=FALSE, fig.keep="last", fig.cap="Comparison of parametric family survival models. Black = non-parametric survival (grey regions = indeterminate MLE), Red = generalized gamma survival, Blue = Weibull. Dashed lines 95% point-wise confidence limits. Fit with cgam package."}
npm_out %>% plot(xlim=c(4,20), XLAB="Days worn", YLAB="Failure probability", dtype="cdf")
lines(failure_probs$time, 1-failure_probs$est, col="red")
lines(failure_probs$time, 1-failure_probs$lcl, col="red", lty=2)
lines(failure_probs$time, 1-failure_probs$ucl, col="red", lty=2)


fs_1 <- flexsurvreg(Surv(left, right, type="interval2")~1, data = prelim.df, dist="weibull")

failure_probs<- summary(fs_1, type="survival", t=4:20, se=TRUE, ci=TRUE)[[1]]
lines(failure_probs$time, 1-failure_probs$est, col="blue")
lines(failure_probs$time, 1-failure_probs$lcl, col="blue", lty=2)
lines(failure_probs$time, 1-failure_probs$ucl, col="blue", lty=2)
```

We also computed a traditional Kaplan-Meier curve treating the data as right censored only (assuming that participants joined the experiment about when their masks failed).
This is displayed in Figure \@ref(fig:comparekm), which shows much lower estimated early failure fractions as the later failures are no longer considered a possible early failure.

```{r comparekm, echo=FALSE, fig.show="hold", warning=FALSE , message=FALSE, fig.keep="last", fig.cap="Comparison of interval censored and traditional survival estimates of mask failure by number of days worn. Black = non-parametric interval censored survival (grey regions = indeterminate MLE), Red = right censored only (Kaplan-Meier)"}
npm_out %>% plot(xlim=c(4,20), XLAB="Days worn", YLAB="Failure probability", dtype="cdf")

lines(km.ci(survfit(Surv(time=Days.Worn, event=fit.fail)~1, data=prelim.df) ), col='red', fun='F')
```

Similar analysis for failure by number of times donned is shown in Figure \@ref(fig:comparedon).
The failure fraction is similarly flat.
Number of times used was fairly correlated with number of days worn (spearman correlation = `r  with(prelim.df, cor(Uses, Days.Worn, method="spearman") )%>% round(2)`, p `r with(prelim.df, wilcox.test(Uses, Days.Worn))$p.value %>% format.pval(eps=.001)`).


```{r comparedon, echo=FALSE, fig.show="hold", warning=FALSE , message=FALSE, fig.keep="last", fig.cap="Comparison of survival and cross sectional models for mask failure by number of times used. Black = non-parametric interval censored survival (grey regions = indeterminate MLE), Red = cross-sectional analysis, Blue = generalized gamma survival"}
npm_out2 %>% plot(xlim=c(6,50), XLAB="Times used", YLAB="Failure probability", dtype="cdf")
fs_1 <- flexsurvreg(Surv(left, right, type="interval2")~1, dist="gengamma", data=prelim.df2)
failure_probs<- summary(fs_1, type="survival", t=6:50, se=TRUE, ci=TRUE)[[1]]

lines(failure_probs$time, 1-failure_probs$est, col="blue")
lines(failure_probs$time, 1-failure_probs$lcl, col="blue", lty=2)
lines(failure_probs$time, 1-failure_probs$ucl, col="blue", lty=2)

cross_fit3 <- cgam(fit.fail ~ incr(Uses) , family=binomial(), data=prelim.df )
dummy_data <- data.frame(Uses = 6:55)
dummy_data <- cbind(dummy_data, predict(cross_fit3, newData=dummy_data, interval="confidence")[c("fit", "lower", "upper")] %>% as.data.frame )
lines(dummy_data$Uses, dummy_data$fit , col='red', lwd=2)
lines(dummy_data$Uses, dummy_data$lower, col='red', lty=2)
lines(dummy_data$Uses, dummy_data$upper, col='red', lty=2)
```
```{r echo=FALSE}
cross_fit <- glm(fit.fail ~ ns(Days.Worn) , family=binomial(), data=prelim.df )
cross_fit2 <- glm(fit.fail ~ ns(Days.Worn) +Sterilizations  , family=binomial(), data=prelim.df )
basic <- glm(fit.fail ~ Sterilizations , family=binomial(), data=prelim.df )
cross_fit3 <- glm(fit.fail ~ ns(Days.Worn) +I(Uses/Days.Worn)  , family=binomial(), data=prelim.df )

t1 <- np_reg %>% summary %>% extract2("summaryParameters") %>% as.vector %>% extract2(1) 
t2 <- np_reg %>% summary %>% extract2("summaryParameters") %>% as.vector %>% extract2(3) 
t3 <- np_reg2b %>% summary %>% extract2("summaryParameters") %>% as.vector %>% extract2(1)
t4 <- np_reg2b %>% summary %>% extract2("summaryParameters") %>% as.vector %>% extract2(3) 

```

Alternative factors contributing to fit failure analyzed included number of sterilizations and intensity of use (number of times donned per day). 
Using the logistic regression model, the number of sterilizations was found to have a modest effect with modest precision (OR `r cross_fit2 %>% coefficients %>% as.vector %>% extract2(3) %>% exp %>% round(1)` 95\% CI `r cross_fit2 %>% confint %>% magrittr::extract(3,1:2) %>% exp %>% round(1) %>% unname`).
The number of times donned per day was found to have a negligible effect with modest precision (OR `r cross_fit3 %>% coefficients %>% as.vector %>% extract2(3) %>% exp %>% round(1)` 95\% CI `r cross_fit3 %>% confint %>% magrittr::extract(3,1:2) %>% exp %>% round(1) %>% unname`).
In cox analysis, the number of sterilizations was found to have a small effect with modest precision (cox B =`r t1 %>% round(2)`, 95\% CI `r t1 %>% subtract(1.96*t2) %>% round(2) ` to  `r t1 %>% add(1.96*t2) %>% round(2) ` ).
The number of times donned per day was found to have a negligible effect with modest precision (cox B =`r t3 %>% round(2)`, 95\% CI `r t3 %>% subtract(1.96*t4) %>% round(2) ` to  `r t3 %>% add(1.96*t4) %>% round(2) ` ).


```{r echo=FALSE}
local_data <- prelim.df %>% group_by(Fits.well) %>% summarize(mfit=mean(fit.fail ), nfit=n(), lower=PropCIs::scoreci(x=sum(fit.fail), n=n(), conf.level=0.95)$conf.int[1], upper=PropCIs::scoreci(x=sum(fit.fail), n=n(), conf.level=0.95)$conf.int[2] )
local_data2 <- prelim.df %>%mutate(Fits.well = Fits.well == "No") %>% group_by(fit.fail) %>% summarize(mfit=mean(Fits.well ), nfit=n(), lower=PropCIs::scoreci(x=sum(Fits.well), n=n(), conf.level=0.95)$conf.int[1], upper=PropCIs::scoreci(x=sum(Fits.well), n=n(), conf.level=0.95)$conf.int[2] )
temp_conf <- with(prelim.df, caret::confusionMatrix(reference=factor(!fit.fail, labels=c("Yes", "No")), data=Fits.well %>% fct_recode(Yes="No", No="Yes" )))
local_data3 <- prelim.df %>% mutate(qual2=Mask.quality %in% c("Like New", "Good") ) %>% group_by(fit.fail) %>% summarize(mfit=mean(qual2 ), nfit=n(), lower=PropCIs::scoreci(x=sum(qual2), n=n(), conf.level=0.95)$conf.int[1], upper=PropCIs::scoreci(x=sum(qual2), n=n(), conf.level=0.95)$conf.int[2] )
local_data4 <- prelim.df %>% mutate(qual2=Mask.quality %in% c("Like New") ) %>% select(fit.fail, qual2 ) %>% table %>% fisher.test
```
Although imperfect, participants were able to somewhat discriminate poorly fitting masks.
Figure \@ref(fig:split) displays the survival stratified by perceived fit.
Among the `r local_data[1,3]` participants reporting a poor fit, `r local_data[1,2] %>% round(2) %>% multiply_by(100)`% failed the fit test (95% CI `r local_data[1,4]%>% round(2) %>% multiply_by(100)` to `r local_data[1,5]%>% round(2) %>% multiply_by(100)`).
Among the `r local_data[2,3]` participants reporting a good fit, `r local_data[2,2] %>% round(2)%>% multiply_by(100)`% failed the fit test (95% CI `r local_data[2,4]%>% round(2) %>% multiply_by(100)` to `r local_data[2,5]%>% round(2) %>% multiply_by(100)`, p `r fisher.test(prelim.df$Fits.well, prelim.df$fit.fail) %>% extract2("p.value") %>% format.pval(digits=2)` by Fisher's exact test).
Reversing the direction of conditioning, among those passing the fit test, `r local_data2[1,2] %>% round(2) %>% multiply_by(100)`% believed their mask was poorly fitting (95% CI `r local_data2[1,4]%>% round(2) %>% multiply_by(100)` to `r local_data2[1,5]%>% round(2) %>% multiply_by(100)`). 
Among those failing the fit test, `r local_data2[2,2] %>% round(2)%>% multiply_by(100)`% believed their mask to be poorly fitting (95% CI `r local_data2[2,4]%>% round(2) %>% multiply_by(100)` to `r local_data2[2,5]%>% round(2) %>% multiply_by(100)`).
The user's impression had a sensitivity of `r temp_conf[['byClass']]['Sensitivity'] %>% multiply_by(100) %>% round`%, specificity of `r temp_conf[['byClass']]['Specificity'] %>% multiply_by(100) %>% round`%, and positive and negative predictive values of  `r temp_conf[['byClass']]['Pos Pred Value'] %>% multiply_by(100) %>% round`% and  `r temp_conf[['byClass']]['Neg Pred Value'] %>% multiply_by(100) %>% round`%.
Test administrators also judged mask quality.
As seen in Table \@ref(tab:desc), very few masks were judged to be poor quality, but "Like New" and "Good" quality masks were `r local_data3[2,2] %>% round(2)%>% multiply_by(100)`% of the failed masks (95% CI `r local_data3[2,4]%>% round(2) %>% multiply_by(100)` to `r local_data3[2,5]%>% round(2) %>% multiply_by(100)`).
"Like New" masks were much less likely to fail, OR = `r local_data4$estimate %>% round(1)` (95% CI =`r local_data4$conf.int[1] %>% round(1)` to `r local_data4$conf.int[2] %>% round(1)`, p `r local_data4$p.value%>% format.pval(eps=0.001)`).

```{r split, echo=FALSE, fig.show="hold", warning=FALSE , message=FALSE, fig.keep="last", fig.cap="Comparison of mask failure by days worn stratified by user perceived fit. Black = entire study non-parametric interval censored survival (grey regions = indeterminate MLE), Red= smooth cross-sectional model among self-perceived good fit, Blue = smooth cross-sectional model among self-perceived bad fit "}
cross_fit2 <- cgam(fit.fail ~ s.incr(Days.Worn)*Fits.well  , family=binomial(), data=prelim.df )

npm_out %>% plot(xlim=c(4,20), XLAB="Days worn", YLAB="Failure probability", dtype="cdf")

dummy_data <- data.frame(Days.Worn = 4:20 , Fits.well =prelim.df$Fits.well %>% unique %>% magrittr::extract(1) )
dummy_data <- cbind(dummy_data, predict(cross_fit2, newData=dummy_data, interval="confidence")[c("fit", "lower", "upper")] %>% as.data.frame )
lines(dummy_data$Days.Worn, dummy_data$fit , col='red', lwd=2)
lines(dummy_data$Days.Worn, dummy_data$lower, col='red', lty=2)
lines(dummy_data$Days.Worn, dummy_data$upper, col='red', lty=2)

dummy_data <- data.frame(Days.Worn = 4:20 , Fits.well =prelim.df$Fits.well %>% unique %>% magrittr::extract(2) )
dummy_data <- cbind(dummy_data, predict(cross_fit2, newData=dummy_data, interval="confidence")[c("fit", "lower", "upper")] %>% as.data.frame )
lines(dummy_data$Days.Worn, dummy_data$fit , col='blue', lwd=2)
lines(dummy_data$Days.Worn, dummy_data$lower, col='blue', lty=2)
lines(dummy_data$Days.Worn, dummy_data$upper, col='blue', lty=2)
```

<!--
# Conclusions

In this data, mask fit failure was high for all durations of use and varied minimally by duration and number of uses.
This surprising finding has several potential explanations.
First and most concerning, mask fit failure could occur more frequently early in the use cycle among those where it will fail.
Use patterns or facial morphology may tend to early failure, while others are able to maintain a good fit for long duration of use.
Alternatively, our results could be generated if fit test failure were poorly measured (false failures) or related to inappropriate donning during the test, which would produce a uniform failure fraction.
However, in our re-testing protocol individuals were given new masks immediately after a failed fit and almost uniformly passed the fit test, which makes isolated inappropriate donning or test error a less likely explanation.
Strong selection bias where individuals joined the study when they believed their mask failed could generate similar uniform failure fractions, but is not consistent with the majority of participants believing their mask fit was acceptable.
If clearly failed masks were removed from the population before the experiment, the failure fraction would tend to be artificially decreased (or made more uniform).
However, during the period of the study N95 mask shortages were critical, and discarding masks appears to have been uncommon.
Because few individuals trained in mask fitting were available, re-testing was not readily available outside of our initiative, and participants had little ability to verify that a mask fit had failed.
As seen in Figure \@ref(fig:hists), individuals continued to use masks for long durations even before sterilization was available due to these shortages and lack of testing availability.
-->

# References




    services: ---
output: 
  bookdown::word_document2:
    fig_caption: true
    toc: false
title: "Web Appendix for Probability of Fit Failure with Reuse of N95 Respirators"
author: 
 -

date: "`r format(Sys.time(), '%B %d, %Y')`"
bibliography: n95.bib
---

```{r echo=FALSE, message=FALSE, results='hide'}
library(magrittr)
if(file.exists("n95_intermediates.Rdata"))  {
load("n95_intermediates.Rdata")
library("magrittr")
library("tidyverse")
library("survival")
library("rmarkdown")
library("interval")
library("cgam")
library("icenReg")
library("km.ci")
library("flexsurv")
library("bookdown")
library("tableone")
library("PropCIs")
} else {
source("n95_report.R")
}
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(dev = 'pdf')
```



# Modeling assumptions and strategy
The sample is generated cross-sectionally, but can also be thought of as survival data.
Each fit test provides interval censored information: masks observed to fail a fit test at time *t* failed at some point in $\left(0 , t\right)$ (masks are assumed to have been initially functional). 
Masks that pass the fit test fail some time in the future $(t, t_\textrm{max})$.
For survival analysis we assume that each mask is independent with failure hazard from from a common distribution.
Our parametric survival model fits a 3-parameter generalized gamma hazard to the interval censored data.

Non-parametric or semi-parametric estimators which do not assume a functional form of the hazard are common in traditional survival analysis, and are available for interval censored data as well.
However, non-parametric estimates (NPMLE) for interval censored data are not unique; in some regions any baseline hazard matching continuity requirements is equally supported by the data.
Confidence intervals for interval censored baseline hazards are an active area of research [@wang_flexible_2016; @zhao_simultaneous_2019], with completely non-parametric estimation methods yielding slow $n^\frac{1}{3}$ convergence without a known asymptotic law [@groeneboom_information_1992].
Several semi-parametric methods have recently been shown to have $n^\frac{1}{2}$ convergence with Gaussian asymptotics making them amenable to bootstrapping [@wang_flexible_2016; @bouaziz_regression_2018; @zhao_simultaneous_2019; @li_adaptive_2019].
Proportional hazards regression was used to model factors other than duration of use in this framework.

Modeling the data as cross-sectional observations of fit passing versus failure as a function of time is also supportable because no participant-mask pair is observed more than once and there is minimal information to support extrapolation from before the earliest test time.
Because only a very small number of individuals are tested on more than one mask, we do not model or adjust for participant effects.
Integrated b-splines and constrained step functions allow modeling the failure log-odds as a monotone increasing function of time in a traditional logistic regression analysis.
This approach yields much better studied statistical behavior; however, given the modest sample size the probability statements produced should be taken as approximate.
The cross-sectional model does not encode any behavior before the earliest test time (e.g. that all masks initially fit).
We found that the cross-sectional model and non-parametric and semi-parametric survival models yield essentially identical point estimates when tuned appropriately, which is anticipated based on the use of step functions and splines to model the baseline hazard in the survival routines.

Factors beyond use duration were analyzed with proportional hazards regression (interval survival) or logistic regression (cross sectional).
Calculations were performed in R 3.6.3 with package flexsurv [@jackson_flexsurv_2016] for parametric survival modeling, icenReg [@anderson-bergman_icenreg_2017] for non-parametric survival modeling, and cgam [@liao_cgam_2019] for monotone logistic regression. 
Reported confidence intervals are at the 0.95 level.
Because this was an exploratory study, no pre-determined p-value threshold was applied.

# Results
```{r echo=FALSE}
cross_fit <- cgam(fit.fail ~ s.incr(Days.Worn) , family=binomial(), data=prelim.df )
dummy_data <- data.frame(Days.Worn = c(4,10,15))
dummy_data <- cbind(dummy_data, predict(cross_fit, newData=dummy_data, interval="confidence")[c("fit", "lower", "upper")] %>% as.data.frame )
```

```{r desc, echo=FALSE, messages=FALSE, results='asis'}
factor_vars<- c('Sex' , 'Title' , 'Respirator', 'Fits.well', 'Mask.quality'  )
non_vars <- c( 'Days.Worn', 'Sterilizations', 'Uses' )
con_vars<- c( 'Days.Worn', 'Sterilizations', 'Uses' )
tab3 <- CreateTableOne(vars = c(con_vars,factor_vars) , strata = "fit.fail" , data = prelim.df%>%  mutate(fit.fail=factor(fit.fail, labels=c("Pass", "Fail")) )  , factorVars = factor_vars)
temp <- capture.output(x <- print(tab3 , showAllLevels = TRUE, contDigits=0, printToggle=FALSE, nonnormal=TRUE, exact=T))

tab2 <- CreateTableOne(vars ='Uses.per.day' , strata = "fit.fail" , data = prelim.df%>%  mutate( Uses.per.day=Uses/Days.Worn ) %>% mutate(fit.fail=factor(fit.fail, labels=c("Pass", "Fail")) )  )

temp <- capture.output(x2<- print(tab2 , showAllLevels = TRUE, contDigits=1, printToggle=FALSE, nonnormal=FALSE, exact=T))

x<- rbind(x[1:length(con_vars), ,drop=FALSE], x2[-1,,drop=FALSE], x[-c(1:length(con_vars)), ,drop=FALSE] )

x <- x[,seq(ncol(x)-1)]
rownames(x) <- gsub(rownames(x), pattern=".", fixed=TRUE, replacement=" " )
    knitr::kable(x, caption="Descriptive statistics stratified by fit test failure. P-values for quantitative variables by Mann-Whitney U, factor variables by Fisher's exact test.", format='pandoc')
```

Table \@ref(tab:desc) provides descriptive statistics.
Notably, male participants were less likely to fail fit tests both marginally and adjusting for the number of days worn (OR = `r temp <- glm(fit.fail ~ ns(Days.Worn) + Sex, data=prelim.df); temp2<- temp %>% coef %>% exp %>% extract2(3) %>% round(1); temp2 <- paste(temp2, "95% CI", paste(temp%>% confint %>% exp %>% magrittr::extract(3,1:2) %>% round(1), collapse=" to ") ); temp2   `).
Figure \@ref(fig:hists) displays histograms of number of days worn, number of times used, and number of times sterilized.
Surprisingly, the use duration and intensity was not markedly different between failed and passed mask fits.
Breaking the data into groups by number of days worn, the failure fraction is displayed in Table \@ref(tab:broken).
Table \@ref(tab:broken) shows that the failure fraction at all times is high; approximately 50% in all time categories.

```{r hists, echo=FALSE, fig.show="hold", fig.keep="last", fig.cap="Mask use histograms."}
par(mfrow=c(3,1), oma=c(0,0,0,0), mar=c(2, 3, 2,0))
hist(prelim.df  %>% select(Days.Worn) %>% unlist ,breaks = seq(from=0.5, to=60.5), plot=T, main="Days Worn", xlab=NULL, col= rgb(0.6,1.0,1.0,alpha=0.5))
hist(prelim.df  %>% select(Uses) %>% unlist , breaks=20, plot=T, main="Times used", xlab=NULL, col= rgb(0.6,1.0,1.0,alpha=0.5))
hist(prelim.df  %>% select(Sterilizations) %>% unlist ,  plot=T, main="Times sterilized", xlab=NULL, col= rgb(0.6,1.0,1.0,alpha=0.5))
par(mfrow=c(1,1))
```


```{r broken, echo=FALSE, results='asis' }
prelim.df %>% mutate(day_group = cut(Days.Worn, breaks=c(0.5, 5, 8, 12, 61)) ) %>% group_by(day_group) %>% summarize(n=n() , mean.failure=mean(fit.fail )%>% round(2) %>% multiply_by(100), lower.conf= paste( "(" , PropCIs::scoreci(x=sum(fit.fail), n=n(), conf.level=0.95)$conf.int[1]%>% round(2)%>% multiply_by(100), ",", PropCIs::scoreci(x=sum(fit.fail), n=n(), conf.level=0.95)$conf.int[2]%>% round(2)%>% multiply_by(100) , ")" ) ) %>% set_colnames(c("days worn", "n", "failed %", "CI")) %>% {knitr::kable(x=., align="c", format="pandoc", caption="Failure fractions by duration worn. Confidence intervals by Wilson's score method. ")}
```

Figure \@ref(fig:basicsurvival) displays mask survival as a function of days worn using cross-sectional approaches.
A monotone fit (I-splines) and natural spline (no restrictions) can be seen to agree well with non-parametric monotone methods.
The failure fraction at day `r dummy_data[1, "Days.Worn"]%>% as.integer` is `r dummy_data[1, "fit"]%>% round(2)` (95\% CI `r round(dummy_data[1,c("lower", "upper")],2)`). At day `r dummy_data[2, "Days.Worn"]%>% as.integer` the failure has increased to `r dummy_data[2, "fit"]%>% round(2)` (95\% CI `r round(dummy_data[2,c("lower", "upper")],2)`) and day `r dummy_data[3, "Days.Worn"]%>% as.integer` to `r dummy_data[3, "fit"]%>% round(2)` (95\% CI `r round(dummy_data[3,c("lower", "upper")],2)`).


```{r basicsurvival, echo=FALSE, fig.show="hold", fig.keep="last", fig.cap="Comparison of cross sectional logistic regression models for mask Failure by number of days worn. Black = non-parametric monotone (step functions), Red = semi-parametric smooth with monotone constraint, Blue = semi-parametric smooth (no monotone requirement). Dashed lines 95% point-wise confidence limits. Fit with cgam package."}
cross_fit <- cgam(fit.fail ~ incr(Days.Worn) , family=binomial(), data=prelim.df )
dummy_data <- data.frame(Days.Worn = 4:20)
dummy_data <- cbind(dummy_data, predict(cross_fit, newData=dummy_data, interval="confidence")[c("fit", "lower", "upper")] %>% as.data.frame )
plot(dummy_data$Days.Worn, dummy_data$fit , xlab="Days worn", ylab="Failure probability", ylim=c(0,1), xlim=c(4,20), type="l")
lines(dummy_data$Days.Worn, dummy_data$lower, lty=2)
lines(dummy_data$Days.Worn, dummy_data$upper, lty=2)

cross_fit <- cgam(fit.fail ~ s.incr(Days.Worn) , family=binomial(), data=prelim.df )
dummy_data <- data.frame(Days.Worn = 4:20)
dummy_data <- cbind(dummy_data, predict(cross_fit, newData=dummy_data, interval="confidence")[c("fit", "lower", "upper")] %>% as.data.frame )
points(dummy_data$Days.Worn, dummy_data$fit , col='red', type="l")
lines(dummy_data$Days.Worn, dummy_data$lower, col='red', lty=2)
lines(dummy_data$Days.Worn, dummy_data$upper, col='red', lty=2)


cross_fit <- glm(fit.fail ~ ns(Days.Worn) , family=binomial(), data=prelim.df )
dummy_data <- data.frame(Days.Worn = 4:20)
dummy_data <- cbind(dummy_data, predict(cross_fit, newdata=dummy_data, se.fit=TRUE)[c("fit", "se.fit")] %>% as.data.frame )

points(dummy_data$Days.Worn, cross_fit$family$linkinv(dummy_data$fit) , col='blue', type="l")
dummy_data %<>% mutate( lower=cross_fit$family$linkinv(fit - 1.96*se.fit), upper=cross_fit$family$linkinv(fit+1.96*se.fit))
lines(dummy_data$Days.Worn, dummy_data$lower, col='blue', lty=2)
lines(dummy_data$Days.Worn, dummy_data$upper, col='blue', lty=2)
```

Figure \@ref(fig:comparesurv) compares interval censored survival-based analyses and the cross-sectional analysis.
The parametric model diverges from the non-parametric MLE at the extremes of time, as it requires a smoother change between the initial state (0 failure) to the early observed times.
The generalized gamma and Weibull parametric families fit well.
Figure \@ref(fig:comparepara) displays the results with gamma and weibull hazards.


```{r comparesurv, echo=FALSE, fig.show="hold", fig.keep="last", fig.cap="Comparison of survival and cross-sectional models for mask failure by number of days worn. Black = non-parametric survival with interval censoring (grey regions = indeterminate MLE), Red = generalized gamma survival model with interval censoring, Blue = cross sectional monotone smooth. Dashed lines 95% point-wise confidence limits. "}
npm_out %>% plot(xlim=c(4,20), XLAB="Days worn", YLAB="Failure probability", dtype="cdf")
fs_1 <- flexsurvreg(Surv(left, right, type="interval2")~1, data=prelim.df, dist="gengamma")
cross_fit <- cgam(fit.fail ~ s.incr(Days.Worn) , family=binomial(), data=prelim.df )
dummy_data <- data.frame(Days.Worn = 4:20)
dummy_data <- cbind(dummy_data, predict(cross_fit, newData=dummy_data, interval="confidence")[c("fit", "lower", "upper")] %>% as.data.frame )
lines(dummy_data$Days.Worn, dummy_data$fit , col='blue', lwd=2)
lines(dummy_data$Days.Worn, dummy_data$lower, col='blue', lty=2)
lines(dummy_data$Days.Worn, dummy_data$upper, col='blue', lty=2)

failure_probs<- summary(fs_1, type="survival", t=4:20, se=TRUE, ci=TRUE)[[1]]

lines(failure_probs$time, 1-failure_probs$est, col="red")
lines(failure_probs$time, 1-failure_probs$lcl, col="red", lty=2)
lines(failure_probs$time, 1-failure_probs$ucl, col="red", lty=2)
```

```{r comparepara, echo=FALSE, fig.show="hold", warning=FALSE , message=FALSE, fig.keep="last", fig.cap="Comparison of parametric family survival models. Black = non-parametric survival (grey regions = indeterminate MLE), Red = generalized gamma survival, Blue = Weibull. Dashed lines 95% point-wise confidence limits. Fit with cgam package."}
npm_out %>% plot(xlim=c(4,20), XLAB="Days worn", YLAB="Failure probability", dtype="cdf")
lines(failure_probs$time, 1-failure_probs$est, col="red")
lines(failure_probs$time, 1-failure_probs$lcl, col="red", lty=2)
lines(failure_probs$time, 1-failure_probs$ucl, col="red", lty=2)


fs_1 <- flexsurvreg(Surv(left, right, type="interval2")~1, data = prelim.df, dist="weibull")

failure_probs<- summary(fs_1, type="survival", t=4:20, se=TRUE, ci=TRUE)[[1]]
lines(failure_probs$time, 1-failure_probs$est, col="blue")
lines(failure_probs$time, 1-failure_probs$lcl, col="blue", lty=2)
lines(failure_probs$time, 1-failure_probs$ucl, col="blue", lty=2)
```

We also computed a traditional Kaplan-Meier curve treating the data as right censored only (assuming that participants joined the experiment about when their masks failed).
This is displayed in Figure \@ref(fig:comparekm), which shows much lower estimated early failure fractions as the later failures are no longer considered a possible early failure.

```{r comparekm, echo=FALSE, fig.show="hold", warning=FALSE , message=FALSE, fig.keep="last", fig.cap="Comparison of interval censored and traditional survival estimates of mask failure by number of days worn. Black = non-parametric interval censored survival (grey regions = indeterminate MLE), Red = right censored only (Kaplan-Meier)"}
npm_out %>% plot(xlim=c(4,20), XLAB="Days worn", YLAB="Failure probability", dtype="cdf")

lines(km.ci(survfit(Surv(time=Days.Worn, event=fit.fail)~1, data=prelim.df) ), col='red', fun='F')
```

Similar analysis for failure by number of times donned is shown in Figure \@ref(fig:comparedon).
The failure fraction is similarly flat.
Number of times used was fairly correlated with number of days worn (spearman correlation = `r  with(prelim.df, cor(Uses, Days.Worn, method="spearman") )%>% round(2)`, p `r with(prelim.df, wilcox.test(Uses, Days.Worn))$p.value %>% format.pval(eps=.001)`).


```{r comparedon, echo=FALSE, fig.show="hold", warning=FALSE , message=FALSE, fig.keep="last", fig.cap="Comparison of survival and cross sectional models for mask failure by number of times used. Black = non-parametric interval censored survival (grey regions = indeterminate MLE), Red = cross-sectional analysis, Blue = generalized gamma survival"}
npm_out2 %>% plot(xlim=c(6,50), XLAB="Times used", YLAB="Failure probability", dtype="cdf")
fs_1 <- flexsurvreg(Surv(left, right, type="interval2")~1, dist="gengamma", data=prelim.df2)
failure_probs<- summary(fs_1, type="survival", t=6:50, se=TRUE, ci=TRUE)[[1]]

lines(failure_probs$time, 1-failure_probs$est, col="blue")
lines(failure_probs$time, 1-failure_probs$lcl, col="blue", lty=2)
lines(failure_probs$time, 1-failure_probs$ucl, col="blue", lty=2)

cross_fit3 <- cgam(fit.fail ~ incr(Uses) , family=binomial(), data=prelim.df )
dummy_data <- data.frame(Uses = 6:55)
dummy_data <- cbind(dummy_data, predict(cross_fit3, newData=dummy_data, interval="confidence")[c("fit", "lower", "upper")] %>% as.data.frame )
lines(dummy_data$Uses, dummy_data$fit , col='red', lwd=2)
lines(dummy_data$Uses, dummy_data$lower, col='red', lty=2)
lines(dummy_data$Uses, dummy_data$upper, col='red', lty=2)
```
```{r echo=FALSE}
cross_fit <- glm(fit.fail ~ ns(Days.Worn) , family=binomial(), data=prelim.df )
cross_fit2 <- glm(fit.fail ~ ns(Days.Worn) +Sterilizations  , family=binomial(), data=prelim.df )
basic <- glm(fit.fail ~ Sterilizations , family=binomial(), data=prelim.df )
cross_fit3 <- glm(fit.fail ~ ns(Days.Worn) +I(Uses/Days.Worn)  , family=binomial(), data=prelim.df )

t1 <- np_reg %>% summary %>% extract2("summaryParameters") %>% as.vector %>% extract2(1) 
t2 <- np_reg %>% summary %>% extract2("summaryParameters") %>% as.vector %>% extract2(3) 
t3 <- np_reg2b %>% summary %>% extract2("summaryParameters") %>% as.vector %>% extract2(1)
t4 <- np_reg2b %>% summary %>% extract2("summaryParameters") %>% as.vector %>% extract2(3) 

```

Alternative factors contributing to fit failure analyzed included number of sterilizations and intensity of use (number of times donned per day). 
Using the logistic regression model, the number of sterilizations was found to have a modest effect with modest precision (OR `r cross_fit2 %>% coefficients %>% as.vector %>% extract2(3) %>% exp %>% round(1)` 95\% CI `r cross_fit2 %>% confint %>% magrittr::extract(3,1:2) %>% exp %>% round(1) %>% unname`).
The number of times donned per day was found to have a negligible effect with modest precision (OR `r cross_fit3 %>% coefficients %>% as.vector %>% extract2(3) %>% exp %>% round(1)` 95\% CI `r cross_fit3 %>% confint %>% magrittr::extract(3,1:2) %>% exp %>% round(1) %>% unname`).
In cox analysis, the number of sterilizations was found to have a small effect with modest precision (cox B =`r t1 %>% round(2)`, 95\% CI `r t1 %>% subtract(1.96*t2) %>% round(2) ` to  `r t1 %>% add(1.96*t2) %>% round(2) ` ).
The number of times donned per day was found to have a negligible effect with modest precision (cox B =`r t3 %>% round(2)`, 95\% CI `r t3 %>% subtract(1.96*t4) %>% round(2) ` to  `r t3 %>% add(1.96*t4) %>% round(2) ` ).


```{r echo=FALSE}
local_data <- prelim.df %>% group_by(Fits.well) %>% summarize(mfit=mean(fit.fail ), nfit=n(), lower=PropCIs::scoreci(x=sum(fit.fail), n=n(), conf.level=0.95)$conf.int[1], upper=PropCIs::scoreci(x=sum(fit.fail), n=n(), conf.level=0.95)$conf.int[2] )
local_data2 <- prelim.df %>%mutate(Fits.well = Fits.well == "No") %>% group_by(fit.fail) %>% summarize(mfit=mean(Fits.well ), nfit=n(), lower=PropCIs::scoreci(x=sum(Fits.well), n=n(), conf.level=0.95)$conf.int[1], upper=PropCIs::scoreci(x=sum(Fits.well), n=n(), conf.level=0.95)$conf.int[2] )
temp_conf <- with(prelim.df, caret::confusionMatrix(reference=factor(!fit.fail, labels=c("Yes", "No")), data=Fits.well %>% fct_recode(Yes="No", No="Yes" )))
local_data3 <- prelim.df %>% mutate(qual2=Mask.quality %in% c("Like New", "Good") ) %>% group_by(fit.fail) %>% summarize(mfit=mean(qual2 ), nfit=n(), lower=PropCIs::scoreci(x=sum(qual2), n=n(), conf.level=0.95)$conf.int[1], upper=PropCIs::scoreci(x=sum(qual2), n=n(), conf.level=0.95)$conf.int[2] )
local_data4 <- prelim.df %>% mutate(qual2=Mask.quality %in% c("Like New") ) %>% select(fit.fail, qual2 ) %>% table %>% fisher.test
```
Although imperfect, participants were able to somewhat discriminate poorly fitting masks.
Figure \@ref(fig:split) displays the survival stratified by perceived fit.
Among the `r local_data[1,3]` participants reporting a poor fit, `r local_data[1,2] %>% round(2) %>% multiply_by(100)`% failed the fit test (95% CI `r local_data[1,4]%>% round(2) %>% multiply_by(100)` to `r local_data[1,5]%>% round(2) %>% multiply_by(100)`).
Among the `r local_data[2,3]` participants reporting a good fit, `r local_data[2,2] %>% round(2)%>% multiply_by(100)`% failed the fit test (95% CI `r local_data[2,4]%>% round(2) %>% multiply_by(100)` to `r local_data[2,5]%>% round(2) %>% multiply_by(100)`, p `r fisher.test(prelim.df$Fits.well, prelim.df$fit.fail) %>% extract2("p.value") %>% format.pval(digits=2)` by Fisher's exact test).
Reversing the direction of conditioning, among those passing the fit test, `r local_data2[1,2] %>% round(2) %>% multiply_by(100)`% believed their mask was poorly fitting (95% CI `r local_data2[1,4]%>% round(2) %>% multiply_by(100)` to `r local_data2[1,5]%>% round(2) %>% multiply_by(100)`). 
Among those failing the fit test, `r local_data2[2,2] %>% round(2)%>% multiply_by(100)`% believed their mask to be poorly fitting (95% CI `r local_data2[2,4]%>% round(2) %>% multiply_by(100)` to `r local_data2[2,5]%>% round(2) %>% multiply_by(100)`).
The user's impression had a sensitivity of `r temp_conf[['byClass']]['Sensitivity'] %>% multiply_by(100) %>% round`%, specificity of `r temp_conf[['byClass']]['Specificity'] %>% multiply_by(100) %>% round`%, and positive and negative predictive values of  `r temp_conf[['byClass']]['Pos Pred Value'] %>% multiply_by(100) %>% round`% and  `r temp_conf[['byClass']]['Neg Pred Value'] %>% multiply_by(100) %>% round`%.
Test administrators also judged mask quality.
As seen in Table \@ref(tab:desc), very few masks were judged to be poor quality, but "Like New" and "Good" quality masks were `r local_data3[2,2] %>% round(2)%>% multiply_by(100)`% of the failed masks (95% CI `r local_data3[2,4]%>% round(2) %>% multiply_by(100)` to `r local_data3[2,5]%>% round(2) %>% multiply_by(100)`).
"Like New" masks were much less likely to fail, OR = `r local_data4$estimate %>% round(1)` (95% CI =`r local_data4$conf.int[1] %>% round(1)` to `r local_data4$conf.int[2] %>% round(1)`, p `r local_data4$p.value%>% format.pval(eps=0.001)`).

```{r split, echo=FALSE, fig.show="hold", warning=FALSE , message=FALSE, fig.keep="last", fig.cap="Comparison of mask failure by days worn stratified by user perceived fit. Black = entire study non-parametric interval censored survival (grey regions = indeterminate MLE), Red= smooth cross-sectional model among self-perceived good fit, Blue = smooth cross-sectional model among self-perceived bad fit "}
cross_fit2 <- cgam(fit.fail ~ s.incr(Days.Worn)*Fits.well  , family=binomial(), data=prelim.df )

npm_out %>% plot(xlim=c(4,20), XLAB="Days worn", YLAB="Failure probability", dtype="cdf")

dummy_data <- data.frame(Days.Worn = 4:20 , Fits.well =prelim.df$Fits.well %>% unique %>% magrittr::extract(1) )
dummy_data <- cbind(dummy_data, predict(cross_fit2, newData=dummy_data, interval="confidence")[c("fit", "lower", "upper")] %>% as.data.frame )
lines(dummy_data$Days.Worn, dummy_data$fit , col='red', lwd=2)
lines(dummy_data$Days.Worn, dummy_data$lower, col='red', lty=2)
lines(dummy_data$Days.Worn, dummy_data$upper, col='red', lty=2)

dummy_data <- data.frame(Days.Worn = 4:20 , Fits.well =prelim.df$Fits.well %>% unique %>% magrittr::extract(2) )
dummy_data <- cbind(dummy_data, predict(cross_fit2, newData=dummy_data, interval="confidence")[c("fit", "lower", "upper")] %>% as.data.frame )
lines(dummy_data$Days.Worn, dummy_data$fit , col='blue', lwd=2)
lines(dummy_data$Days.Worn, dummy_data$lower, col='blue', lty=2)
lines(dummy_data$Days.Worn, dummy_data$upper, col='blue', lty=2)
```

<!--
# Conclusions

In this data, mask fit failure was high for all durations of use and varied minimally by duration and number of uses.
This surprising finding has several potential explanations.
First and most concerning, mask fit failure could occur more frequently early in the use cycle among those where it will fail.
Use patterns or facial morphology may tend to early failure, while others are able to maintain a good fit for long duration of use.
Alternatively, our results could be generated if fit test failure were poorly measured (false failures) or related to inappropriate donning during the test, which would produce a uniform failure fraction.
However, in our re-testing protocol individuals were given new masks immediately after a failed fit and almost uniformly passed the fit test, which makes isolated inappropriate donning or test error a less likely explanation.
Strong selection bias where individuals joined the study when they believed their mask failed could generate similar uniform failure fractions, but is not consistent with the majority of participants believing their mask fit was acceptable.
If clearly failed masks were removed from the population before the experiment, the failure fraction would tend to be artificially decreased (or made more uniform).
However, during the period of the study N95 mask shortages were critical, and discarding masks appears to have been uncommon.
Because few individuals trained in mask fitting were available, re-testing was not readily available outside of our initiative, and participants had little ability to verify that a mask fit had failed.
As seen in Figure \@ref(fig:hists), individuals continued to use masks for long durations even before sterilization was available due to these shortages and lack of testing availability.
-->

# References




      postgres: library(PropCIs)
library(magrittr)

baseline_rate <-0.3




sizes_to_use <- seq(from=30, to=200, by=10)
res_mat <- matrix(NA, nrow=length(sizes_to_use), ncol=4 )
num_sim <- 1000
for( local_size in seq_along(sizes_to_use)) {
local_x <-rbinom(n=num_sim, prob=baseline_rate, size=sizes_to_use[local_size]) %>% scoreci(x=., n= sizes_to_use[local_size], conf.level=.95) %>% extract2("conf.int") %>% matrix(ncol=2)
local_x[,1] <- local_x[,1] *-1
local_x <- rowSums(local_x)
res_mat[local_size,] <- c(sizes_to_use[local_size], quantile(local_x, prob=c(.25, .5, .75) ) )
}

pdf("validation_sample_size.pdf")
plot( res_mat[,1], res_mat[,3], xlab="sample size", ylab="expected CI width", lwd=2, type="l")
lines( res_mat[,1], res_mat[,2], lty=2)
lines( res_mat[,1], res_mat[,4], lty=2)

abline(h=c(.15, .2), col='red')


res_mat[which.max(res_mat[,3] <.20 ),1]
res_mat[which.max(res_mat[,3] <.15 ),1]
dev.off()


num_sim <- 200
library(foreach)
library('doParallel')

registerDoParallel(cores=8)
library(flexsurv)
library(dplyr)
res_mat_surv <- matrix(NA, nrow=length(sizes_to_use), ncol=4 )
daily_fail <- c(.1, .1, .1, .1 , .6)

for( local_size in seq_along(sizes_to_use)) {


  local_res <- foreach(local_index = seq_len(num_sim) , .combine='c', .inorder=FALSE) %dopar% {
    local_x <-sample.int(n=5,size=sizes_to_use[local_size], prob=daily_fail, replace=TRUE) 
    local_surv <- data.frame(obs = (local_x)) %>% mutate(left=obs %>% subtract(1) %>% pmax(0.25), right=if_else(obs==5L, 20, as.numeric(obs)) ) %>% mutate(left = if_else(obs==5L, 4, left))
    fs_1 <- flexsurvreg(Surv(left, right, type="interval2")~1, data=local_surv, dist="gamma")
    local_out <- summary(fs_1, type="survival", t=3, se=TRUE, ci=TRUE)[[1]]
    diff(local_out[,3:4, drop=TRUE] %>% unlist)
  }

  res_mat_surv[local_size,] <- c(sizes_to_use[local_size], quantile(local_res, prob=c(.25, .5, .75) ) )

}


pdf("validation_sample_survival_size.pdf")
plot( res_mat_surv[,1], res_mat_surv[,3], xlab="sample size", ylab="expected CI width", lwd=2, type="l", col='red')
lines( res_mat_surv[,1], res_mat_surv[,2], lty=2, col='red')
lines( res_mat_surv[,1], res_mat_surv[,4], lty=2, col='red')


lines( res_mat[,1], res_mat[,3])
lines( res_mat[,1], res_mat[,2], lty=2)
lines( res_mat[,1], res_mat[,4], lty=2)

dev.off()




library("km.ci")
res_mat_km <- matrix(NA, nrow=length(sizes_to_use), ncol=4 )
daily_fail <- c(.1, .1, .1, .1 , .6)

for( local_size in seq_along(sizes_to_use)) {


  local_res <- foreach(local_index = seq_len(num_sim) , .combine='c', .inorder=FALSE) %dopar% {

    local_x <-sample.int(n=5,size=sizes_to_use[local_size], prob=daily_fail, replace=TRUE) 
    local_surv <- data.frame(obs = (local_x)) %>% mutate(left=obs %>% subtract(1) %>% pmax(0.25), right=if_else(obs==5L, 20, as.numeric(obs)) ) %>% mutate(left = if_else(obs==5L, 4, left))
    fs_1 <- km.ci(survfit(Surv(time=obs,event=obs<5, type="right")~1, data=local_surv))
    local_out <- summary(fs_1, type="survival", t=3)

    local_out$upper - local_out$lower
  }

  res_mat_km[local_size,] <- c(sizes_to_use[local_size], quantile(local_res, prob=c(.25, .5, .75) ) )

}




pdf("validation_sample_survival_size.pdf")
plot( res_mat_surv[,1], res_mat_surv[,3], xlab="sample size", ylab="expected CI width", lwd=2, type="l", col='red')
lines( res_mat_surv[,1], res_mat_surv[,2], lty=2, col='red')
lines( res_mat_surv[,1], res_mat_surv[,4], lty=2, col='red')


lines( res_mat[,1], res_mat[,3])
lines( res_mat[,1], res_mat[,2], lty=2)
lines( res_mat[,1], res_mat[,4], lty=2)


lines( res_mat_km[,1], res_mat_km[,3] , col='green')
lines( res_mat_km[,1], res_mat_km[,2], lty=2, col='green')
lines( res_mat_km[,1], res_mat_km[,4], lty=2, col='green')


dev.off()





        image: migrator_ts: 1695775149
__migrator:
  kind: version
  migration_number: 1
  bump_number: 1
  commit_message: "Rebuild for libboost 1.82"
  # limit the number of prs for ramp-up
  pr_limit: 10
libboost_devel:
  - 1.82
# This migration is matched with a piggy-back migrator
# (see https://github.com/regro/cf-scripts/pull/1668)
# that will replace boost-cpp with libboost-devel
boost_cpp:
  - 1.82
# same for boost -> libboost-python-devel
libboost_python_devel:
  - 1.82
boost:
  - 1.82
        ports: __migrator:
  build_number: 1
  kind: version
  migration_number: 1
fmt:
- '10'
migrator_ts: 1683802784.4940007
          
        env: __migrator:
  build_number: 1
  kind: version
  migration_number: 1
libthrift:
- 0.19.0
migrator_ts: 1693762377.7427814
          POSTGRES_DB: migrator_ts: 1698047052
__migrator:
  kind: version
  migration_number: 1
  bump_number: 1

zeromq:
  - '4.3.5'
          POSTGRES_USER: This file is automatically generated by conda-smithy. If any
particular build configuration is expected, but it is not found,
please make sure all dependencies are satisfiable. To add/modify any
matrix elements, you should create/change conda-smithy's input
recipe/conda_build_config.yaml and re-render the recipe, rather than
editing these files directly.
          POSTGRES_PASSWORD: alsa_lib:
- '1.2'
c_compiler:
- gcc
c_compiler_version:
- '12'
cdt_name:
- cos7
channel_sources:
- conda-forge
channel_targets:
- gnuradio main
cxx_compiler:
- gxx
cxx_compiler_version:
- '12'
docker_image:
- quay.io/condaforge/linux-anvil-cos7-x86_64
fftw:
- '3'
gmp:
- '6'
gsl:
- '2.7'
libboost_devel:
- '1.82'
libiio:
- '0'
libsndfile:
- '1.2'
libthrift:
- 0.20.0
numpy:
- '1.23'
pin_run_as_build:
  python:
    min_pin: x.x
    max_pin: x.x
pybind11_abi:
- '4'
pyqt:
- '5.15'
python:
- 3.11.* *_cpython
qt_main:
- '5.15'
soapysdr:
- '0.8'
spdlog:
- '1.12'
target_platform:
- linux-64
uhd:
- 4.6.0
volk:
- '3.1'
zeromq:
- 4.3.5
zip_keys:
- - c_compiler_version
  - cxx_compiler_version
- - python
  - numpy
    env: MACOSX_DEPLOYMENT_TARGET:
- '10.13'
MACOSX_SDK_VERSION:
- '10.13'
c_compiler:
- clang
c_compiler_version:
- '16'
channel_sources:
- conda-forge
channel_targets:
- gnuradio main
cxx_compiler:
- clangxx
cxx_compiler_version:
- '16'
fftw:
- '3'
gmp:
- '6'
gsl:
- '2.7'
libboost_devel:
- '1.82'
libiio:
- '0'
libsndfile:
- '1.2'
libthrift:
- 0.20.0
macos_machine:
- x86_64-apple-darwin13.4.0
numpy:
- '1.23'
pin_run_as_build:
  python:
    min_pin: x.x
    max_pin: x.x
pybind11_abi:
- '4'
pyqt:
- '5.15'
python:
- 3.11.* *_cpython
qt_main:
- '5.15'
soapysdr:
- '0.8'
spdlog:
- '1.12'
target_platform:
- osx-64
uhd:
- 4.6.0
volk:
- '3.1'
zeromq:
- 4.3.5
zip_keys:
- - c_compiler_version
  - cxx_compiler_version
- - python
  - numpy
      RAILS_ENV: c_compiler:
- vs2022
channel_sources:
- conda-forge
channel_targets:
- gnuradio main
cxx_compiler:
- vs2022
fftw:
- '3'
gsl:
- '2.7'
libboost_devel:
- '1.82'
libiio:
- '0'
libsndfile:
- '1.2'
numpy:
- '1.23'
pin_run_as_build:
  python:
    min_pin: x.x
    max_pin: x.x
pybind11_abi:
- '4'
pyqt:
- '5.15'
python:
- 3.11.* *_cpython
qt_main:
- '5.15'
soapysdr:
- '0.8'
spdlog:
- '1.12'
target_platform:
- win-64
uhd:
- 4.6.0
volk:
- '3.1'
zeromq:
- 4.3.5
zip_keys:
- - python
  - numpy
      DATABASE_URL: setlocal EnableDelayedExpansion
@echo on

:: Make a build folder and change to it
cmake -E make_directory build
if errorlevel 1 exit 1
cd build
if errorlevel 1 exit 1

:: configure
cmake -G "Ninja" ^
    -DCMAKE_BUILD_TYPE=Release ^
    -DCMAKE_INSTALL_PREFIX="%LIBRARY_PREFIX%" ^
    -DCMAKE_PREFIX_PATH="%LIBRARY_PREFIX%" ^
    -DPYTHON_EXECUTABLE="%PYTHON%" ^
    -DGR_PYTHON_DIR="%SP_DIR%" ^
    ..
if errorlevel 1 exit 1

:: build
cmake --build . --config Release -- -j%CPU_COUNT%
if errorlevel 1 exit 1

:: install
cmake --build . --config Release --target install
if errorlevel 1 exit 1

:: test
set SKIP_TESTS=^
%=EMPTY=%

ctest --build-config Release --output-on-failure --timeout 120 -j%CPU_COUNT% -E "%SKIP_TESTS%"
if errorlevel 1 exit 1

:: now run the skipped tests to see failures, but exit without error anyway
ctest --build-config Release --output-on-failure --timeout 120 -j%CPU_COUNT% -R "%SKIP_TESTS%"
exit 0
    steps: #!/usr/bin/env bash

if [[ $target_platform == osx* ]] ; then
    CXXFLAGS="${CXXFLAGS} -D_LIBCPP_DISABLE_AVAILABILITY"
fi

# Workaround for no std::aligned_alloc with osx-64
# https://github.com/chriskohlhoff/asio/issues/1090
# Maybe remove when boost is updated to 1.80.0?
if [[ "${target_platform}" == "osx-64" ]]; then
  export CXXFLAGS="-DBOOST_ASIO_DISABLE_STD_ALIGNED_ALLOC ${CXXFLAGS}"
fi

cmake -E make_directory build
cd build

cmake_config_args=(
    -DCMAKE_BUILD_TYPE=Release
    -DCMAKE_PREFIX_PATH=$PREFIX
    -DCMAKE_INSTALL_PREFIX=$PREFIX
    -DLIB_SUFFIX=""
    -DPYTHON_EXECUTABLE=$PYTHON
    -DGR_PYTHON_DIR=$SP_DIR
)

cmake ${CMAKE_ARGS} -G "Ninja" .. "${cmake_config_args[@]}"
cmake --build . --config Release -- -j${CPU_COUNT}

cmake --build . --config Release --target install

if [[ $target_platform == linux* ]] ; then
    export QT_QPA_PLATFORM=offscreen
    SKIP_TESTS=(
    )
else
    SKIP_TESTS=(
    )
fi
SKIP_TESTS_STR=$( IFS="|"; echo "^(${SKIP_TESTS[*]})$" )

ctest --build-config Release --output-on-failure --timeout 120 -j${CPU_COUNT} -E "$SKIP_TESTS_STR"

# now run the skipped tests to see the failures, but don't error out
ctest --build-config Release --output-on-failure --timeout 120 -j${CPU_COUNT} -R "$SKIP_TESTS_STR" || exit 0
      - name: channel_targets:
  - gnuradio main
c_compiler:    # [win]
- vs2022       # [win]
cxx_compiler:  # [win]
- vs2022       # [win]
        uses: {% set name = "gnuradio-dev" %}
# Set package version from cleaned up git tags if possible,
# otherwise fall back to date-based version.
{% set tag_version = environ.get("GIT_DESCRIBE_TAG", "")|string|replace("-","_")|replace("v","")|replace("git","") %}
{% set post_commit = environ.get("GIT_DESCRIBE_NUMBER", 0)|string %}
{% set hash = environ.get("GIT_DESCRIBE_HASH", "local")|string %}
{% set fallback_version = "0.0.0.{0}.dev+g{1}".format(datetime.datetime.now().strftime("%Y%m%d"), environ.get("GIT_FULL_HASH", "local")[:9]) %}
{% set version = (tag_version if post_commit == "0" else "{0}.post{1}+{2}".format(tag_version, post_commit, hash)) if tag_version else fallback_version %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  # use local path or git repository depending on if the build is local or done on CI
  path: "../.."  # [not os.environ.get("CI")]
  git_url: {{ environ.get('FEEDSTOCK_ROOT', "../..") }}  # [os.environ.get("CI")]

build:
  number: 0
  skip: true  # [py!=311]
  entry_points:
    - gnuradio-companion = gnuradio.grc.main:main  # [win]
    - gr_filter_design = gnuradio.filter.filter_design:main  # [win]
    - gr_modtool = gnuradio.modtool.cli.base:cli  # [win]
    - grcc = gnuradio.grc.compiler:main  # [win]
    - uhd_siggen = gnuradio.uhd.uhd_siggen_base:main  # [win]
  run_exports:
    - {{ pin_subpackage('gnuradio-dev', max_pin='x.x.x') }}

requirements:
  build:
    - {{ compiler('c') }}
    - {{ compiler('cxx') }}
    - cmake >=3.8
    - git
    - ninja
    - pkg-config  # [not win]
    - sysroot_linux-64 2.17  # [linux64]
    - thrift-compiler
    # cross-compilation requirements
    - python                              # [build_platform != target_platform]
    - cross-python_{{ target_platform }}  # [build_platform != target_platform]
    - pybind11                            # [build_platform != target_platform]
    - numpy                               # [build_platform != target_platform]
   # below are needed to link with Qt for qtgui
    - {{ cdt('mesa-dri-drivers') }}  # [linux]
    - {{ cdt('mesa-libgl-devel') }}  # [linux]
  host:
    - click
    - click-plugins
    - codec2
    - fftw
    - gmp  # [not win]
    - gsl
    - libboost-devel
    - libsndfile
    - libthrift  # [not win]
    - mako
    - mpir  # [win]
    - numpy
    - packaging
    - pip  # [win]
    - pybind11
    - pybind11-abi
    - python
    - spdlog
    - thrift  # [not win]
    - volk
  # gnuradio.audio
    - alsa-lib  # [linux]
    - jack  # [linux]
    - portaudio
  # gnuradio companion
    - gtk3
    - lxml
    - pygobject
    - pyyaml
    - jsonschema
  # gnuradio.iio
    - libiio
    - libad9361-iio
  # gnuradio.qtgui
    - pyqt
    - qt-main
    - qwt
  # gnuradio.soapy
    - soapysdr
  # gnuradio.uhd
    - uhd
  # gnuradio.video_sdl
    - sdl
  # gnuradio.zeromq
    - cppzmq
    - zeromq
  # below needed only to run tests in host environment
    - pytest
    - pyzmq
    - setuptools
  run:
    - alsa-plugins  # [linux]
    - click
    - click-plugins
    - fftw
    - lxml
    - mako
    - matplotlib-base
    - menuinst  # [win]
    - numpy
    - packaging
    - {{ pin_compatible('portaudio') }}
    - pygobject
    - pyqt
    - pyqtgraph
    - python
    - pyyaml
    - jsonschema
    - pyzmq
    - {{ pin_compatible('qwt', max_pin='x.x') }}
    - scipy
    # need setuptools because modtool uses pkg_resources
    - setuptools
    - thrift  # [not win]
  run_constrained:
  # conflict with the non-dev conda-forge packages
  # by constraining to non-existent version
    - gnuradio-core ==9999999999
    - gnuradio-grc ==9999999999
    - gnuradio-qtgui ==9999999999
    - gnuradio-soapy ==9999999999
    - gnuradio-uhd ==9999999999
    - gnuradio-video-sdl ==9999999999
    - gnuradio-zeromq ==9999999999

test:
  commands:
    - gnuradio-config-info -v --prefix --sysconfdir --prefsdir --userprefsdir --prefs --builddate --enabled-components --cc --cxx --cflags
    - gr_modtool --help
  imports:
    - gnuradio.analog
    - gnuradio.audio
    - gnuradio.blocks
    - gnuradio.channels
    - gnuradio.digital
    - gnuradio.dtv
    - gnuradio.fec
    - gnuradio.fft
    - gnuradio.filter
    - gnuradio.gr
    - gnuradio.iio
    - gnuradio.network
    - gnuradio.pdu
    - gnuradio.qtgui
    - gnuradio.soapy
    - gnuradio.trellis
    - gnuradio.uhd
    - gnuradio.video_sdl
    - gnuradio.vocoder
    - gnuradio.wavelet
    - gnuradio.zeromq
    - pmt

about:
  home: https://gnuradio.org/
  license: GPL-3.0-or-later
  license_file: COPYING
  summary: The free and open software radio ecosystem
  description: >
    GNU Radio is a free software development toolkit that provides the signal
    processing runtime and processing blocks to implement software radios using
    readily-available, low-cost external RF hardware and commodity processors.
    It is widely used in hobbyist, academic and commercial environments to
    support wireless communications research as well as to implement real-world
    radio systems.

    GNU Radio applications are primarily written using the Python programming
    language, while the supplied, performance-critical signal processing path
    is implemented in C++ using processor floating point extensions where
    available. Thus, the developer is able to implement real-time, high-
    throughput radio systems in a simple-to-use, rapid-application-development
    environment.
  doc_url: https://gnuradio.org/doc/doxygen/
  dev_url: https://github.com/gnuradio/gnuradio

extra:
  recipe-maintainers:
    - ryanvolz
      # Add or replace dependency steps here
      - name: mesa-libGL
mesa-dri-drivers
xorg-x11-server-Xvfb
        uses: Users
*****

This recipe is primarily used for CI builds, although it is possible to use it
locally from a checked-out git repository with "conda-build".

Developers
**********

CI builds use this recipe and the settings in .conda/conda-forge.yml. Any changes
to the recipe should be accompanied by running

    conda-smithy rerender --feedstock_config .conda/conda-forge.yml -c auto
    git rm -f .github/workflows/automerge.yml .github/workflows/webservices.yml .circleci/config.yml
    git commit --amend -s

so that the generated build scripts are updated when necessary.
***** RUN THE ABOVE TO CHECK FOR UPDATES WHENEVER EDITS ARE MADE in .conda *****

You can also re-render from a pull request by starting a comment with "/rerender", which will trigger a Github workflow to perform the above steps.

The CI will build conda packages for commits and pull requests, and it will
upload the packages to Anaconda Cloud on commits to the branch specified
in the configuration below. The channel and label that the packages are
uploaded to are set in the recipe directory in conda_build_config.yaml.
Uploads to Anaconda Cloud also require an API token to be set to the
BINSTAR_TOKEN environment variable. Documentation for token generation:
https://docs.anaconda.com/anacondaorg/user-guide/tasks/work-with-accounts/#creating-access-tokens
To populate BINSTAR_TOKEN for CI jobs, add the token as a secret, e.g.:
https://docs.github.com/en/actions/reference/encrypted-secrets
        with: # This file defines the configuration for building conda packages with CI.
# The actual files for running the CI are created/updated by "conda-smithy".
# You should edit only this file and the recipe files (in recipe_dir, below)
# and not any of the automatically-generated files in e.g. .ci_support,
# .scripts, or .github/workflows/conda-build.yml.

# See https://conda-forge.org/docs/maintainer/conda_forge_yml.html for
# documentation on possible keys and values.

clone_depth: 0
github_actions:
  cancel_in_progress: false
  store_build_artifacts: true
os_version:
  linux_64: cos7
provider:
  linux: github_actions
  osx: github_actions
  win: github_actions
recipe_dir: .conda/recipe
# skip unnecessary files since this is not a full-fledged conda-forge feedstock
skip_render:
  - README.md
  - LICENSE.txt
  - .gitattributes
  - .gitignore
  - build-locally.py
  - LICENSE
test: native_and_emulated
# enable uploads to Anaconda Cloud from specified branches only
# ***** UPDATE THIS FOR MAINTENANCE BRANCHES ********************************
upload_on_branch: main
          bundler-cache: #Wed Apr 10 15:27:10 PDT 2013
distributionBase=GRADLE_USER_HOME
distributionPath=wrapper/dists
zipStoreBase=GRADLE_USER_HOME
zipStorePath=wrapper/dists
distributionUrl=https\://services.gradle.org/distributions/gradle-2.2.1-all.zip
      # Add or replace database setup steps here
      - name: <?xml version='1.0' encoding='utf-8'?>
<resources>
    <array name="qt_sources">
        <item>https://download.qt-project.org/ministro/android/qt5/qt-5.4</item>
    </array>

    <!-- The following is handled automatically by the deployment tool. It should
         not be edited manually. -->

    <array name="bundled_libs">
        <!-- %%INSERT_EXTRA_LIBS%% -->
    </array>

     <array name="qt_libs">
         <!-- %%INSERT_QT_LIBS%% -->
     </array>

    <array name="bundled_in_lib">
        <!-- %%INSERT_BUNDLED_IN_LIB%% -->
    </array>
    <array name="bundled_in_assets">
        <!-- %%INSERT_BUNDLED_IN_ASSETS%% -->
    </array>

</resources>
        run: package labs.mavlink.VideoReceiverApp;

/* Copyright 2013 Google Inc.
 *
 * This library is free software; you can redistribute it and/or
 * modify it under the terms of the GNU Lesser General Public
 * License as published by the Free Software Foundation; either
 * version 2.1 of the License, or (at your option) any later version.
 *
 * This library is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 * Lesser General Public License for more details.
 *
 * You should have received a copy of the GNU Lesser General Public
 * License along with this library; if not, write to the Free Software
 * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301,
 * USA.
 *
 * Project home page: http://code.google.com/p/usb-serial-for-android/
 */
///////////////////////////////////////////////////////////////////////////////////////////
//  Written by:  April 2014
//
//  These routines interface with the Android USB Host devices for serial port communication.
//  The code uses the usb-serial-for-android software library.  The QGCActivity class is the
//  interface to the C++ routines through jni calls.  Do not change the functions without also
//  changing the corresponding calls in the C++ routines or you will break the interface.
//
////////////////////////////////////////////////////////////////////////////////////////////

import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.ArrayList;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.Timer;
import java.util.TimerTask;
import java.io.IOException;

import android.app.Activity;
import android.app.PendingIntent;
import android.content.BroadcastReceiver;
import android.content.Context;
import android.content.Intent;
import android.content.IntentFilter;
import android.hardware.usb.UsbAccessory;
import android.hardware.usb.UsbDevice;
import android.hardware.usb.UsbDeviceConnection;
import android.hardware.usb.UsbManager;
import android.widget.Toast;
import android.util.Log;
import android.os.PowerManager;
import android.os.Bundle;
import android.app.PendingIntent;
import android.view.WindowManager;
import android.os.Bundle;
import android.bluetooth.BluetoothDevice;

import org.qtproject.qt5.android.bindings.QtActivity;
import org.qtproject.qt5.android.bindings.QtApplication;

public class QGLSinkActivity extends QtActivity
{
    public native void nativeInit();

    // QGLSinkActivity singleton
    public QGLSinkActivity() {
    }

    @Override
    public void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        nativeInit();
    }

    @Override
    public void onResume() {
        super.onResume();
    }

    @Override
    protected void onDestroy() {
        super.onDestroy();
    }

    public void onInit(int status) {
    }

    public void jniOnLoad() {
        nativeInit();
    }
}
      # Add or replace test runners here
      - name: /*
 * Copyright (C) 2012, Collabora Ltd.
 *   Author: 
 *
 * Copyright (C) 2015, Collabora Ltd.
 *   Author: >
 *
 * This library is free software; you can redistribute it and/or
 * modify it under the terms of the GNU Lesser General Public
 * License as published by the Free Software Foundation
 * version 2.1 of the License.
 *
 * This library is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
 * Lesser General Public License for more details.
 *
 * You should have received a copy of the GNU Lesser General Public
 * License along with this library; if not, write to the Free Software
 * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301 USA
 *
 */

package org.freedesktop.gstreamer.androidmedia;

import android.hardware.Camera;

public class GstAhcCallback implements Camera.PreviewCallback,
                                       Camera.ErrorCallback,
                                       Camera.AutoFocusCallback {
    public long mUserData;
    public long mCallback;

    public static native void gst_ah_camera_on_preview_frame(byte[] data, Camera camera,
                                                             long callback, long user_data);
    public static native void gst_ah_camera_on_error(int error, Camera camera,
                                                     long callback, long user_data);
    public static native void gst_ah_camera_on_auto_focus(boolean success, Camera camera,
                                                             long callback, long user_data);

    public GstAhcCallback(long callback, long user_data) {
        mCallback = callback;
        mUserData = user_data;
    }

    @Override
    public void onPreviewFrame(byte[] data, Camera camera) {
        gst_ah_camera_on_preview_frame(data, camera, mCallback, mUserData);
    }

    @Override
    public void onError(int error, Camera camera) {
        gst_ah_camera_on_error(error, camera, mCallback, mUserData);
    }

    @Override
    public void onAutoFocus(boolean success, Camera camera) {
        gst_ah_camera_on_auto_focus(success, camera, mCallback, mUserData);
    }
}
        run: /*
 * Copyright (C) 2016 SurroundIO
 *   Author: >
 *
 * This library is free software; you can redistribute it and/or
 * modify it under the terms of the GNU Library General Public
 * License as published by the Free Software Foundation; either
 * version 2 of the License, or (at your option) any later version.
 *
 * This library is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 * Library General Public License for more details.
 *
 * You should have received a copy of the GNU Library General Public
 * License along with this library; if not, write to the
 * Free Software Foundation, Inc., 51 Franklin St, Fifth Floor,
 * Boston, MA 02110-1301, USA.
 */

package org.freedesktop.gstreamer.androidmedia;

import android.hardware.Sensor;
import android.hardware.SensorEvent;
import android.hardware.SensorEventListener;

public class GstAhsCallback implements SensorEventListener {
    public long mUserData;
    public long mSensorCallback;
    public long mAccuracyCallback;

    public static native void gst_ah_sensor_on_sensor_changed(SensorEvent event,
                                                              long callback, long user_data);
    public static native void gst_ah_sensor_on_accuracy_changed(Sensor sensor, int accuracy,
                                                                long callback, long user_data);

    public GstAhsCallback(long sensor_callback,
        long accuracy_callback, long user_data) {
        mSensorCallback = sensor_callback;
        mAccuracyCallback = accuracy_callback;
        mUserData = user_data;
    }

    @Override
    public void onSensorChanged(SensorEvent event) {
      gst_ah_sensor_on_sensor_changed(event, mSensorCallback, mUserData);
    }

    @Override
    public void onAccuracyChanged(Sensor sensor, int accuracy) {
      gst_ah_sensor_on_accuracy_changed(sensor, accuracy,
          mAccuracyCallback, mUserData);
    }
}

  lint: /*
 * Copyright (C) 2015, Collabora Ltd.
 *   Author: >
 *
 * This library is free software; you can redistribute it and/or
 * modify it under the terms of the GNU Lesser General Public
 * License as published by the Free Software Foundation
 * version 2.1 of the License.
 *
 * This library is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
 * Lesser General Public License for more details.
 *
 * You should have received a copy of the GNU Lesser General Public
 * License along with this library; if not, write to the Free Software
 * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301 USA
 *
 */

package org.freedesktop.gstreamer.androidmedia;

import android.graphics.SurfaceTexture;
import android.graphics.SurfaceTexture.OnFrameAvailableListener;

public class GstAmcOnFrameAvailableListener implements OnFrameAvailableListener
{
    private long context = 0;

    public synchronized void onFrameAvailable (SurfaceTexture surfaceTexture) {
        native_onFrameAvailable(context, surfaceTexture);
    }

    public synchronized long getContext () {
        return context;
    }

    public synchronized void setContext (long c) {
        context = c;
    }

    private native void native_onFrameAvailable (long context, SurfaceTexture surfaceTexture);
}
    runs-on: <?xml version="1.0"?>
<manifest package="labs.mavlink.VideoReceiverApp" xmlns:android="http://schemas.android.com/apk/res/android" android:versionName="1" android:versionCode="100000" android:installLocation="auto">
    <application android:hardwareAccelerated="true" android:name="org.qtproject.qt5.android.bindings.QtApplication" android:label="-- %%INSERT_APP_NAME%% --" android:icon="@drawable/icon">
        <activity android:configChanges="orientation|uiMode|screenLayout|screenSize|smallestScreenSize|locale|fontScale|keyboard|keyboardHidden|navigation" android:name="labs.mavlink.VideoReceiverApp.QGLSinkActivity" android:label="-- %%INSERT_APP_NAME%% --" android:screenOrientation="sensorLandscape" android:launchMode="singleTask" android:keepScreenOn="true">
            <intent-filter>
                <action android:name="android.intent.action.MAIN"/>
                <category android:name="android.intent.category.LAUNCHER"/>
                <action android:name="android.hardware.usb.action.USB_DEVICE_ATTACHED"/>
                <action android:name="android.hardware.usb.action.USB_DEVICE_DETACHED"/>
                <action android:name="android.bluetooth.device.action.ACL_CONNECTED"/>
                <action android:name="android.bluetooth.device.action.ACL_DISCONNECTED"/>
                <action android:name="android.hardware.usb.action.USB_ACCESSORY_ATTACHED"/>
            </intent-filter>

            <!-- Rest of Standard Manifest -->
            <meta-data android:name="android.app.lib_name" android:value="-- %%INSERT_APP_LIB_NAME%% --"/>
            <meta-data android:name="android.app.qt_sources_resource_id" android:resource="@array/qt_sources"/>
            <meta-data android:name="android.app.repository" android:value="default"/>
            <meta-data android:name="android.app.qt_libs_resource_id" android:resource="@array/qt_libs"/>
            <meta-data android:name="android.app.bundled_libs_resource_id" android:resource="@array/bundled_libs"/>
            <!-- Deploy Qt libs as part of package -->
            <meta-data android:name="android.app.bundle_local_qt_libs" android:value="-- %%BUNDLE_LOCAL_QT_LIBS%% --"/>
            <meta-data android:name="android.app.bundled_in_lib_resource_id" android:resource="@array/bundled_in_lib"/>
            <meta-data android:name="android.app.bundled_in_assets_resource_id" android:resource="@array/bundled_in_assets"/>
            <!-- Run with local libs -->
            <meta-data android:name="android.app.use_local_qt_libs" android:value="-- %%USE_LOCAL_QT_LIBS%% --"/>
            <meta-data android:name="android.app.libs_prefix" android:value="/data/local/tmp/qt/"/>
            <meta-data android:name="android.app.load_local_libs" android:value="-- %%INSERT_LOCAL_LIBS%% --"/>
            <meta-data android:name="android.app.load_local_jars" android:value="-- %%INSERT_LOCAL_JARS%% --"/>
            <meta-data android:name="android.app.static_init_classes" android:value="-- %%INSERT_INIT_CLASSES%% --"/>
            <!--  Messages maps -->
            <meta-data android:value="@string/ministro_not_found_msg" android:name="android.app.ministro_not_found_msg"/>
            <meta-data android:value="@string/ministro_needed_msg" android:name="android.app.ministro_needed_msg"/>
            <meta-data android:value="@string/fatal_error_msg" android:name="android.app.fatal_error_msg"/>
            <!--  Messages maps -->

            <!-- Splash screen -->
            <!--
            <meta-data android:name="android.app.splash_screen_drawable" android:resource="@drawable/logo"/>
            -->
            <!-- Splash screen -->

            <!-- Background running -->
            <!-- Warning: changing this value to true may cause unexpected crashes if the
                          application still try to draw after
                          "applicationStateChanged(Qt::ApplicationSuspended)"
                          signal is sent! -->
            <meta-data android:name="android.app.background_running" android:value="false"/>
            <!-- Background running -->
        </activity>
    </application>
    <uses-sdk android:minSdkVersion="16" android:targetSdkVersion="28"/>

    <!-- Needed to keep working while 'asleep' -->


    <!-- The following comment will be replaced upon deployment with default permissions based on the dependencies of the application.
         Remove the comment if you do not require these default permissions. -->
    <!-- %%INSERT_PERMISSIONS -->

    <!-- Support devices without USB host mode since there are other connection types -->
    <uses-feature android:name="android.hardware.usb.host" android:required="false"/>

    <!-- Support devices without Bluetooth since there are other connection types -->
    <uses-feature android:name="android.hardware.bluetooth" android:required="false"/>

    <!-- Support devices that don't have location services -->
    <uses-feature android:name="android.hardware.location.gps" android:required="false"/>
    <uses-feature android:name="android.hardware.location.network" android:required="false"/>
    <uses-feature android:name="android.hardware.location" android:required="false"/>
    <uses-feature android:name="android.hardware.usb.accessory"/>


        <uses-permission android:name="android.permission.INTERNET"/>
        <uses-permission android:name="android.permission.WRITE_INTERNAL_STORAGE"/>
        <uses-permission android:name="android.permission.WRITE_EXTERNAL_STORAGE"/>

    <!-- The following comment will be replaced upon deployment with default features based on the dependencies of the application.
         Remove the comment if you do not require these default features. -->
    <!-- %%INSERT_FEATURES -->

</manifest>
    steps: <?xml version="1.0"?>
<manifest android:versionName="@QT_ANDROID_APP_VERSION@" package="@QT_ANDROID_APP_PACKAGE_NAME@" android:installLocation="auto" xmlns:android="http://schemas.android.com/apk/res/android" android:versionCode="@QT_ANDROID_APP_VERSION_CODE@">
    <application android:label="@QT_ANDROID_APP_NAME@" android:name="org.qtproject.qt5.android.bindings.QtApplication">
		<activity android:label="@QT_ANDROID_APP_NAME@" android:name="org.qtproject.qt5.android.bindings.QtActivity" android:screenOrientation="unspecified" android:configChanges="orientation|uiMode|screenLayout|screenSize|smallestScreenSize|locale|fontScale|keyboard|keyboardHidden|navigation">
			<intent-filter>
				<action android:name="android.intent.action.MAIN"/>
				<category android:name="android.intent.category.LAUNCHER"/>
			</intent-filter>
			<meta-data android:name="android.app.lib_name" android:value="-- %%INSERT_APP_LIB_NAME%% --"/>
			<meta-data android:name="android.app.qt_sources_resource_id" android:resource="@array/qt_sources"/>
			<meta-data android:name="android.app.repository" android:value="default"/>
			<meta-data android:name="android.app.qt_libs_resource_id" android:resource="@array/qt_libs"/>
			<meta-data android:name="android.app.bundled_libs_resource_id" android:resource="@array/bundled_libs"/>
			<!-- Deploy Qt libs as part of package -->
			<meta-data android:name="android.app.bundle_local_qt_libs" android:value="-- %%BUNDLE_LOCAL_QT_LIBS%% --"/>
			<meta-data android:name="android.app.bundled_in_lib_resource_id" android:resource="@array/bundled_in_lib"/>
			<meta-data android:name="android.app.bundled_in_assets_resource_id" android:resource="@array/bundled_in_assets"/>
			<!-- Run with local libs -->
			<meta-data android:name="android.app.use_local_qt_libs" android:value="-- %%USE_LOCAL_QT_LIBS%% --"/>
			<meta-data android:name="android.app.libs_prefix" android:value="/data/local/tmp/qt/"/>
			<meta-data android:name="android.app.load_local_libs" android:value="-- %%INSERT_LOCAL_LIBS%% --"/>
			<meta-data android:name="android.app.load_local_jars" android:value="-- %%INSERT_LOCAL_JARS%% --"/>
			<meta-data android:name="android.app.static_init_classes" android:value="-- %%INSERT_INIT_CLASSES%% --"/>
			<!--  Messages maps -->
			<!--<meta-data android:name="android.app.ministro_not_found_msg" android:value="@string/ministro_not_found_msg"/>
			<meta-data android:name="android.app.ministro_needed_msg" android:value="@string/ministro_needed_msg"/>
			<meta-data android:name="android.app.fatal_error_msg" android:value="@string/fatal_error_msg"/>-->
		</activity>
	</application>
	<supports-screens android:anyDensity="true" android:normalScreens="true" android:smallScreens="true" android:largeScreens="true"/>
	<uses-sdk android:minSdkVersion="18" android:targetSdkVersion="19"/>
	<uses-permission android:name="android.permission.INTERNET" />
</manifest>
      - name: buildscript {

    repositories {
        maven  {
            url "http://repo1.maven.org/maven2"
        }
    }

    dependencies {
        classpath 'com.android.tools.build:gradle:1.1.0'
    }
}

allprojects {
    repositories {
        jcenter()
    }
}

apply plugin: 'com.android.application'

dependencies {
    compile fileTree(dir: 'libs', include: ['*.jar'])
}

android {
    /*******************************************************
     * The following variables:
     * - androidBuildToolsVersion,
     * - androidCompileSdkVersion
     * - qt5AndroidDir - holds the path to qt android files
     *                   needed to build any Qt application
     *                   on Android.
     *
     * are defined in gradle.properties file. This file is
     * updated by QtCreator and androiddeployqt tools.
     * Changing them manually might break the compilation!
     *******************************************************/

    compileSdkVersion androidCompileSdkVersion.toInteger()

    buildToolsVersion androidBuildToolsVersion

    sourceSets {
        main {
            manifest.srcFile 'AndroidManifest.xml'
            java.srcDirs = [qt5AndroidDir + '/src', 'src', 'java']
            aidl.srcDirs = [qt5AndroidDir + '/src', 'src', 'aidl']
            res.srcDirs = [qt5AndroidDir + '/res', 'res']
            resources.srcDirs = ['src']
            renderscript.srcDirs = ['src']
            assets.srcDirs = ['assets']
            jniLibs.srcDirs = ['libs']
       }
    }

    aaptOptions {
        cruncherEnabled = false
    }

    lintOptions {
        abortOnError false
    }
}
        uses: #!/usr/bin/env bash

##############################################################################
##
##  Gradle start up script for UN*X
##
##############################################################################

# Add default JVM options here. You can also use JAVA_OPTS and GRADLE_OPTS to pass JVM options to this script.
DEFAULT_JVM_OPTS=""

APP_NAME="Gradle"
APP_BASE_NAME=`basename "$0"`

# Use the maximum available, or set MAX_FD != -1 to use that value.
MAX_FD="maximum"

warn ( ) {
    echo "$*"
}

die ( ) {
    echo
    echo "$*"
    echo
    exit 1
}

# OS specific support (must be 'true' or 'false').
cygwin=false
msys=false
darwin=false
case "`uname`" in
  CYGWIN* )
    cygwin=true
    ;;
  Darwin* )
    darwin=true
    ;;
  MINGW* )
    msys=true
    ;;
esac

# For Cygwin, ensure paths are in UNIX format before anything is touched.
if $cygwin ; then
    [ -n "$JAVA_HOME" ] && JAVA_HOME=`cygpath --unix "$JAVA_HOME"`
fi

# Attempt to set APP_HOME
# Resolve links: $0 may be a link
PRG="$0"
# Need this for relative symlinks.
while [ -h "$PRG" ] ; do
    ls=`ls -ld "$PRG"`
    link=`expr "$ls" : '.*-> \(.*\)$'`
    if expr "$link" : '/.*' > /dev/null; then
        PRG="$link"
    else
        PRG=`dirname "$PRG"`"/$link"
    fi
done
SAVED="`pwd`"
cd "`dirname \"$PRG\"`/" >&-
APP_HOME="`pwd -P`"
cd "$SAVED" >&-

CLASSPATH=$APP_HOME/gradle/wrapper/gradle-wrapper.jar

# Determine the Java command to use to start the JVM.
if [ -n "$JAVA_HOME" ] ; then
    if [ -x "$JAVA_HOME/jre/sh/java" ] ; then
        # IBM's JDK on AIX uses strange locations for the executables
        JAVACMD="$JAVA_HOME/jre/sh/java"
    else
        JAVACMD="$JAVA_HOME/bin/java"
    fi
    if [ ! -x "$JAVACMD" ] ; then
        die "ERROR: JAVA_HOME is set to an invalid directory: $JAVA_HOME

Please set the JAVA_HOME variable in your environment to match the
location of your Java installation."
    fi
else
    JAVACMD="java"
    which java >/dev/null 2>&1 || die "ERROR: JAVA_HOME is not set and no 'java' command could be found in your PATH.

Please set the JAVA_HOME variable in your environment to match the
location of your Java installation."
fi

# Increase the maximum file descriptors if we can.
if [ "$cygwin" = "false" -a "$darwin" = "false" ] ; then
    MAX_FD_LIMIT=`ulimit -H -n`
    if [ $? -eq 0 ] ; then
        if [ "$MAX_FD" = "maximum" -o "$MAX_FD" = "max" ] ; then
            MAX_FD="$MAX_FD_LIMIT"
        fi
        ulimit -n $MAX_FD
        if [ $? -ne 0 ] ; then
            warn "Could not set maximum file descriptor limit: $MAX_FD"
        fi
    else
        warn "Could not query maximum file descriptor limit: $MAX_FD_LIMIT"
    fi
fi

# For Darwin, add options to specify how the application appears in the dock
if $darwin; then
    GRADLE_OPTS="$GRADLE_OPTS \"-Xdock:name=$APP_NAME\" \"-Xdock:icon=$APP_HOME/media/gradle.icns\""
fi

# For Cygwin, switch paths to Windows format before running java
if $cygwin ; then
    APP_HOME=`cygpath --path --mixed "$APP_HOME"`
    CLASSPATH=`cygpath --path --mixed "$CLASSPATH"`

    # We build the pattern for arguments to be converted via cygpath
    ROOTDIRSRAW=`find -L / -maxdepth 1 -mindepth 1 -type d 2>/dev/null`
    SEP=""
    for dir in $ROOTDIRSRAW ; do
        ROOTDIRS="$ROOTDIRS$SEP$dir"
        SEP="|"
    done
    OURCYGPATTERN="(^($ROOTDIRS))"
    # Add a user-defined pattern to the cygpath arguments
    if [ "$GRADLE_CYGPATTERN" != "" ] ; then
        OURCYGPATTERN="$OURCYGPATTERN|($GRADLE_CYGPATTERN)"
    fi
    # Now convert the arguments - kludge to limit ourselves to /bin/sh
    i=0
    for arg in "$@" ; do
        CHECK=`echo "$arg"|egrep -c "$OURCYGPATTERN" -`
        CHECK2=`echo "$arg"|egrep -c "^-"`                                 ### Determine if an option

        if [ $CHECK -ne 0 ] && [ $CHECK2 -eq 0 ] ; then                    ### Added a condition
            eval `echo args$i`=`cygpath --path --ignore --mixed "$arg"`
        else
            eval `echo args$i`="\"$arg\""
        fi
        i=$((i+1))
    done
    case $i in
        (0) set -- ;;
        (1) set -- "$args0" ;;
        (2) set -- "$args0" "$args1" ;;
        (3) set -- "$args0" "$args1" "$args2" ;;
        (4) set -- "$args0" "$args1" "$args2" "$args3" ;;
        (5) set -- "$args0" "$args1" "$args2" "$args3" "$args4" ;;
        (6) set -- "$args0" "$args1" "$args2" "$args3" "$args4" "$args5" ;;
        (7) set -- "$args0" "$args1" "$args2" "$args3" "$args4" "$args5" "$args6" ;;
        (8) set -- "$args0" "$args1" "$args2" "$args3" "$args4" "$args5" "$args6" "$args7" ;;
        (9) set -- "$args0" "$args1" "$args2" "$args3" "$args4" "$args5" "$args6" "$args7" "$args8" ;;
    esac
fi

# Split up the JVM_OPTS And GRADLE_OPTS values into an array, following the shell quoting and substitution rules
function splitJvmOpts() {
    JVM_OPTS=("$@")
}
eval splitJvmOpts $DEFAULT_JVM_OPTS $JAVA_OPTS $GRADLE_OPTS
JVM_OPTS[${#JVM_OPTS[*]}]="-Dorg.gradle.appname=$APP_BASE_NAME"

exec "$JAVACMD" "${JVM_OPTS[@]}" -classpath "$CLASSPATH" org.gradle.wrapper.GradleWrapperMain "$@"
      - name: @if "%DEBUG%" == "" @echo off
@rem ##########################################################################
@rem
@rem  Gradle startup script for Windows
@rem
@rem ##########################################################################

@rem Set local scope for the variables with windows NT shell
if "%OS%"=="Windows_NT" setlocal

@rem Add default JVM options here. You can also use JAVA_OPTS and GRADLE_OPTS to pass JVM options to this script.
set DEFAULT_JVM_OPTS=

set DIRNAME=%~dp0
if "%DIRNAME%" == "" set DIRNAME=.
set APP_BASE_NAME=%~n0
set APP_HOME=%DIRNAME%

@rem Find java.exe
if defined JAVA_HOME goto findJavaFromJavaHome

set JAVA_EXE=java.exe
%JAVA_EXE% -version >NUL 2>&1
if "%ERRORLEVEL%" == "0" goto init

echo.
echo ERROR: JAVA_HOME is not set and no 'java' command could be found in your PATH.
echo.
echo Please set the JAVA_HOME variable in your environment to match the
echo location of your Java installation.

goto fail

:findJavaFromJavaHome
set JAVA_HOME=%JAVA_HOME:"=%
set JAVA_EXE=%JAVA_HOME%/bin/java.exe

if exist "%JAVA_EXE%" goto init

echo.
echo ERROR: JAVA_HOME is set to an invalid directory: %JAVA_HOME%
echo.
echo Please set the JAVA_HOME variable in your environment to match the
echo location of your Java installation.

goto fail

:init
@rem Get command-line arguments, handling Windowz variants

if not "%OS%" == "Windows_NT" goto win9xME_args
if "%@eval[2+2]" == "4" goto 4NT_args

:win9xME_args
@rem Slurp the command line arguments.
set CMD_LINE_ARGS=
set _SKIP=2

:win9xME_args_slurp
if "x%~1" == "x" goto execute

set CMD_LINE_ARGS=%*
goto execute

:4NT_args
@rem Get arguments from the 4NT Shell from JP Software
set CMD_LINE_ARGS=%$

:execute
@rem Setup the command line

set CLASSPATH=%APP_HOME%\gradle\wrapper\gradle-wrapper.jar

@rem Execute Gradle
"%JAVA_EXE%" %DEFAULT_JVM_OPTS% %JAVA_OPTS% %GRADLE_OPTS% "-Dorg.gradle.appname=%APP_BASE_NAME%" -classpath "%CLASSPATH%" org.gradle.wrapper.GradleWrapperMain %CMD_LINE_ARGS%

:end
@rem End local scope for the variables with windows NT shell
if "%ERRORLEVEL%"=="0" goto mainEnd

:fail
rem Set variable GRADLE_EXIT_CONSOLE if you need the _script_ return code instead of
rem the _cmd.exe /c_ return code!
if  not "" == "%GRADLE_EXIT_CONSOLE%" exit 1
exit /b 1

:mainEnd
if "%OS%"=="Windows_NT" endlocal

:omega
        uses: cmake_minimum_required(VERSION 3.10)

project(VideoReceiverApp LANGUAGES C CXX)

set_property(CACHE CMAKE_BUILD_TYPE PROPERTY STRINGS "Debug;Release;RelWithDebInfo;MinSizeRel;Coverage")

set(CMAKE_CXX_STANDARD 14)
set(CMAKE_AUTOMOC ON)
set(CMAKE_AUTOUIC ON)
set(CMAKE_AUTORCC ON)
set(CMAKE_INCLUDE_CURRENT_DIR ON)

include(FeatureSummary)

if ("${CMAKE_CXX_COMPILER_ID}" STREQUAL "Clang" OR "${CMAKE_CXX_COMPILER_ID}" STREQUAL "GNU")
    add_compile_options(-Wall -Wextra -Wno-address-of-packed-member)
endif()

# CMake build type
# Debug Release RelWithDebInfo MinSizeRel Coverage
if (NOT CMAKE_BUILD_TYPE)
    # default to release with debug symbols
    set(CMAKE_BUILD_TYPE RelWithDebInfo CACHE STRING "Build type" FORCE)
endif()

set(QGC_ROOT ${CMAKE_SOURCE_DIR}/..)

# Add folder where are supportive functions
list(APPEND CMAKE_MODULE_PATH ${QGC_ROOT}/cmake)

# Configure Qt5 to get necessary variables
include(Qt5QGCConfiguration)
message(STATUS "Build Type: ${CMAKE_BUILD_TYPE}")
message(STATUS "Qt version: ${QT_VERSION}")
message(STATUS "Qt spec: ${QT_MKSPEC}")

set(COMPANY "Auterion")
set(COPYRIGHT "Copyright (c) 2020 VideoReceiverApp. All rights reserved.")
set(IDENTIFIER "labs.auterion.VideoReceiverApp")

include(Git)
message(STATUS "VideoReceiverApp version: ${GIT_VERSION}")

#=============================================================================
# ccache
#
option(CCACHE "Use ccache if available" ON)
find_program(CCACHE_PROGRAM ccache)
if (CCACHE AND CCACHE_PROGRAM AND NOT DEFINED ENV{CCACHE_DISABLE})
    set_property(GLOBAL PROPERTY RULE_LAUNCH_COMPILE "${CCACHE_PROGRAM}")
endif()

#=============================================================================
# Compile QML
#
option(COMPILE_QML "Pre-compile QML files using the Qt Quick compiler." FALSE)
add_feature_info(COMPILE_QML COMPILE_QML "Pre-compile QML files using the Qt Quick compiler.")
if(COMPILE_QML)
    find_package(Qt5QuickCompiler)

    set_package_properties(Qt5QuickCompiler PROPERTIES
        DESCRIPTION "Pre-compile QML files using the Qt Quick compiler."
        TYPE OPTIONAL
        )
endif()

#=============================================================================
# Debug QML
#
option(DEBUG_QML "Build VideoReceiverApp with QML debugging/profiling support." FALSE)
add_feature_info(DEBUG_QML DEBUG_QML "Build VideoReceiverApp with QML debugging/profiling support.")
if(DEBUG_QML)
    message(STATUS "To enable the QML debugger/profiler, run with: '-qmljsdebugger=port:1234'")
    add_definitions(-DQMLJSDEBUGGER)
    add_definitions(-DQT_DECLARATIVE_DEBUG)
    add_definitions(-DQT_QML_DEBUG)
endif()

#=============================================================================
# GStreamer
#
find_package(PkgConfig)
pkg_check_modules(GST
    gstreamer-1.0>=1.14
    gstreamer-video-1.0>=1.14
    gstreamer-gl-1.0>=1.14
    egl
    )

if (GST_FOUND)
    include_directories(
        ${GST_INCLUDE_DIRS}
        )
endif()

#=============================================================================
# Qt5
#
find_package(Qt5 ${QT_VERSION}
    COMPONENTS
    Bluetooth
    Charts
    Concurrent
    Core
    Location
    Multimedia
    Network
    Positioning
    Quick
    QuickWidgets
    OpenGL
    Sql
    Svg
    Test
    TextToSpeech
    Widgets
    Xml
    REQUIRED
    HINTS
    ${QT_LIBRARY_HINTS}
    )

# Sets the default flags for compilation and linking.
include(CompileOptions)

include_directories(
    ${QGC_ROOT}/src
    ${CMAKE_CURRENT_BINARY_DIR}
    ${Qt5Location_PRIVATE_INCLUDE_DIRS}
    VideoReceiver
    )

add_subdirectory(${QGC_ROOT}/libs/qmlglsink qmlglsink.build)
add_subdirectory(${QGC_ROOT}/src/VideoReceiver VideoReceiver.build)

set(VIDEORECIVERAPP_SOURCES main.cpp ${QGC_ROOT}/src/QGCLoggingCategory.cc)
set(VIDEORECIVERAPP_RESOURCES qml.qrc)

if(ANDROID)
    add_library(VideoReceiverApp SHARED ${VIDEORECIVERAPP_SOURCES} ${VIDEORECIVERAPP_RESOURCES})
else()
    add_executable(VideoReceiverApp ${VIDEORECIVERAPP_SOURCES} ${VIDEORECIVERAPP_RESOURCES})
endif()

target_link_libraries(VideoReceiverApp
    PRIVATE
        VideoReceiver
        Qt5::Core
        Qt5::Multimedia
        Qt5::OpenGL
        Qt5::Quick
        Qt5::QuickWidgets
)
        with: <?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>CFBundleDisplayName</key>
	<string>QQmlGlSinkTest</string>
	<key>CFBundleExecutable</key>
	<string>$(EXECUTABLE_NAME)</string>
	<key>NSHumanReadableCopyright</key>
	<string>Open Source Flight Systems GmbH - Internal Build</string>
	<key>CFBundleIconFile</key>
	<string></string>
	<key>CFBundleIdentifier</key>
	<string>labs.auterion.VideoReceiverApp</string>
	<key>CFBundleName</key>
	<string>$(PRODUCT_NAME)</string>
	<key>CFBundlePackageType</key>
	<string>APPL</string>
	<key>CFBundleShortVersionString</key>
	<string>0.0.0</string>
	<key>CFBundleSignature</key>
	<string>????</string>
	<key>CFBundleVersion</key>
	<string>1</string>
	<key>LSRequiresIPhoneOS</key>
	<true/>
	<key>UIFileSharingEnabled</key>
	<true/>
</dict>
</plist>
          bundler-cache: #include <QGuiApplication>
#include <QQmlApplicationEngine>

#include <QQuickWindow>
#include <QQuickItem>
#include <QRunnable>
#include <QCommandLineParser>
#include <QTimer>

#include <gst/gst.h>

#include "QGCLoggingCategory.h"

QGC_LOGGING_CATEGORY(AppLog, "VideoReceiverApp")

#if defined(__android__)
#include <QtAndroidExtras>

#include <jni.h>

#include <android/log.h>

static jobject _class_loader = nullptr;
static jobject _context = nullptr;

extern "C" {
    void gst_amc_jni_set_java_vm(JavaVM *java_vm);

    jobject gst_android_get_application_class_loader(void) {
        return _class_loader;
    }
}

static void
gst_android_init(JNIEnv* env, jobject context)
{
    jobject class_loader = nullptr;

    jclass context_cls = env->GetObjectClass(context);

    if (!context_cls) {
        return;
    }

    jmethodID get_class_loader_id = env->GetMethodID(context_cls, "getClassLoader", "()Ljava/lang/ClassLoader;");

    if (env->ExceptionCheck()) {
        env->ExceptionDescribe();
        env->ExceptionClear();
        return;
    }

    class_loader = env->CallObjectMethod(context, get_class_loader_id);

    if (env->ExceptionCheck()) {
        env->ExceptionDescribe();
        env->ExceptionClear();
        return;
    }

    _context = env->NewGlobalRef(context);
    _class_loader = env->NewGlobalRef(class_loader);
}

static const char kJniClassName[] {"labs/mavlink/VideoReceiverApp/QGLSinkActivity"};

static void setNativeMethods(void)
{
    JNINativeMethod javaMethods[] {
        {"nativeInit", "()V", reinterpret_cast<void *>(gst_android_init)}
    };

    QAndroidJniEnvironment jniEnv;

    if (jniEnv->ExceptionCheck()) {
        jniEnv->ExceptionDescribe();
        jniEnv->ExceptionClear();
    }

    jclass objectClass = jniEnv->FindClass(kJniClassName);

    if (!objectClass) {
        qWarning() << "Couldn't find class:" << kJniClassName;
        return;
    }

    jint val = jniEnv->RegisterNatives(objectClass, javaMethods, sizeof(javaMethods) / sizeof(javaMethods[0]));

    if (val < 0) {
        qWarning() << "Error registering methods: " << val;
    } else {
        qDebug() << "Main Native Functions Registered";
    }

    if (jniEnv->ExceptionCheck()) {
        jniEnv->ExceptionDescribe();
        jniEnv->ExceptionClear();
    }
}

jint JNI_OnLoad(JavaVM* vm, void* reserved)
{
    Q_UNUSED(reserved);

    JNIEnv* env;

    if (vm->GetEnv(reinterpret_cast<void**>(&env), JNI_VERSION_1_6) != JNI_OK) {
        return -1;
    }

    setNativeMethods();

    gst_amc_jni_set_java_vm(vm);

    return JNI_VERSION_1_6;
}
#endif

#include <GStreamer.h>
#include <VideoReceiver.h>

class VideoReceiverApp : public QRunnable
{
public:
    VideoReceiverApp(QCoreApplication& app, bool qmlAllowed)
        : _app(app)
        , _qmlAllowed(qmlAllowed)
    {}

    void run();

    int exec();

    void startStreaming();
    void startDecoding();
    void startRecording();

protected:
    void _dispatch(std::function<void()> code);

private:
    QCoreApplication& _app;
    bool _qmlAllowed;
    VideoReceiver* _receiver = nullptr;
    QQuickWindow* _window = nullptr;
    QQuickItem* _widget = nullptr;
    void* _videoSink = nullptr;
    QString _url;
    unsigned _timeout = 5;
    unsigned _connect = 1;
    bool _decode = true;
    unsigned _stopDecodingAfter = 0;
    bool _record = false;
    QString _videoFile;
    unsigned int _fileFormat = VideoReceiver::FILE_FORMAT_MIN;
    unsigned _stopRecordingAfter = 15;
    bool _useFakeSink = false;
    bool _streaming = false;
    bool _decoding = false;
    bool _recording = false;
};

void
VideoReceiverApp::run()
{
    if((_videoSink = GStreamer::createVideoSink(nullptr, _widget)) == nullptr) {
        qCDebug(AppLog) << "createVideoSink failed";
        return;
    }

    _receiver->startDecoding(_videoSink);
}

int
VideoReceiverApp::exec()
{
    QCommandLineParser parser;

    parser.addHelpOption();

    parser.addPositionalArgument("url",
        QCoreApplication::translate("main", "Source URL."));

    QCommandLineOption timeoutOption(QStringList() << "t" << "timeout",
        QCoreApplication::translate("main", "Source timeout."),
        QCoreApplication::translate("main", "seconds"));

    parser.addOption(timeoutOption);

    QCommandLineOption connectOption(QStringList() << "c" << "connect",
        QCoreApplication::translate("main", "Number of connection attempts."),
        QCoreApplication::translate("main", "attempts"));

    parser.addOption(connectOption);

    QCommandLineOption decodeOption(QStringList() << "d" << "decode",
        QCoreApplication::translate("main", "Decode and render video."));

    parser.addOption(decodeOption);

    QCommandLineOption noDecodeOption("no-decode",
        QCoreApplication::translate("main", "Don't decode and render video."));

    parser.addOption(noDecodeOption);

    QCommandLineOption stopDecodingOption("stop-decoding",
        QCoreApplication::translate("main", "Stop decoding after time."),
        QCoreApplication::translate("main", "seconds"));

    parser.addOption(stopDecodingOption);

    QCommandLineOption recordOption(QStringList() << "r" << "record",
        QCoreApplication::translate("main", "Record video."),
        QGuiApplication::translate("main", "file"));

    parser.addOption(recordOption);

    QCommandLineOption formatOption(QStringList() << "f" << "format",
        QCoreApplication::translate("main", "File format."),
        QCoreApplication::translate("main", "format"));

    parser.addOption(formatOption);

    QCommandLineOption stopRecordingOption("stop-recording",
        QCoreApplication::translate("main", "Stop recording after time."),
        QCoreApplication::translate("main", "seconds"));

    parser.addOption(stopRecordingOption);

    QCommandLineOption videoSinkOption("video-sink",
        QCoreApplication::translate("main", "Use video sink: 0 - autovideosink, 1 - fakesink"),
        QCoreApplication::translate("main", "sink"));

    if (!_qmlAllowed) {
        parser.addOption(videoSinkOption);
    }

    parser.process(_app);

    const QStringList args = parser.positionalArguments();

    if (args.size() != 1) {
        parser.showHelp(0);
    }

    _url = args.at(0);

    if (parser.isSet(timeoutOption)) {
        _timeout = parser.value(timeoutOption).toUInt();
    }

    if (parser.isSet(connectOption)) {
        _connect = parser.value(connectOption).toUInt();
    }

    if (parser.isSet(decodeOption) && parser.isSet(noDecodeOption)) {
        parser.showHelp(0);
    }

    if (parser.isSet(decodeOption)) {
        _decode = true;
    }

    if (parser.isSet(noDecodeOption)) {
        _decode = false;
    }

    if (_decode && parser.isSet(stopDecodingOption)) {
        _stopDecodingAfter = parser.value(stopDecodingOption).toUInt();
    }

    if (parser.isSet(recordOption)) {
        _record = true;
        _videoFile = parser.value(recordOption);
    }

    if (parser.isSet(formatOption)) {
        _fileFormat += parser.value(formatOption).toUInt();
    }

    if (_record && parser.isSet(stopRecordingOption)) {
        _stopRecordingAfter = parser.value(stopRecordingOption).toUInt();
    }

    if (parser.isSet(videoSinkOption)) {
        _useFakeSink = parser.value(videoSinkOption).toUInt() > 0;
    }

    _receiver = GStreamer::createVideoReceiver(nullptr);

    QQmlApplicationEngine engine;

    if (_decode && _qmlAllowed) {
        engine.load(QUrl(QStringLiteral("qrc:/main.qml")));

        _window = static_cast<QQuickWindow*>(engine.rootObjects().first());
        Q_ASSERT(_window != nullptr);

        _widget = _window->findChild<QQuickItem*>("videoItem");
        Q_ASSERT(_widget != nullptr);
    }

    startStreaming();

    QObject::connect(_receiver, &VideoReceiver::timeout, [](){
        qCDebug(AppLog) << "Streaming timeout";
     });

    QObject::connect(_receiver, &VideoReceiver::streamingChanged, [this](bool active){
        _streaming = active;
        if (_streaming) {
            qCDebug(AppLog) << "Streaming started";
        } else {
            qCDebug(AppLog) << "Streaming stopped";
        }
     });

    QObject::connect(_receiver, &VideoReceiver::decodingChanged, [this](bool active){
        _decoding = active;
        if (_decoding) {
            qCDebug(AppLog) << "Decoding started";
        } else {
            qCDebug(AppLog) << "Decoding stopped";
            if (_streaming) {
                if (!_recording) {
                    _dispatch([this](){
                        _receiver->stop();
                    });
                }
            }
        }
     });

    QObject::connect(_receiver, &VideoReceiver::recordingChanged, [this](bool active){
        _recording = active;
        if (_recording) {
            qCDebug(AppLog) << "Recording started";
        } else {
            qCDebug(AppLog) << "Recording stopped";
            if (_streaming) {
                if (!_decoding) {
                    _dispatch([this](){
                        _receiver->stop();
                    });
                }
            }
        }
     });

    QObject::connect(_receiver, &VideoReceiver::onStartComplete, [this](VideoReceiver::STATUS status){
        if (status != VideoReceiver::STATUS_OK) {
            qCDebug(AppLog) << "Video receiver start failed";
            _dispatch([this](){
                if (--_connect > 0) {
                    qCDebug(AppLog) << "Restarting ...";
                    _dispatch([this](){
                        startStreaming();
                    });
                } else {
                    qCDebug(AppLog) << "Closing...";
                    delete _receiver;
                    _app.exit();
                }
            });
        } else {
            qCDebug(AppLog) << "Video receiver started";
        }
     });

    QObject::connect(_receiver, &VideoReceiver::onStopComplete, [this](VideoReceiver::STATUS ){
        qCDebug(AppLog) << "Video receiver stopped";

        _dispatch([this](){
            if (--_connect > 0) {
                qCDebug(AppLog) << "Restarting ...";
                _dispatch([this](){
                    startStreaming();
                });
            } else {
                qCDebug(AppLog) << "Closing...";
                delete _receiver;
                _app.exit();
            }
        });
     });


    return _app.exec();
}

void
VideoReceiverApp::startStreaming()
{
    _receiver->start(_url, _timeout);

    if (_decode) {
        startDecoding();
    }

    if (_record) {
        startRecording();
    }
}

void
VideoReceiverApp::startDecoding()
{
    if (_qmlAllowed) {
        _window->scheduleRenderJob(this, QQuickWindow::BeforeSynchronizingStage);
    } else {
        if (_videoSink == nullptr) {
            if ((_videoSink = gst_element_factory_make(_useFakeSink ? "fakesink" : "autovideosink", nullptr)) == nullptr) {
                qCDebug(AppLog) << "Failed to create video sink";
                return;
            }
        }

        _receiver->startDecoding(_videoSink);
    }

    if (_stopDecodingAfter > 0) {
        unsigned connect = _connect;
        QTimer::singleShot(_stopDecodingAfter * 1000, Qt::PreciseTimer, [this, connect](){
            if (connect != _connect) {
                return;
            }
            _receiver->stopDecoding();
        });
    }
}

void
VideoReceiverApp::startRecording()
{
    _receiver->startRecording(_videoFile, static_cast<VideoReceiver::FILE_FORMAT>(_fileFormat));

    if (_stopRecordingAfter > 0) {
        unsigned connect = _connect;
        QTimer::singleShot(_stopRecordingAfter * 1000, [this, connect](){
            if (connect != _connect) {
                return;
            }
            _receiver->stopRecording();
        });
    }
}

void
VideoReceiverApp::_dispatch(std::function<void()> code)
{
    QTimer* timer = new QTimer();
    timer->moveToThread(qApp->thread());
    timer->setSingleShot(true);
    QObject::connect(timer, &QTimer::timeout, [=](){
        code();
        timer->deleteLater();
    });
    QMetaObject::invokeMethod(timer, "start", Qt::QueuedConnection, Q_ARG(int, 0));
}


static bool isQtApp(const char* app)
{
    const char* s;

#if defined(Q_OS_WIN)
    if ((s = strrchr(app, '\\')) != nullptr) {
#else
    if ((s = strrchr(app, '/')) != nullptr) {
#endif
        s += 1;
    } else {
        s = app;
    }

    return s[0] == 'Q' || s[0] == 'q';
}

int main(int argc, char *argv[])
{
    if (argc < 1) {
        return 0;
    }

    GStreamer::initialize(argc, argv, 3);

    if (isQtApp(argv[0])) {
        QGuiApplication app(argc, argv);
        VideoReceiverApp videoApp(app, true);
        return videoApp.exec();
    } else {
        QCoreApplication app(argc, argv);
        VideoReceiverApp videoApp(app, false);
        return videoApp.exec();
    }
}
      - name: import QtQuick 2.12
import QtQuick.Window 2.12
import QtQuick.Layouts 1.3
import org.freedesktop.gstreamer.GLVideoItem 1.0

Window {
    visible: true
    width: 640
    height: 480
    title: qsTr("VideoReceiverApp")

    RowLayout {
        anchors.fill: parent
        spacing: 0

        GstGLVideoItem {
            id: video
            objectName: "videoItem"
            Layout.fillWidth: true
            Layout.fillHeight: true
        }
    }
}
        run: <RCC>
    <qresource prefix="/">
        <file>main.qml</file>
    </qresource>
</RCC>
      # Add or replace any other lints here
      - name: Security audit dependencies
        run: bin/bundler-audit --update
      - name: Security audit application code
        run: bin/brakeman -q -w2
      - name: Lint Ruby files
        run: bin/rubocop --parallel
